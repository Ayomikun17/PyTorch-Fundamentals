{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6649a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b728098",
   "metadata": {},
   "source": [
    "### Getting the dataset\n",
    "Working with the fashion MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df083e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None)\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0991cd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8bdb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8dda82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835d6c8",
   "metadata": {},
   "source": [
    "Dictionary of the classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f58986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56340496",
   "metadata": {},
   "source": [
    "PyTorch by default takes the batch size, **color channel** first then the height and width of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77dd7472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79143f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae59e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze())\n",
    "plt.title('Ankle boot')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606ab622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap = 'gray')\n",
    "plt.title('Ankle boot Gray scale')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc25fa4",
   "metadata": {},
   "source": [
    "### Visualizing the images in the dataset randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b27167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows, cols =4, 4\n",
    "for i in range(1, rows*cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size = [1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap = 'gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "748b6d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addd1a3",
   "metadata": {},
   "source": [
    "### Prepare DataLoader \n",
    "\n",
    "Breaking the entire dataset to batches for computationally efficiency and updating the parameters per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c453d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader( dataset = train_data,\n",
    "                               batch_size = BATCH_SIZE,\n",
    "                               shuffle = True\n",
    "                                )\n",
    "\n",
    "test_dataloader = DataLoader( dataset = test_data,\n",
    "                               batch_size = BATCH_SIZE,\n",
    "                               shuffle = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac8f9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1b42eac4730>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1b42eac40d0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc5d2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173fad7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_label_batch = next(iter(train_dataloader))\n",
    "\n",
    "train_features_batch.shape, train_label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd9b8eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "x = train_features_batch[0]\n",
    "\n",
    "output = flatten(x)\n",
    "output.shape # Color channel, height*width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a7106ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape:int, hidden_units: int, output_shape: int ):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = input_shape , out_features = hidden_units),\n",
    "            nn.Linear(in_features = hidden_units, out_features = output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c69568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = FashionMNISTModelV0(input_shape = 784,\n",
    "                              hidden_units = 10,\n",
    "                              output_shape = 10)\n",
    "\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008f4eb4",
   "metadata": {},
   "source": [
    "### Setup loss, optimizer and evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3c26712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model_1.parameters(), \n",
    "                              lr = 0.1)\n",
    "\n",
    "acc = Accuracy(task ='Multiclass', num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51530db2",
   "metadata": {},
   "source": [
    "### Finding out how long it took the model to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfca554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Total train time: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70eb5702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train time: 0.001 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000799399999976913"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "end_time = timer()\n",
    "print_train_time(start = start_time, end= end_time, device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c16ab",
   "metadata": {},
   "source": [
    "### Train/Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06b7a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9223009d764f4bce8ab24072e4aa0f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "------\n",
      "Looked at 0/ 60000 samples\n",
      "\n",
      " Train loss: 0.0012621207861229777 | Test loss: 16.7300  | Test acc: 0.1893\n",
      "\n",
      " Train loss: 0.008124697022140026 | Test loss: 13.4469  | Test acc: 0.1284\n",
      "\n",
      " Train loss: 0.006923175882548094 | Test loss: 24.7402  | Test acc: 0.1001\n",
      "\n",
      " Train loss: 0.013110530562698841 | Test loss: 17.8378  | Test acc: 0.1006\n",
      "\n",
      " Train loss: 0.009357682429254055 | Test loss: 15.5976  | Test acc: 0.1079\n",
      "\n",
      " Train loss: 0.007538660895079374 | Test loss: 13.7783  | Test acc: 0.2625\n",
      "\n",
      " Train loss: 0.007954972796142101 | Test loss: 10.9160  | Test acc: 0.2366\n",
      "\n",
      " Train loss: 0.006317449267953634 | Test loss: 6.9505  | Test acc: 0.2848\n",
      "\n",
      " Train loss: 0.004096081014722586 | Test loss: 6.9715  | Test acc: 0.2423\n",
      "\n",
      " Train loss: 0.00442467350512743 | Test loss: 8.2757  | Test acc: 0.3282\n",
      "\n",
      " Train loss: 0.004629870411008596 | Test loss: 4.8531  | Test acc: 0.4342\n",
      "\n",
      " Train loss: 0.002266234252601862 | Test loss: 6.2149  | Test acc: 0.3846\n",
      "\n",
      " Train loss: 0.0035230943467468023 | Test loss: 4.6590  | Test acc: 0.5217\n",
      "\n",
      " Train loss: 0.0024619188625365496 | Test loss: 6.9001  | Test acc: 0.4257\n",
      "\n",
      " Train loss: 0.003228636458516121 | Test loss: 11.3282  | Test acc: 0.2979\n",
      "\n",
      " Train loss: 0.007218098267912865 | Test loss: 7.8967  | Test acc: 0.5222\n",
      "\n",
      " Train loss: 0.00603495491668582 | Test loss: 5.9769  | Test acc: 0.5217\n",
      "\n",
      " Train loss: 0.004939652513712645 | Test loss: 5.0484  | Test acc: 0.4689\n",
      "\n",
      " Train loss: 0.0036225654184818268 | Test loss: 4.3499  | Test acc: 0.4569\n",
      "\n",
      " Train loss: 0.003019204130396247 | Test loss: 3.3793  | Test acc: 0.5259\n",
      "\n",
      " Train loss: 0.002121545374393463 | Test loss: 4.5827  | Test acc: 0.5107\n",
      "\n",
      " Train loss: 0.0012821060372516513 | Test loss: 4.5789  | Test acc: 0.4835\n",
      "\n",
      " Train loss: 0.0021713643800467253 | Test loss: 3.9815  | Test acc: 0.5284\n",
      "\n",
      " Train loss: 0.0014828270068392158 | Test loss: 3.7861  | Test acc: 0.4917\n",
      "\n",
      " Train loss: 0.0018303495598956943 | Test loss: 3.6070  | Test acc: 0.4759\n",
      "\n",
      " Train loss: 0.0033494196832180023 | Test loss: 2.6681  | Test acc: 0.5823\n",
      "\n",
      " Train loss: 0.001001979224383831 | Test loss: 2.5710  | Test acc: 0.5974\n",
      "\n",
      " Train loss: 0.0009257444180548191 | Test loss: 2.9852  | Test acc: 0.6116\n",
      "\n",
      " Train loss: 0.0005449919262900949 | Test loss: 3.7715  | Test acc: 0.5810\n",
      "\n",
      " Train loss: 0.0006955201970413327 | Test loss: 4.1825  | Test acc: 0.5715\n",
      "\n",
      " Train loss: 0.002612542361021042 | Test loss: 3.5749  | Test acc: 0.6030\n",
      "\n",
      " Train loss: 0.0008908701129257679 | Test loss: 3.1977  | Test acc: 0.6403\n",
      "\n",
      " Train loss: 0.0018622587667778134 | Test loss: 3.0419  | Test acc: 0.6465\n",
      "\n",
      " Train loss: 0.0013240311527624726 | Test loss: 2.8395  | Test acc: 0.6208\n",
      "\n",
      " Train loss: 0.0011856106575578451 | Test loss: 4.3094  | Test acc: 0.4670\n",
      "\n",
      " Train loss: 0.0017205345211550593 | Test loss: 6.2238  | Test acc: 0.4195\n",
      "\n",
      " Train loss: 0.002835965482518077 | Test loss: 4.0430  | Test acc: 0.5521\n",
      "\n",
      " Train loss: 0.0007830190006643534 | Test loss: 2.4984  | Test acc: 0.6266\n",
      "\n",
      " Train loss: 0.0014899310190230608 | Test loss: 4.4782  | Test acc: 0.5638\n",
      "\n",
      " Train loss: 0.002297289203852415 | Test loss: 2.7740  | Test acc: 0.6129\n",
      "\n",
      " Train loss: 0.0011966601014137268 | Test loss: 2.8189  | Test acc: 0.6193\n",
      "\n",
      " Train loss: 0.002690741792321205 | Test loss: 2.2540  | Test acc: 0.6730\n",
      "\n",
      " Train loss: 0.001434932230040431 | Test loss: 1.8334  | Test acc: 0.6855\n",
      "\n",
      " Train loss: 0.0003714819613378495 | Test loss: 2.4175  | Test acc: 0.6485\n",
      "\n",
      " Train loss: 0.0010839712340384722 | Test loss: 2.8342  | Test acc: 0.6208\n",
      "\n",
      " Train loss: 0.0010025660740211606 | Test loss: 3.1344  | Test acc: 0.6037\n",
      "\n",
      " Train loss: 0.0009367453749291599 | Test loss: 2.8285  | Test acc: 0.6240\n",
      "\n",
      " Train loss: 0.000733254652004689 | Test loss: 2.5099  | Test acc: 0.6718\n",
      "\n",
      " Train loss: 0.0016451883129775524 | Test loss: 2.3096  | Test acc: 0.7038\n",
      "\n",
      " Train loss: 0.0012839995324611664 | Test loss: 2.1182  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.0012499782023951411 | Test loss: 2.0789  | Test acc: 0.7033\n",
      "\n",
      " Train loss: 0.001027127611450851 | Test loss: 1.9695  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.00041828781832009554 | Test loss: 1.9742  | Test acc: 0.6678\n",
      "\n",
      " Train loss: 0.001083281938917935 | Test loss: 2.3361  | Test acc: 0.6160\n",
      "\n",
      " Train loss: 0.002321870531886816 | Test loss: 2.0995  | Test acc: 0.6378\n",
      "\n",
      " Train loss: 0.0013214221689850092 | Test loss: 2.2306  | Test acc: 0.6561\n",
      "\n",
      " Train loss: 0.0011871691094711423 | Test loss: 2.4503  | Test acc: 0.6589\n",
      "\n",
      " Train loss: 0.0009631772409193218 | Test loss: 2.3613  | Test acc: 0.6852\n",
      "\n",
      " Train loss: 0.0014312240527942777 | Test loss: 2.2354  | Test acc: 0.7093\n",
      "\n",
      " Train loss: 0.0017225705087184906 | Test loss: 2.2569  | Test acc: 0.6951\n",
      "\n",
      " Train loss: 0.0013381685130298138 | Test loss: 2.0915  | Test acc: 0.6709\n",
      "\n",
      " Train loss: 0.0012941713212057948 | Test loss: 1.8333  | Test acc: 0.6781\n",
      "\n",
      " Train loss: 0.0008699459140188992 | Test loss: 1.9820  | Test acc: 0.6608\n",
      "\n",
      " Train loss: 0.0006541324546560645 | Test loss: 2.4756  | Test acc: 0.6272\n",
      "\n",
      " Train loss: 0.001900507602840662 | Test loss: 2.2619  | Test acc: 0.6477\n",
      "\n",
      " Train loss: 0.0014004395343363285 | Test loss: 1.5713  | Test acc: 0.7017\n",
      "\n",
      " Train loss: 0.000501820701174438 | Test loss: 1.5848  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0007416801527142525 | Test loss: 1.6738  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0005815185722894967 | Test loss: 1.7186  | Test acc: 0.7165\n",
      "\n",
      " Train loss: 0.0012480970472097397 | Test loss: 1.7835  | Test acc: 0.7281\n",
      "\n",
      " Train loss: 0.0006878425483591855 | Test loss: 1.9188  | Test acc: 0.7089\n",
      "\n",
      " Train loss: 0.0006866744952276349 | Test loss: 1.7329  | Test acc: 0.7231\n",
      "\n",
      " Train loss: 0.0002348239067941904 | Test loss: 1.9362  | Test acc: 0.6703\n",
      "\n",
      " Train loss: 0.0014276632573455572 | Test loss: 1.9102  | Test acc: 0.6732\n",
      "\n",
      " Train loss: 0.0013341746525838971 | Test loss: 1.5595  | Test acc: 0.7088\n",
      "\n",
      " Train loss: 0.000967878382652998 | Test loss: 1.6096  | Test acc: 0.6939\n",
      "\n",
      " Train loss: 0.0010767951607704163 | Test loss: 1.4401  | Test acc: 0.7034\n",
      "\n",
      " Train loss: 0.0009436671971343458 | Test loss: 1.5161  | Test acc: 0.6878\n",
      "\n",
      " Train loss: 0.0009927087230607867 | Test loss: 1.5813  | Test acc: 0.6848\n",
      "\n",
      " Train loss: 0.0007049292325973511 | Test loss: 1.6718  | Test acc: 0.6792\n",
      "\n",
      " Train loss: 0.0008901159162633121 | Test loss: 1.3313  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.00047435250598937273 | Test loss: 1.1340  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0009888972854241729 | Test loss: 1.2473  | Test acc: 0.6819\n",
      "\n",
      " Train loss: 0.0009060355951078236 | Test loss: 1.1788  | Test acc: 0.6981\n",
      "\n",
      " Train loss: 0.0006012665689922869 | Test loss: 1.4326  | Test acc: 0.6721\n",
      "\n",
      " Train loss: 0.0005594246904365718 | Test loss: 1.6205  | Test acc: 0.6532\n",
      "\n",
      " Train loss: 0.0007694374653510749 | Test loss: 1.6073  | Test acc: 0.6139\n",
      "\n",
      " Train loss: 0.0011387403355911374 | Test loss: 1.1159  | Test acc: 0.6949\n",
      "\n",
      " Train loss: 0.00038118715747259557 | Test loss: 1.0991  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.00054338009795174 | Test loss: 1.2075  | Test acc: 0.6881\n",
      "\n",
      " Train loss: 0.0006386793684214354 | Test loss: 1.3469  | Test acc: 0.6764\n",
      "\n",
      " Train loss: 0.0005834570620208979 | Test loss: 1.3609  | Test acc: 0.6891\n",
      "\n",
      " Train loss: 0.0008400297956541181 | Test loss: 1.1844  | Test acc: 0.7267\n",
      "\n",
      " Train loss: 0.0008221189491450787 | Test loss: 0.9577  | Test acc: 0.7426\n",
      "\n",
      " Train loss: 0.00019962640362791717 | Test loss: 1.1786  | Test acc: 0.6976\n",
      "\n",
      " Train loss: 0.0004208646423649043 | Test loss: 1.4840  | Test acc: 0.6721\n",
      "\n",
      " Train loss: 0.0006717718788422644 | Test loss: 1.5984  | Test acc: 0.6904\n",
      "\n",
      " Train loss: 0.001282106852158904 | Test loss: 1.3696  | Test acc: 0.6786\n",
      "\n",
      " Train loss: 0.0003514145500957966 | Test loss: 1.1010  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0003312941116746515 | Test loss: 1.0361  | Test acc: 0.7219\n",
      "\n",
      " Train loss: 0.000230832738452591 | Test loss: 1.0071  | Test acc: 0.7339\n",
      "\n",
      " Train loss: 0.0010462261270731688 | Test loss: 0.9500  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.00035574971116147935 | Test loss: 1.1666  | Test acc: 0.6984\n",
      "\n",
      " Train loss: 0.0004520954971667379 | Test loss: 1.1783  | Test acc: 0.7138\n",
      "\n",
      " Train loss: 0.0008353627054020762 | Test loss: 1.1691  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.0003281101235188544 | Test loss: 1.1287  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0005054056528024375 | Test loss: 1.0870  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0005068101454526186 | Test loss: 1.0689  | Test acc: 0.7271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.00045692408457398415 | Test loss: 1.0019  | Test acc: 0.7495\n",
      "\n",
      " Train loss: 0.00042540475260466337 | Test loss: 1.0921  | Test acc: 0.7165\n",
      "\n",
      " Train loss: 0.00024345074780285358 | Test loss: 1.2901  | Test acc: 0.6548\n",
      "\n",
      " Train loss: 0.0008879187516868114 | Test loss: 1.1088  | Test acc: 0.6936\n",
      "\n",
      " Train loss: 0.0008356396574527025 | Test loss: 1.1140  | Test acc: 0.7008\n",
      "\n",
      " Train loss: 0.00066751689882949 | Test loss: 1.4098  | Test acc: 0.6566\n",
      "\n",
      " Train loss: 0.000854811049066484 | Test loss: 1.3864  | Test acc: 0.6495\n",
      "\n",
      " Train loss: 0.0006789177423343062 | Test loss: 1.1192  | Test acc: 0.6834\n",
      "\n",
      " Train loss: 0.0008319393382407725 | Test loss: 0.8880  | Test acc: 0.7521\n",
      "\n",
      " Train loss: 0.00024338813091162592 | Test loss: 1.0351  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.000844989437609911 | Test loss: 1.0899  | Test acc: 0.6984\n",
      "\n",
      " Train loss: 0.0004159903328400105 | Test loss: 1.0701  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0007728479104116559 | Test loss: 1.0062  | Test acc: 0.7058\n",
      "\n",
      " Train loss: 0.00039042113348841667 | Test loss: 1.1482  | Test acc: 0.6700\n",
      "\n",
      " Train loss: 0.0010854126885533333 | Test loss: 1.2094  | Test acc: 0.6632\n",
      "\n",
      " Train loss: 0.0005278806202113628 | Test loss: 0.9783  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.00029075535712763667 | Test loss: 0.9826  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.000386268540751189 | Test loss: 1.1605  | Test acc: 0.6737\n",
      "\n",
      " Train loss: 0.0009409710764884949 | Test loss: 1.2083  | Test acc: 0.6801\n",
      "\n",
      " Train loss: 0.0006519816815853119 | Test loss: 1.1921  | Test acc: 0.6874\n",
      "\n",
      " Train loss: 0.0003779929247684777 | Test loss: 1.1726  | Test acc: 0.6898\n",
      "\n",
      " Train loss: 0.00042954852688126266 | Test loss: 1.0338  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0007658216636627913 | Test loss: 1.0031  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.00045659812167286873 | Test loss: 1.1413  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0006742139812558889 | Test loss: 1.1623  | Test acc: 0.6995\n",
      "\n",
      " Train loss: 0.0006475695408880711 | Test loss: 1.1397  | Test acc: 0.6858\n",
      "\n",
      " Train loss: 0.000425901758717373 | Test loss: 1.0907  | Test acc: 0.6891\n",
      "\n",
      " Train loss: 0.0004979176446795464 | Test loss: 1.0120  | Test acc: 0.6910\n",
      "\n",
      " Train loss: 0.0004971816670149565 | Test loss: 0.9455  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.00039761888911016285 | Test loss: 1.0052  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0005906674196012318 | Test loss: 0.9788  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.0004094228206668049 | Test loss: 1.0026  | Test acc: 0.7414\n",
      "\n",
      " Train loss: 0.0006880642613396049 | Test loss: 1.1519  | Test acc: 0.7176\n",
      "\n",
      " Train loss: 0.00043329797335900366 | Test loss: 1.2862  | Test acc: 0.6977\n",
      "\n",
      " Train loss: 0.0009665833204053342 | Test loss: 1.0810  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.000267666851868853 | Test loss: 0.9140  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.00029787683160975575 | Test loss: 0.9079  | Test acc: 0.7498\n",
      "\n",
      " Train loss: 0.0003644956450443715 | Test loss: 1.1368  | Test acc: 0.6854\n",
      "\n",
      " Train loss: 0.0004242523282300681 | Test loss: 1.3063  | Test acc: 0.6499\n",
      "\n",
      " Train loss: 0.0014837185153737664 | Test loss: 1.0390  | Test acc: 0.7289\n",
      "\n",
      " Train loss: 0.0006635187310166657 | Test loss: 1.1509  | Test acc: 0.7258\n",
      "\n",
      " Train loss: 0.000661804573610425 | Test loss: 1.1959  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.0006088522495701909 | Test loss: 1.1271  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0011158045381307602 | Test loss: 1.0285  | Test acc: 0.7448\n",
      "\n",
      " Train loss: 0.00018867725157178938 | Test loss: 1.0947  | Test acc: 0.7221\n",
      "\n",
      " Train loss: 0.00037918263114988804 | Test loss: 1.3094  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.0008278050809167325 | Test loss: 1.1960  | Test acc: 0.6952\n",
      "\n",
      " Train loss: 0.0008767303661443293 | Test loss: 0.9811  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0002495558583177626 | Test loss: 0.9811  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.000676260213367641 | Test loss: 1.0196  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0004187466111034155 | Test loss: 1.0831  | Test acc: 0.6857\n",
      "\n",
      " Train loss: 0.00046871151425875723 | Test loss: 0.9831  | Test acc: 0.7154\n",
      "\n",
      " Train loss: 0.00039183199987746775 | Test loss: 0.9057  | Test acc: 0.7423\n",
      "\n",
      " Train loss: 0.0003562500642146915 | Test loss: 0.8918  | Test acc: 0.7438\n",
      "\n",
      " Train loss: 0.0005605733604170382 | Test loss: 1.0219  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.000939686899073422 | Test loss: 0.9695  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.00042455256334505975 | Test loss: 0.9302  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0005109829944558442 | Test loss: 0.9298  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.0004092268936801702 | Test loss: 0.9381  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.00033566341153346 | Test loss: 1.0314  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.0005778954364359379 | Test loss: 0.9587  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0003522518090903759 | Test loss: 1.0245  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0004096807970199734 | Test loss: 0.9835  | Test acc: 0.7527\n",
      "\n",
      " Train loss: 0.0005440573440864682 | Test loss: 0.9077  | Test acc: 0.7654\n",
      "\n",
      " Train loss: 0.0003574497241061181 | Test loss: 0.9122  | Test acc: 0.7528\n",
      "\n",
      " Train loss: 0.0005766036338172853 | Test loss: 0.8784  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.0003014796820934862 | Test loss: 0.9407  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.0003431084915064275 | Test loss: 0.9930  | Test acc: 0.7162\n",
      "\n",
      " Train loss: 0.0003002100274898112 | Test loss: 1.0213  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.0009646790567785501 | Test loss: 0.8480  | Test acc: 0.7497\n",
      "\n",
      " Train loss: 0.0002466680889483541 | Test loss: 0.8731  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.00031499937176704407 | Test loss: 0.9520  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0005009930464439094 | Test loss: 0.9125  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.00042615123675204813 | Test loss: 0.8743  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.00055376545060426 | Test loss: 0.9076  | Test acc: 0.7302\n",
      "\n",
      " Train loss: 0.00045425078133121133 | Test loss: 0.8542  | Test acc: 0.7446\n",
      "\n",
      " Train loss: 0.0003687178250402212 | Test loss: 0.7919  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0007285499013960361 | Test loss: 0.7243  | Test acc: 0.7503\n",
      "\n",
      " Train loss: 0.0003405936586204916 | Test loss: 0.9016  | Test acc: 0.7067\n",
      "\n",
      " Train loss: 0.0004578380612656474 | Test loss: 0.8894  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0005223684129305184 | Test loss: 0.7764  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.00040566411917097867 | Test loss: 0.7891  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.00030590916867367923 | Test loss: 0.8650  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.00047602690756320953 | Test loss: 0.8393  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.00041487079579383135 | Test loss: 0.7996  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.00045295601012185216 | Test loss: 0.7773  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.0004210157203488052 | Test loss: 0.7876  | Test acc: 0.7561\n",
      "\n",
      " Train loss: 0.00026066708960570395 | Test loss: 0.7767  | Test acc: 0.7642\n",
      "\n",
      " Train loss: 0.0004745705518871546 | Test loss: 0.7384  | Test acc: 0.7695\n",
      "\n",
      " Train loss: 0.00037596301990561187 | Test loss: 0.7583  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0005265531945042312 | Test loss: 0.7321  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.00019860840984620154 | Test loss: 0.7310  | Test acc: 0.7666\n",
      "\n",
      " Train loss: 0.00025713848299346864 | Test loss: 0.7562  | Test acc: 0.7640\n",
      "\n",
      " Train loss: 0.00032216557883657515 | Test loss: 0.7493  | Test acc: 0.7691\n",
      "\n",
      " Train loss: 0.0004069709393661469 | Test loss: 0.7168  | Test acc: 0.7790\n",
      "\n",
      " Train loss: 0.0004395788419060409 | Test loss: 0.7431  | Test acc: 0.7768\n",
      "\n",
      " Train loss: 0.0004149031010456383 | Test loss: 0.7108  | Test acc: 0.7858\n",
      "\n",
      " Train loss: 0.00031472762930206954 | Test loss: 0.7076  | Test acc: 0.7856\n",
      "\n",
      " Train loss: 0.0002862990368157625 | Test loss: 0.7638  | Test acc: 0.7668\n",
      "\n",
      " Train loss: 0.0003200471692252904 | Test loss: 0.8616  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0005841591046191752 | Test loss: 0.8512  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.00043974583968520164 | Test loss: 0.7540  | Test acc: 0.7804\n",
      "\n",
      " Train loss: 0.00023859532666392624 | Test loss: 0.8240  | Test acc: 0.7765\n",
      "\n",
      " Train loss: 0.00034760357812047005 | Test loss: 0.9137  | Test acc: 0.7650\n",
      "\n",
      " Train loss: 0.0003459245490375906 | Test loss: 1.0556  | Test acc: 0.7327\n",
      "\n",
      " Train loss: 0.00038573265192098916 | Test loss: 0.9610  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0004684145387727767 | Test loss: 0.7798  | Test acc: 0.7919\n",
      "\n",
      " Train loss: 0.0003884164907503873 | Test loss: 0.7824  | Test acc: 0.7889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.00017046109132934362 | Test loss: 0.8435  | Test acc: 0.7750\n",
      "\n",
      " Train loss: 0.0002381417143624276 | Test loss: 0.8827  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0006230907165445387 | Test loss: 0.9693  | Test acc: 0.7552\n",
      "\n",
      " Train loss: 0.00048239051830023527 | Test loss: 0.9315  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0005882276454940438 | Test loss: 0.8122  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.0001930704602273181 | Test loss: 0.7739  | Test acc: 0.7786\n",
      "\n",
      " Train loss: 0.0006133306305855513 | Test loss: 0.7502  | Test acc: 0.7841\n",
      "\n",
      " Train loss: 0.0003014466492459178 | Test loss: 0.7592  | Test acc: 0.7847\n",
      "\n",
      " Train loss: 0.00026709449593909085 | Test loss: 0.8554  | Test acc: 0.7550\n",
      "\n",
      " Train loss: 0.0006826803437434137 | Test loss: 0.8330  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0003817073302343488 | Test loss: 0.8760  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.0003133418213110417 | Test loss: 0.9634  | Test acc: 0.7111\n",
      "\n",
      " Train loss: 0.0007490580319426954 | Test loss: 0.8316  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.00031581264920532703 | Test loss: 0.7584  | Test acc: 0.7471\n",
      "\n",
      " Train loss: 0.0004432562564034015 | Test loss: 0.7619  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0008751014829613268 | Test loss: 0.8698  | Test acc: 0.7428\n",
      "\n",
      " Train loss: 0.00031468356610275805 | Test loss: 0.9222  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.0003702740359585732 | Test loss: 0.9442  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0003655429754871875 | Test loss: 0.8813  | Test acc: 0.7328\n",
      "\n",
      " Train loss: 0.0007385020726360381 | Test loss: 0.8406  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0003642217197921127 | Test loss: 0.8343  | Test acc: 0.7352\n",
      "\n",
      " Train loss: 0.00040741966222412884 | Test loss: 0.8544  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.0005206839996390045 | Test loss: 0.7611  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.0003616772301029414 | Test loss: 0.7815  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.0008358994382433593 | Test loss: 0.9094  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0005786064430139959 | Test loss: 0.9075  | Test acc: 0.7659\n",
      "\n",
      " Train loss: 0.0005304907681420445 | Test loss: 0.7596  | Test acc: 0.7853\n",
      "\n",
      " Train loss: 0.00033773924224078655 | Test loss: 0.7015  | Test acc: 0.7879\n",
      "\n",
      " Train loss: 0.0002951869391836226 | Test loss: 0.7421  | Test acc: 0.7740\n",
      "\n",
      " Train loss: 0.0001559853262733668 | Test loss: 0.8499  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0004734185349661857 | Test loss: 0.8995  | Test acc: 0.7360\n",
      "\n",
      " Train loss: 0.0004088209825567901 | Test loss: 0.9677  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0006758656818419695 | Test loss: 0.9626  | Test acc: 0.7052\n",
      "\n",
      " Train loss: 0.0004776892310474068 | Test loss: 0.7549  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.00044327008072286844 | Test loss: 0.7185  | Test acc: 0.7812\n",
      "\n",
      " Train loss: 0.0003207469708286226 | Test loss: 0.8751  | Test acc: 0.7559\n",
      "\n",
      " Train loss: 0.000251639517955482 | Test loss: 1.0515  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0006689062574878335 | Test loss: 1.0814  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0006395598757080734 | Test loss: 0.9235  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.0004507499106694013 | Test loss: 0.9835  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.00029062098474241793 | Test loss: 1.2049  | Test acc: 0.7231\n",
      "\n",
      " Train loss: 0.0005898785893805325 | Test loss: 1.0547  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0003152479184791446 | Test loss: 0.8793  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.00035091632162220776 | Test loss: 1.0534  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.00038849571137689054 | Test loss: 1.2716  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.0005547091132029891 | Test loss: 1.3596  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.00012574350694194436 | Test loss: 1.5729  | Test acc: 0.6725\n",
      "\n",
      " Train loss: 0.0010611717589199543 | Test loss: 1.0720  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.0005908120656386018 | Test loss: 1.0595  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0005823386018164456 | Test loss: 1.3394  | Test acc: 0.6955\n",
      "\n",
      " Train loss: 0.0006331210606731474 | Test loss: 1.3442  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0006153443828225136 | Test loss: 0.9862  | Test acc: 0.7404\n",
      "\n",
      " Train loss: 0.0005442522815428674 | Test loss: 0.9128  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.00024233688600361347 | Test loss: 1.1893  | Test acc: 0.6856\n",
      "\n",
      " Train loss: 0.0004814915591850877 | Test loss: 1.1844  | Test acc: 0.6826\n",
      "\n",
      " Train loss: 0.0007403643685393035 | Test loss: 0.9133  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.00047724932665005326 | Test loss: 0.7858  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0009220030042342842 | Test loss: 0.8784  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.00022822176106274128 | Test loss: 1.2220  | Test acc: 0.6870\n",
      "\n",
      " Train loss: 0.00035224517341703176 | Test loss: 1.5026  | Test acc: 0.6635\n",
      "\n",
      " Train loss: 0.0005786899710074067 | Test loss: 1.3249  | Test acc: 0.6708\n",
      "\n",
      " Train loss: 0.0006538779125548899 | Test loss: 1.0318  | Test acc: 0.7054\n",
      "\n",
      " Train loss: 0.0006569972611032426 | Test loss: 1.1721  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0004096782358828932 | Test loss: 1.3375  | Test acc: 0.6842\n",
      "\n",
      " Train loss: 0.0005741318454965949 | Test loss: 1.3944  | Test acc: 0.6794\n",
      "\n",
      " Train loss: 0.0005221879691816866 | Test loss: 0.9390  | Test acc: 0.7260\n",
      "\n",
      " Train loss: 0.000337725825374946 | Test loss: 0.7537  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0003047272330150008 | Test loss: 0.8233  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.0005741054774262011 | Test loss: 0.9581  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.00039566008490510285 | Test loss: 1.1351  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.00036065050517208874 | Test loss: 1.2120  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.000751822255551815 | Test loss: 1.0189  | Test acc: 0.7124\n",
      "\n",
      " Train loss: 0.0005006151623092592 | Test loss: 0.9423  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.0002799603680614382 | Test loss: 0.8964  | Test acc: 0.7532\n",
      "\n",
      " Train loss: 0.00045851789764128625 | Test loss: 1.0184  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.00039639734313823283 | Test loss: 1.1507  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0007653236971236765 | Test loss: 0.9544  | Test acc: 0.7681\n",
      "\n",
      " Train loss: 0.0009309686720371246 | Test loss: 0.8612  | Test acc: 0.7824\n",
      "\n",
      " Train loss: 0.00037938871537335217 | Test loss: 0.8708  | Test acc: 0.7705\n",
      "\n",
      " Train loss: 0.0013495924649760127 | Test loss: 0.8520  | Test acc: 0.7662\n",
      "\n",
      " Train loss: 0.0007046998362056911 | Test loss: 0.8667  | Test acc: 0.7567\n",
      "\n",
      " Train loss: 0.00046878503053449094 | Test loss: 1.0573  | Test acc: 0.7088\n",
      "\n",
      " Train loss: 0.0004913224256597459 | Test loss: 1.0949  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.0007784024346619844 | Test loss: 0.9007  | Test acc: 0.7517\n",
      "\n",
      " Train loss: 0.00038273920654319227 | Test loss: 1.0665  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0011084171710535884 | Test loss: 0.9556  | Test acc: 0.7422\n",
      "\n",
      " Train loss: 0.000638857891317457 | Test loss: 1.0985  | Test acc: 0.7398\n",
      "\n",
      " Train loss: 0.0006338644889183342 | Test loss: 1.5467  | Test acc: 0.6631\n",
      "\n",
      " Train loss: 0.0009457030100747943 | Test loss: 1.2736  | Test acc: 0.6743\n",
      "\n",
      " Train loss: 0.000471155479317531 | Test loss: 1.0089  | Test acc: 0.7298\n",
      "\n",
      " Train loss: 0.0005724794464185834 | Test loss: 0.8670  | Test acc: 0.7699\n",
      "\n",
      " Train loss: 0.0005423861439339817 | Test loss: 0.9587  | Test acc: 0.7287\n",
      "\n",
      " Train loss: 0.0001577292860019952 | Test loss: 1.0803  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0005769205745309591 | Test loss: 1.0006  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.0006641244399361312 | Test loss: 1.2747  | Test acc: 0.7080\n",
      "\n",
      " Train loss: 0.0006522878538817167 | Test loss: 1.4433  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.000640856334939599 | Test loss: 1.4268  | Test acc: 0.6837\n",
      "\n",
      " Train loss: 0.00042993182432837784 | Test loss: 1.2527  | Test acc: 0.6788\n",
      "\n",
      " Train loss: 0.0006693567265756428 | Test loss: 1.0627  | Test acc: 0.7249\n",
      "\n",
      " Train loss: 0.0007950415019877255 | Test loss: 1.0736  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.000751835701521486 | Test loss: 1.1802  | Test acc: 0.6934\n",
      "\n",
      " Train loss: 0.001217768294736743 | Test loss: 1.0962  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.0007337242714129388 | Test loss: 0.9629  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.00024328897416125983 | Test loss: 1.1935  | Test acc: 0.6672\n",
      "\n",
      " Train loss: 0.0008250205428339541 | Test loss: 1.3460  | Test acc: 0.6292\n",
      "\n",
      " Train loss: 0.0009905470069497824 | Test loss: 1.5602  | Test acc: 0.6048\n",
      "\n",
      " Train loss: 0.0006972673581913114 | Test loss: 1.7480  | Test acc: 0.5918\n",
      "\n",
      " Train loss: 0.0007459759362973273 | Test loss: 1.2828  | Test acc: 0.6601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0009700926602818072 | Test loss: 1.0939  | Test acc: 0.7184\n",
      "\n",
      " Train loss: 0.0008057935629040003 | Test loss: 0.8736  | Test acc: 0.7554\n",
      "\n",
      " Train loss: 0.00038808814133517444 | Test loss: 1.0769  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.00033895025262609124 | Test loss: 1.3223  | Test acc: 0.6655\n",
      "\n",
      " Train loss: 0.0008529296610504389 | Test loss: 1.2521  | Test acc: 0.6895\n",
      "\n",
      " Train loss: 0.0004325333284214139 | Test loss: 1.5908  | Test acc: 0.6562\n",
      "\n",
      " Train loss: 0.0009367223829030991 | Test loss: 1.2733  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.0007642197888344526 | Test loss: 0.8988  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0005761075881309807 | Test loss: 0.8996  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0004942871164530516 | Test loss: 0.9408  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.0009423309238627553 | Test loss: 0.9431  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.00034747470635920763 | Test loss: 0.8676  | Test acc: 0.7653\n",
      "\n",
      " Train loss: 0.0006028579082340002 | Test loss: 0.8504  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.00013571362069342285 | Test loss: 0.9828  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.00039547556662000716 | Test loss: 1.1149  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.0003933820698875934 | Test loss: 1.2038  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.0006734566413797438 | Test loss: 1.0875  | Test acc: 0.7363\n",
      "\n",
      " Train loss: 0.000495786196552217 | Test loss: 1.1166  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.00048410712042823434 | Test loss: 1.1874  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0009659730130806565 | Test loss: 1.0684  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.0009218059713020921 | Test loss: 1.9001  | Test acc: 0.5911\n",
      "\n",
      " Train loss: 0.00114598183427006 | Test loss: 1.8742  | Test acc: 0.5905\n",
      "\n",
      " Train loss: 0.0006219460046850145 | Test loss: 1.2298  | Test acc: 0.6995\n",
      "\n",
      " Train loss: 0.0006833306979387999 | Test loss: 1.0927  | Test acc: 0.7536\n",
      "\n",
      " Train loss: 0.0007735759718343616 | Test loss: 1.2253  | Test acc: 0.7510\n",
      "\n",
      " Train loss: 0.0004516265180427581 | Test loss: 1.1980  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.00039596855640411377 | Test loss: 1.1648  | Test acc: 0.7360\n",
      "\n",
      " Train loss: 0.0003175127203576267 | Test loss: 1.0888  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.0002622492902446538 | Test loss: 1.0135  | Test acc: 0.7588\n",
      "\n",
      " Train loss: 0.00032026038388721645 | Test loss: 1.0342  | Test acc: 0.7386\n",
      "\n",
      " Train loss: 0.0004992284812033176 | Test loss: 0.9175  | Test acc: 0.7665\n",
      "\n",
      " Train loss: 0.0005083029391244054 | Test loss: 1.0298  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.000498071254696697 | Test loss: 0.8961  | Test acc: 0.7758\n",
      "\n",
      " Train loss: 0.0004352813120931387 | Test loss: 1.0953  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.0003633089945651591 | Test loss: 1.5150  | Test acc: 0.7039\n",
      "\n",
      " Train loss: 0.0005764816305600107 | Test loss: 1.3821  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.0005898806266486645 | Test loss: 1.4482  | Test acc: 0.6820\n",
      "\n",
      " Train loss: 0.0004965555272065103 | Test loss: 1.5384  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.0012116957223042846 | Test loss: 1.1910  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.0008980956044979393 | Test loss: 1.7685  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.0012256756890565157 | Test loss: 1.8256  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0012598371831700206 | Test loss: 1.3159  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.001096842112019658 | Test loss: 1.4577  | Test acc: 0.6726\n",
      "\n",
      " Train loss: 0.0008841195376589894 | Test loss: 2.2117  | Test acc: 0.6310\n",
      "\n",
      " Train loss: 0.0008935004589147866 | Test loss: 1.8885  | Test acc: 0.6207\n",
      "\n",
      " Train loss: 0.0006712378235533834 | Test loss: 1.6939  | Test acc: 0.6865\n",
      "\n",
      " Train loss: 0.0009964125929400325 | Test loss: 1.8043  | Test acc: 0.6938\n",
      "\n",
      " Train loss: 0.0012974601704627275 | Test loss: 1.5529  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0010146757122129202 | Test loss: 1.3375  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.00020277831936255097 | Test loss: 2.6023  | Test acc: 0.5792\n",
      "\n",
      " Train loss: 0.0010004888754338026 | Test loss: 2.9349  | Test acc: 0.5965\n",
      "\n",
      " Train loss: 0.0008657131693325937 | Test loss: 3.3580  | Test acc: 0.5823\n",
      "\n",
      " Train loss: 0.0019013804849237204 | Test loss: 3.0515  | Test acc: 0.6068\n",
      "\n",
      " Train loss: 0.0017270343378186226 | Test loss: 1.7686  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.0009372131316922605 | Test loss: 2.4435  | Test acc: 0.6712\n",
      "\n",
      " Train loss: 0.0014479567762464285 | Test loss: 2.7938  | Test acc: 0.6416\n",
      "\n",
      " Train loss: 0.0014101315755397081 | Test loss: 2.2691  | Test acc: 0.6645\n",
      "\n",
      " Train loss: 0.0008207038627006114 | Test loss: 1.7714  | Test acc: 0.6709\n",
      "\n",
      " Train loss: 0.0006021897424943745 | Test loss: 1.8318  | Test acc: 0.6887\n",
      "\n",
      " Train loss: 0.0004754036490339786 | Test loss: 2.9142  | Test acc: 0.6012\n",
      "\n",
      " Train loss: 0.0005029114545322955 | Test loss: 3.7428  | Test acc: 0.5329\n",
      "\n",
      " Train loss: 0.002262474037706852 | Test loss: 2.7406  | Test acc: 0.6220\n",
      "\n",
      " Train loss: 0.0005973131046630442 | Test loss: 2.6459  | Test acc: 0.6735\n",
      "\n",
      " Train loss: 0.0003525877255015075 | Test loss: 3.8459  | Test acc: 0.6281\n",
      "\n",
      " Train loss: 0.001957286149263382 | Test loss: 3.3409  | Test acc: 0.6824\n",
      "\n",
      " Train loss: 0.0016509277047589421 | Test loss: 2.4960  | Test acc: 0.6908\n",
      "\n",
      " Train loss: 0.001971242716535926 | Test loss: 3.2156  | Test acc: 0.6563\n",
      "\n",
      " Train loss: 0.0018159671453759074 | Test loss: 4.2482  | Test acc: 0.6701\n",
      "\n",
      " Train loss: 0.0014296667650341988 | Test loss: 4.5821  | Test acc: 0.6577\n",
      "\n",
      " Train loss: 0.0030598852317780256 | Test loss: 2.7718  | Test acc: 0.6694\n",
      "\n",
      " Train loss: 0.0015232713194563985 | Test loss: 1.7556  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.0011945845326408744 | Test loss: 2.0558  | Test acc: 0.7033\n",
      "\n",
      " Train loss: 0.0013650580076500773 | Test loss: 2.3920  | Test acc: 0.6301\n",
      "\n",
      " Train loss: 0.0009769225725904107 | Test loss: 3.6334  | Test acc: 0.5197\n",
      "\n",
      " Train loss: 0.002383120357990265 | Test loss: 3.8581  | Test acc: 0.6173\n",
      "\n",
      " Train loss: 0.0014385349350050092 | Test loss: 4.5458  | Test acc: 0.6585\n",
      "Looked at 12800/ 60000 samples\n",
      "\n",
      " Train loss: 0.0033149158116430044 | Test loss: 2.5974  | Test acc: 0.6761\n",
      "\n",
      " Train loss: 0.0015348015585914254 | Test loss: 3.1585  | Test acc: 0.6174\n",
      "\n",
      " Train loss: 0.0020136581733822823 | Test loss: 2.9670  | Test acc: 0.6560\n",
      "\n",
      " Train loss: 0.0020428397692739964 | Test loss: 3.4206  | Test acc: 0.5861\n",
      "\n",
      " Train loss: 0.002551463432610035 | Test loss: 2.7474  | Test acc: 0.6482\n",
      "\n",
      " Train loss: 0.001416763523593545 | Test loss: 2.3030  | Test acc: 0.6724\n",
      "\n",
      " Train loss: 0.0008738220785744488 | Test loss: 2.7324  | Test acc: 0.6417\n",
      "\n",
      " Train loss: 0.0015206834068521857 | Test loss: 3.1439  | Test acc: 0.6494\n",
      "\n",
      " Train loss: 0.001327542238868773 | Test loss: 2.4967  | Test acc: 0.6867\n",
      "\n",
      " Train loss: 0.0014515096554532647 | Test loss: 3.3378  | Test acc: 0.6706\n",
      "\n",
      " Train loss: 0.0017232983373105526 | Test loss: 6.6810  | Test acc: 0.5189\n",
      "\n",
      " Train loss: 0.00357380835339427 | Test loss: 6.2974  | Test acc: 0.4753\n",
      "\n",
      " Train loss: 0.0033425348810851574 | Test loss: 4.7399  | Test acc: 0.5488\n",
      "\n",
      " Train loss: 0.002783305710181594 | Test loss: 2.6198  | Test acc: 0.6683\n",
      "\n",
      " Train loss: 0.00222350237891078 | Test loss: 3.9520  | Test acc: 0.5977\n",
      "\n",
      " Train loss: 0.0013626266736537218 | Test loss: 5.2731  | Test acc: 0.5893\n",
      "\n",
      " Train loss: 0.0014741254271939397 | Test loss: 5.2047  | Test acc: 0.6109\n",
      "\n",
      " Train loss: 0.003345419419929385 | Test loss: 4.1236  | Test acc: 0.6246\n",
      "\n",
      " Train loss: 0.0009907253552228212 | Test loss: 2.9923  | Test acc: 0.6291\n",
      "\n",
      " Train loss: 0.0016408050432801247 | Test loss: 3.4871  | Test acc: 0.6131\n",
      "\n",
      " Train loss: 0.00194664450827986 | Test loss: 5.1564  | Test acc: 0.5547\n",
      "\n",
      " Train loss: 0.0034627236891537905 | Test loss: 3.8508  | Test acc: 0.5313\n",
      "\n",
      " Train loss: 0.0015844590961933136 | Test loss: 3.4928  | Test acc: 0.5659\n",
      "\n",
      " Train loss: 0.0020840114448219538 | Test loss: 3.9711  | Test acc: 0.5858\n",
      "\n",
      " Train loss: 0.0015495914267376065 | Test loss: 4.0228  | Test acc: 0.6004\n",
      "\n",
      " Train loss: 0.0010728356428444386 | Test loss: 5.3864  | Test acc: 0.5732\n",
      "\n",
      " Train loss: 0.003053084248676896 | Test loss: 3.1147  | Test acc: 0.6657\n",
      "\n",
      " Train loss: 0.0005921813426539302 | Test loss: 3.0915  | Test acc: 0.6735\n",
      "\n",
      " Train loss: 0.0018204187508672476 | Test loss: 2.7811  | Test acc: 0.6950\n",
      "\n",
      " Train loss: 0.002031231764703989 | Test loss: 3.6842  | Test acc: 0.6448\n",
      "\n",
      " Train loss: 0.0018934234976768494 | Test loss: 5.6485  | Test acc: 0.5742\n",
      "\n",
      " Train loss: 0.0032465257681906223 | Test loss: 2.9274  | Test acc: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0012982129119336605 | Test loss: 3.1339  | Test acc: 0.6832\n",
      "\n",
      " Train loss: 0.0019010597607120872 | Test loss: 3.0861  | Test acc: 0.6724\n",
      "\n",
      " Train loss: 0.0015059313736855984 | Test loss: 3.3409  | Test acc: 0.6746\n",
      "\n",
      " Train loss: 0.0015069895889610052 | Test loss: 2.9518  | Test acc: 0.6999\n",
      "\n",
      " Train loss: 0.0017575387610122561 | Test loss: 3.0714  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.0015799235552549362 | Test loss: 4.1554  | Test acc: 0.6507\n",
      "\n",
      " Train loss: 0.0035936019849032164 | Test loss: 4.6873  | Test acc: 0.6134\n",
      "\n",
      " Train loss: 0.0035145985893905163 | Test loss: 2.9621  | Test acc: 0.6722\n",
      "\n",
      " Train loss: 0.0013911022106185555 | Test loss: 3.6716  | Test acc: 0.6731\n",
      "\n",
      " Train loss: 0.0018011396750807762 | Test loss: 6.2303  | Test acc: 0.6123\n",
      "\n",
      " Train loss: 0.0019422731129452586 | Test loss: 6.6313  | Test acc: 0.6280\n",
      "\n",
      " Train loss: 0.0012758029624819756 | Test loss: 6.2192  | Test acc: 0.6687\n",
      "\n",
      " Train loss: 0.0024536254350095987 | Test loss: 4.9957  | Test acc: 0.6629\n",
      "\n",
      " Train loss: 0.0024151550605893135 | Test loss: 4.8438  | Test acc: 0.5732\n",
      "\n",
      " Train loss: 0.0024603214114904404 | Test loss: 3.9057  | Test acc: 0.6020\n",
      "\n",
      " Train loss: 0.002042749896645546 | Test loss: 3.6169  | Test acc: 0.5779\n",
      "\n",
      " Train loss: 0.0007464283844456077 | Test loss: 3.4029  | Test acc: 0.6021\n",
      "\n",
      " Train loss: 0.001293435343541205 | Test loss: 2.8397  | Test acc: 0.6501\n",
      "\n",
      " Train loss: 0.00199696933850646 | Test loss: 2.9231  | Test acc: 0.6684\n",
      "\n",
      " Train loss: 0.0011202930472791195 | Test loss: 2.5554  | Test acc: 0.6794\n",
      "\n",
      " Train loss: 0.0010530127910897136 | Test loss: 2.2356  | Test acc: 0.6728\n",
      "\n",
      " Train loss: 0.0007561784004792571 | Test loss: 2.9340  | Test acc: 0.6189\n",
      "\n",
      " Train loss: 0.0010062200017273426 | Test loss: 4.9515  | Test acc: 0.5385\n",
      "\n",
      " Train loss: 0.003006923943758011 | Test loss: 4.0675  | Test acc: 0.5893\n",
      "\n",
      " Train loss: 0.0009152557468041778 | Test loss: 3.2766  | Test acc: 0.6473\n",
      "\n",
      " Train loss: 0.0022539477795362473 | Test loss: 2.1852  | Test acc: 0.7205\n",
      "\n",
      " Train loss: 0.0029230534564703703 | Test loss: 2.5753  | Test acc: 0.7091\n",
      "\n",
      " Train loss: 0.0011992804938927293 | Test loss: 3.4837  | Test acc: 0.6533\n",
      "\n",
      " Train loss: 0.002013055607676506 | Test loss: 4.0188  | Test acc: 0.6249\n",
      "\n",
      " Train loss: 0.002940477803349495 | Test loss: 2.9562  | Test acc: 0.7093\n",
      "\n",
      " Train loss: 0.0011421872768551111 | Test loss: 2.9417  | Test acc: 0.6878\n",
      "\n",
      " Train loss: 0.0009763350826688111 | Test loss: 3.3399  | Test acc: 0.6414\n",
      "\n",
      " Train loss: 0.0017796923639252782 | Test loss: 2.2886  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.0011496954830363393 | Test loss: 2.4640  | Test acc: 0.6917\n",
      "\n",
      " Train loss: 0.0013477082829922438 | Test loss: 3.0055  | Test acc: 0.6624\n",
      "\n",
      " Train loss: 0.0006694540497846901 | Test loss: 3.2320  | Test acc: 0.6578\n",
      "\n",
      " Train loss: 0.0012191509595140815 | Test loss: 2.6884  | Test acc: 0.6696\n",
      "\n",
      " Train loss: 0.0013795364648103714 | Test loss: 2.9948  | Test acc: 0.6199\n",
      "\n",
      " Train loss: 0.001022350275889039 | Test loss: 4.1587  | Test acc: 0.6169\n",
      "\n",
      " Train loss: 0.0027431745547801256 | Test loss: 4.2271  | Test acc: 0.6143\n",
      "\n",
      " Train loss: 0.0026366666425019503 | Test loss: 4.6893  | Test acc: 0.5565\n",
      "\n",
      " Train loss: 0.0035757622681558132 | Test loss: 3.8483  | Test acc: 0.6111\n",
      "\n",
      " Train loss: 0.0027337258215993643 | Test loss: 2.7037  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.001152417273260653 | Test loss: 2.3411  | Test acc: 0.6987\n",
      "\n",
      " Train loss: 0.0014655704144388437 | Test loss: 3.1589  | Test acc: 0.6556\n",
      "\n",
      " Train loss: 0.0017712865956127644 | Test loss: 3.0263  | Test acc: 0.6691\n",
      "\n",
      " Train loss: 0.0018209611298516393 | Test loss: 2.6477  | Test acc: 0.6854\n",
      "\n",
      " Train loss: 0.0008540040580555797 | Test loss: 2.9379  | Test acc: 0.6444\n",
      "\n",
      " Train loss: 0.0007188815507106483 | Test loss: 3.8265  | Test acc: 0.5960\n",
      "\n",
      " Train loss: 0.0017895465716719627 | Test loss: 2.1209  | Test acc: 0.7046\n",
      "\n",
      " Train loss: 0.0007058265618979931 | Test loss: 2.7219  | Test acc: 0.6353\n",
      "\n",
      " Train loss: 0.0020717771258205175 | Test loss: 2.9942  | Test acc: 0.6437\n",
      "\n",
      " Train loss: 0.001814675284549594 | Test loss: 3.1387  | Test acc: 0.6408\n",
      "\n",
      " Train loss: 0.0009066404891200364 | Test loss: 3.4328  | Test acc: 0.6493\n",
      "\n",
      " Train loss: 0.0026473919861018658 | Test loss: 4.4976  | Test acc: 0.6186\n",
      "\n",
      " Train loss: 0.0021748682484030724 | Test loss: 3.2933  | Test acc: 0.6224\n",
      "\n",
      " Train loss: 0.0019595406483858824 | Test loss: 3.4944  | Test acc: 0.5862\n",
      "\n",
      " Train loss: 0.0017023301916196942 | Test loss: 3.3502  | Test acc: 0.6353\n",
      "\n",
      " Train loss: 0.0017009114380925894 | Test loss: 4.4007  | Test acc: 0.6253\n",
      "\n",
      " Train loss: 0.003403096692636609 | Test loss: 4.2517  | Test acc: 0.6217\n",
      "\n",
      " Train loss: 0.0027308461721986532 | Test loss: 4.5110  | Test acc: 0.5962\n",
      "\n",
      " Train loss: 0.002638735342770815 | Test loss: 4.0311  | Test acc: 0.5820\n",
      "\n",
      " Train loss: 0.0010015723528340459 | Test loss: 4.6467  | Test acc: 0.5769\n",
      "\n",
      " Train loss: 0.004393025301396847 | Test loss: 2.9934  | Test acc: 0.6511\n",
      "\n",
      " Train loss: 0.0012991910334676504 | Test loss: 3.6805  | Test acc: 0.6255\n",
      "\n",
      " Train loss: 0.0010100639192387462 | Test loss: 5.2642  | Test acc: 0.5742\n",
      "\n",
      " Train loss: 0.0032476051710546017 | Test loss: 4.3525  | Test acc: 0.6126\n",
      "\n",
      " Train loss: 0.0024264755193144083 | Test loss: 3.4804  | Test acc: 0.5981\n",
      "\n",
      " Train loss: 0.0016460870392620564 | Test loss: 3.8996  | Test acc: 0.5825\n",
      "\n",
      " Train loss: 0.0028689270839095116 | Test loss: 3.4531  | Test acc: 0.6448\n",
      "\n",
      " Train loss: 0.0012003171723335981 | Test loss: 3.7989  | Test acc: 0.6713\n",
      "\n",
      " Train loss: 0.002868431620299816 | Test loss: 2.6004  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0007322279852814972 | Test loss: 3.7202  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.002110357629135251 | Test loss: 4.2974  | Test acc: 0.6993\n",
      "\n",
      " Train loss: 0.0011563339503481984 | Test loss: 4.4749  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.002433049725368619 | Test loss: 4.0541  | Test acc: 0.6863\n",
      "\n",
      " Train loss: 0.0014305938966572285 | Test loss: 3.5167  | Test acc: 0.6978\n",
      "\n",
      " Train loss: 0.001841527409851551 | Test loss: 3.9564  | Test acc: 0.6602\n",
      "\n",
      " Train loss: 0.0024316732306033373 | Test loss: 3.1488  | Test acc: 0.6973\n",
      "\n",
      " Train loss: 0.002439776435494423 | Test loss: 3.2608  | Test acc: 0.6927\n",
      "\n",
      " Train loss: 0.0018163673812523484 | Test loss: 3.9165  | Test acc: 0.6771\n",
      "\n",
      " Train loss: 0.001185916131362319 | Test loss: 4.6908  | Test acc: 0.6537\n",
      "\n",
      " Train loss: 0.0011730504920706153 | Test loss: 4.8420  | Test acc: 0.6569\n",
      "\n",
      " Train loss: 0.0030459065455943346 | Test loss: 2.7631  | Test acc: 0.7358\n",
      "\n",
      " Train loss: 0.0012012524530291557 | Test loss: 3.3218  | Test acc: 0.6804\n",
      "\n",
      " Train loss: 0.0010289683705195785 | Test loss: 4.4495  | Test acc: 0.6091\n",
      "\n",
      " Train loss: 0.002200912917032838 | Test loss: 5.5984  | Test acc: 0.5906\n",
      "\n",
      " Train loss: 0.0035687454510480165 | Test loss: 3.4764  | Test acc: 0.6629\n",
      "\n",
      " Train loss: 0.00281124678440392 | Test loss: 3.5557  | Test acc: 0.6776\n",
      "\n",
      " Train loss: 0.002074324991554022 | Test loss: 3.8325  | Test acc: 0.6806\n",
      "\n",
      " Train loss: 0.0014173637609928846 | Test loss: 4.2032  | Test acc: 0.6731\n",
      "\n",
      " Train loss: 0.002692234003916383 | Test loss: 3.9852  | Test acc: 0.6704\n",
      "\n",
      " Train loss: 0.00371170393191278 | Test loss: 3.5798  | Test acc: 0.6981\n",
      "\n",
      " Train loss: 0.0019629260059446096 | Test loss: 4.1903  | Test acc: 0.6881\n",
      "\n",
      " Train loss: 0.004219823516905308 | Test loss: 2.3044  | Test acc: 0.7577\n",
      "\n",
      " Train loss: 0.001978363608941436 | Test loss: 2.8690  | Test acc: 0.7273\n",
      "\n",
      " Train loss: 0.001492905430495739 | Test loss: 5.0059  | Test acc: 0.6250\n",
      "\n",
      " Train loss: 0.003153441706672311 | Test loss: 5.1998  | Test acc: 0.6011\n",
      "\n",
      " Train loss: 0.00189372175373137 | Test loss: 6.0446  | Test acc: 0.5807\n",
      "\n",
      " Train loss: 0.002332099713385105 | Test loss: 4.7839  | Test acc: 0.6001\n",
      "\n",
      " Train loss: 0.002631179289892316 | Test loss: 3.6523  | Test acc: 0.6522\n",
      "\n",
      " Train loss: 0.002873121527954936 | Test loss: 3.6621  | Test acc: 0.6514\n",
      "\n",
      " Train loss: 0.0053009591065347195 | Test loss: 3.3569  | Test acc: 0.6790\n",
      "\n",
      " Train loss: 0.00199092086404562 | Test loss: 5.1094  | Test acc: 0.6348\n",
      "\n",
      " Train loss: 0.0015597549499943852 | Test loss: 8.1935  | Test acc: 0.5967\n",
      "\n",
      " Train loss: 0.006415567826479673 | Test loss: 6.7336  | Test acc: 0.6257\n",
      "\n",
      " Train loss: 0.0026732091791927814 | Test loss: 6.9705  | Test acc: 0.5759\n",
      "\n",
      " Train loss: 0.003096087370067835 | Test loss: 5.2089  | Test acc: 0.6017\n",
      "\n",
      " Train loss: 0.0027251162100583315 | Test loss: 5.4445  | Test acc: 0.6599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0027684196829795837 | Test loss: 6.7518  | Test acc: 0.6371\n",
      "\n",
      " Train loss: 0.0021955547854304314 | Test loss: 6.9477  | Test acc: 0.6244\n",
      "\n",
      " Train loss: 0.003407633863389492 | Test loss: 4.0519  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0013488417025655508 | Test loss: 2.9400  | Test acc: 0.7625\n",
      "\n",
      " Train loss: 0.000685904873535037 | Test loss: 4.1880  | Test acc: 0.7097\n",
      "\n",
      " Train loss: 0.002207714132964611 | Test loss: 5.3672  | Test acc: 0.6660\n",
      "\n",
      " Train loss: 0.0012743870029225945 | Test loss: 5.6957  | Test acc: 0.6791\n",
      "\n",
      " Train loss: 0.0026926822029054165 | Test loss: 6.1400  | Test acc: 0.6053\n",
      "\n",
      " Train loss: 0.003195414552465081 | Test loss: 3.3038  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.0017240369925275445 | Test loss: 5.6464  | Test acc: 0.6692\n",
      "\n",
      " Train loss: 0.0019647248554974794 | Test loss: 9.4139  | Test acc: 0.5733\n",
      "\n",
      " Train loss: 0.0024336869828402996 | Test loss: 6.9244  | Test acc: 0.6422\n",
      "\n",
      " Train loss: 0.003639552276581526 | Test loss: 4.7587  | Test acc: 0.7001\n",
      "\n",
      " Train loss: 0.005263940431177616 | Test loss: 4.8161  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0037540276534855366 | Test loss: 6.6318  | Test acc: 0.6378\n",
      "\n",
      " Train loss: 0.001291417283937335 | Test loss: 7.6079  | Test acc: 0.6610\n",
      "\n",
      " Train loss: 0.004585122223943472 | Test loss: 7.2970  | Test acc: 0.6666\n",
      "\n",
      " Train loss: 0.004564434289932251 | Test loss: 6.8594  | Test acc: 0.6461\n",
      "\n",
      " Train loss: 0.0012446094769984484 | Test loss: 6.2081  | Test acc: 0.6770\n",
      "\n",
      " Train loss: 0.0036657252348959446 | Test loss: 5.1144  | Test acc: 0.7174\n",
      "\n",
      " Train loss: 0.002247316064313054 | Test loss: 5.8660  | Test acc: 0.6835\n",
      "\n",
      " Train loss: 0.0036415359936654568 | Test loss: 8.3164  | Test acc: 0.5970\n",
      "\n",
      " Train loss: 0.0031474458519369364 | Test loss: 8.2523  | Test acc: 0.6401\n",
      "\n",
      " Train loss: 0.00315825711004436 | Test loss: 7.4822  | Test acc: 0.6601\n",
      "\n",
      " Train loss: 0.0020075261127203703 | Test loss: 10.1369  | Test acc: 0.5944\n",
      "\n",
      " Train loss: 0.005174754653126001 | Test loss: 9.9964  | Test acc: 0.5343\n",
      "\n",
      " Train loss: 0.0072570242919027805 | Test loss: 6.2988  | Test acc: 0.6259\n",
      "\n",
      " Train loss: 0.004281307104974985 | Test loss: 5.7452  | Test acc: 0.6579\n",
      "\n",
      " Train loss: 0.003635840490460396 | Test loss: 9.7840  | Test acc: 0.5750\n",
      "\n",
      " Train loss: 0.004156543407589197 | Test loss: 8.7857  | Test acc: 0.5948\n",
      "\n",
      " Train loss: 0.00351711711846292 | Test loss: 5.6259  | Test acc: 0.6816\n",
      "\n",
      " Train loss: 0.0014862981624901295 | Test loss: 7.2824  | Test acc: 0.6217\n",
      "\n",
      " Train loss: 0.00379294715821743 | Test loss: 9.1097  | Test acc: 0.5669\n",
      "\n",
      " Train loss: 0.004526464268565178 | Test loss: 7.8355  | Test acc: 0.5860\n",
      "\n",
      " Train loss: 0.00376716535538435 | Test loss: 6.8514  | Test acc: 0.6336\n",
      "\n",
      " Train loss: 0.0036415786016732454 | Test loss: 5.1055  | Test acc: 0.6895\n",
      "\n",
      " Train loss: 0.0009848555782809854 | Test loss: 5.8180  | Test acc: 0.6517\n",
      "\n",
      " Train loss: 0.0022669213358312845 | Test loss: 6.8561  | Test acc: 0.6715\n",
      "\n",
      " Train loss: 0.005408414173871279 | Test loss: 6.7345  | Test acc: 0.6958\n",
      "\n",
      " Train loss: 0.002995452145114541 | Test loss: 5.4943  | Test acc: 0.7224\n",
      "\n",
      " Train loss: 0.0040891519747674465 | Test loss: 4.6982  | Test acc: 0.7095\n",
      "\n",
      " Train loss: 0.0020753610879182816 | Test loss: 7.2107  | Test acc: 0.6298\n",
      "\n",
      " Train loss: 0.005938618443906307 | Test loss: 7.0094  | Test acc: 0.6352\n",
      "\n",
      " Train loss: 0.003457865444943309 | Test loss: 5.4980  | Test acc: 0.6670\n",
      "\n",
      " Train loss: 0.003718254854902625 | Test loss: 4.9291  | Test acc: 0.6904\n",
      "\n",
      " Train loss: 0.0014678648440167308 | Test loss: 5.1126  | Test acc: 0.6899\n",
      "\n",
      " Train loss: 0.0010536662302911282 | Test loss: 5.4092  | Test acc: 0.6955\n",
      "\n",
      " Train loss: 0.0021959207952022552 | Test loss: 5.9320  | Test acc: 0.6814\n",
      "\n",
      " Train loss: 0.009777046740055084 | Test loss: 6.5995  | Test acc: 0.6615\n",
      "\n",
      " Train loss: 0.00273919478058815 | Test loss: 6.3961  | Test acc: 0.6652\n",
      "\n",
      " Train loss: 0.005047680344432592 | Test loss: 5.9911  | Test acc: 0.6659\n",
      "\n",
      " Train loss: 0.0029369278345257044 | Test loss: 6.4041  | Test acc: 0.6378\n",
      "\n",
      " Train loss: 0.0018999368185177445 | Test loss: 5.6770  | Test acc: 0.6124\n",
      "\n",
      " Train loss: 0.002214950043708086 | Test loss: 5.5286  | Test acc: 0.6366\n",
      "\n",
      " Train loss: 0.001976274885237217 | Test loss: 4.8535  | Test acc: 0.6520\n",
      "\n",
      " Train loss: 0.00298923347145319 | Test loss: 4.7829  | Test acc: 0.6670\n",
      "\n",
      " Train loss: 0.002975932089611888 | Test loss: 6.5653  | Test acc: 0.6155\n",
      "\n",
      " Train loss: 0.0036410789471119642 | Test loss: 5.9982  | Test acc: 0.6172\n",
      "\n",
      " Train loss: 0.00223642960190773 | Test loss: 5.2247  | Test acc: 0.6024\n",
      "\n",
      " Train loss: 0.0020777289755642414 | Test loss: 6.0296  | Test acc: 0.6029\n",
      "\n",
      " Train loss: 0.0020534065552055836 | Test loss: 6.6952  | Test acc: 0.5983\n",
      "\n",
      " Train loss: 0.0016683766152709723 | Test loss: 5.4555  | Test acc: 0.6428\n",
      "\n",
      " Train loss: 0.0021039603743702173 | Test loss: 4.8148  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.0010434524156153202 | Test loss: 4.7458  | Test acc: 0.6860\n",
      "\n",
      " Train loss: 0.00092685641720891 | Test loss: 4.5521  | Test acc: 0.6879\n",
      "\n",
      " Train loss: 0.002229367382824421 | Test loss: 4.0293  | Test acc: 0.7026\n",
      "\n",
      " Train loss: 0.00425426010042429 | Test loss: 3.9448  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.0045686932280659676 | Test loss: 3.6327  | Test acc: 0.7036\n",
      "\n",
      " Train loss: 0.0024709973949939013 | Test loss: 3.9400  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.002894221805036068 | Test loss: 4.1435  | Test acc: 0.6904\n",
      "\n",
      " Train loss: 0.0009687872952781618 | Test loss: 4.8358  | Test acc: 0.6583\n",
      "\n",
      " Train loss: 0.002763504395261407 | Test loss: 4.3743  | Test acc: 0.6345\n",
      "\n",
      " Train loss: 0.00405686954036355 | Test loss: 4.6878  | Test acc: 0.6186\n",
      "\n",
      " Train loss: 0.0021698628552258015 | Test loss: 7.2097  | Test acc: 0.5649\n",
      "\n",
      " Train loss: 0.003767103422433138 | Test loss: 7.5318  | Test acc: 0.5626\n",
      "\n",
      " Train loss: 0.004396173171699047 | Test loss: 4.3041  | Test acc: 0.6876\n",
      "\n",
      " Train loss: 0.001644355128519237 | Test loss: 3.7510  | Test acc: 0.7198\n",
      "\n",
      " Train loss: 0.0010334535036236048 | Test loss: 4.7476  | Test acc: 0.6702\n",
      "\n",
      " Train loss: 0.005216325167566538 | Test loss: 5.3738  | Test acc: 0.6237\n",
      "\n",
      " Train loss: 0.0028142756782472134 | Test loss: 4.7037  | Test acc: 0.6627\n",
      "\n",
      " Train loss: 0.002401426201686263 | Test loss: 3.2662  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.001811426947824657 | Test loss: 2.5183  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.0014303828356787562 | Test loss: 2.9709  | Test acc: 0.6817\n",
      "\n",
      " Train loss: 0.001865921774879098 | Test loss: 4.6717  | Test acc: 0.6165\n",
      "\n",
      " Train loss: 0.0032032050658017397 | Test loss: 4.4808  | Test acc: 0.6053\n",
      "\n",
      " Train loss: 0.0026596132665872574 | Test loss: 2.8980  | Test acc: 0.6857\n",
      "\n",
      " Train loss: 0.0022083090152591467 | Test loss: 4.0672  | Test acc: 0.6308\n",
      "\n",
      " Train loss: 0.0027741757221519947 | Test loss: 3.0755  | Test acc: 0.6749\n",
      "\n",
      " Train loss: 0.003017406677827239 | Test loss: 2.7712  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.0010698894038796425 | Test loss: 4.9943  | Test acc: 0.6313\n",
      "\n",
      " Train loss: 0.002524336101487279 | Test loss: 4.9606  | Test acc: 0.6474\n",
      "\n",
      " Train loss: 0.001370809506624937 | Test loss: 4.4872  | Test acc: 0.6604\n",
      "\n",
      " Train loss: 0.0024889600463211536 | Test loss: 4.5267  | Test acc: 0.6143\n",
      "\n",
      " Train loss: 0.0021391932386904955 | Test loss: 4.1965  | Test acc: 0.5630\n",
      "\n",
      " Train loss: 0.0014532927889376879 | Test loss: 3.4865  | Test acc: 0.6179\n",
      "\n",
      " Train loss: 0.0017821247456595302 | Test loss: 2.4488  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.0018644093070179224 | Test loss: 2.3457  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0011194616090506315 | Test loss: 3.1842  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.0029266979545354843 | Test loss: 3.3748  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.001998694147914648 | Test loss: 3.0262  | Test acc: 0.7150\n",
      "\n",
      " Train loss: 0.0009080219315364957 | Test loss: 2.6973  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.0033785535488277674 | Test loss: 2.6432  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.0010809305822476745 | Test loss: 2.5865  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0008047186420299113 | Test loss: 2.7484  | Test acc: 0.6991\n",
      "\n",
      " Train loss: 0.000719639181625098 | Test loss: 2.6406  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.0016438146121799946 | Test loss: 3.0901  | Test acc: 0.6960\n",
      "\n",
      " Train loss: 0.002218737732619047 | Test loss: 3.4648  | Test acc: 0.6847\n",
      "\n",
      " Train loss: 0.0013732429360970855 | Test loss: 3.4790  | Test acc: 0.6933\n",
      "\n",
      " Train loss: 0.0017797762993723154 | Test loss: 2.9405  | Test acc: 0.7073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.000409277796279639 | Test loss: 2.4660  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.001774374395608902 | Test loss: 2.3530  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0012039606226608157 | Test loss: 2.9599  | Test acc: 0.6821\n",
      "\n",
      " Train loss: 0.003026555525138974 | Test loss: 3.0754  | Test acc: 0.6641\n",
      "\n",
      " Train loss: 0.0017693060217425227 | Test loss: 2.5805  | Test acc: 0.6874\n",
      "\n",
      " Train loss: 0.0014063541311770678 | Test loss: 3.0750  | Test acc: 0.6791\n",
      "\n",
      " Train loss: 0.0011943666031584144 | Test loss: 2.8302  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.0007730142679065466 | Test loss: 2.4835  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.000525232928339392 | Test loss: 2.4238  | Test acc: 0.7163\n",
      "\n",
      " Train loss: 0.0013009578688070178 | Test loss: 3.4751  | Test acc: 0.6388\n",
      "\n",
      " Train loss: 0.0014120350824669003 | Test loss: 3.0091  | Test acc: 0.6774\n",
      "\n",
      " Train loss: 0.0010306912008672953 | Test loss: 2.6737  | Test acc: 0.7034\n",
      "\n",
      " Train loss: 0.0010697755496948957 | Test loss: 2.3687  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.0031327386386692524 | Test loss: 2.7016  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0016365511110052466 | Test loss: 3.0112  | Test acc: 0.6994\n",
      "\n",
      " Train loss: 0.0010691569186747074 | Test loss: 2.9939  | Test acc: 0.6976\n",
      "\n",
      " Train loss: 0.0019310667412355542 | Test loss: 2.2264  | Test acc: 0.7441\n",
      "\n",
      " Train loss: 0.0013763541355729103 | Test loss: 2.0803  | Test acc: 0.7551\n",
      "\n",
      " Train loss: 0.001902524963952601 | Test loss: 2.3503  | Test acc: 0.7489\n",
      "\n",
      " Train loss: 0.000353266455931589 | Test loss: 2.6349  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.001263190875761211 | Test loss: 2.6448  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.0015451668296009302 | Test loss: 2.6018  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.0015145392389968038 | Test loss: 2.1752  | Test acc: 0.7611\n",
      "\n",
      " Train loss: 0.0016944835660979152 | Test loss: 2.0485  | Test acc: 0.7624\n",
      "\n",
      " Train loss: 0.001184837776236236 | Test loss: 2.1734  | Test acc: 0.7423\n",
      "\n",
      " Train loss: 0.000793473853264004 | Test loss: 2.6111  | Test acc: 0.6970\n",
      "\n",
      " Train loss: 0.00038443729863502085 | Test loss: 2.6036  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.0018584589706733823 | Test loss: 2.1300  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.0007964653195813298 | Test loss: 2.4251  | Test acc: 0.7190\n",
      "\n",
      " Train loss: 0.0007078897324390709 | Test loss: 3.1777  | Test acc: 0.6664\n",
      "\n",
      " Train loss: 0.0018111650133505464 | Test loss: 3.1085  | Test acc: 0.6597\n",
      "\n",
      " Train loss: 0.0011585745960474014 | Test loss: 3.1797  | Test acc: 0.6744\n",
      "\n",
      " Train loss: 0.002283363603055477 | Test loss: 3.4558  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.0022967939730733633 | Test loss: 3.5093  | Test acc: 0.6689\n",
      "\n",
      " Train loss: 0.001859030919149518 | Test loss: 2.7792  | Test acc: 0.6969\n",
      "\n",
      " Train loss: 0.0022356552071869373 | Test loss: 2.3739  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0008866255520842969 | Test loss: 3.0273  | Test acc: 0.6982\n",
      "\n",
      " Train loss: 0.0007755146943964064 | Test loss: 5.0625  | Test acc: 0.6404\n",
      "\n",
      " Train loss: 0.0025024395436048508 | Test loss: 5.1259  | Test acc: 0.6246\n",
      "\n",
      " Train loss: 0.002514329506084323 | Test loss: 2.5574  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.0012965683126822114 | Test loss: 2.2482  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.00032478271168656647 | Test loss: 2.1474  | Test acc: 0.7254\n",
      "\n",
      " Train loss: 0.0009112259722314775 | Test loss: 1.9541  | Test acc: 0.7259\n",
      "\n",
      " Train loss: 0.001904449425637722 | Test loss: 2.4121  | Test acc: 0.7128\n",
      "\n",
      " Train loss: 0.00048277457244694233 | Test loss: 2.9577  | Test acc: 0.7036\n",
      "\n",
      " Train loss: 0.0024868266191333532 | Test loss: 2.8457  | Test acc: 0.6764\n",
      "\n",
      " Train loss: 0.0011782236397266388 | Test loss: 3.1122  | Test acc: 0.6556\n",
      "\n",
      " Train loss: 0.0013926055980846286 | Test loss: 2.8719  | Test acc: 0.6697\n",
      "\n",
      " Train loss: 0.0012593790888786316 | Test loss: 2.6519  | Test acc: 0.6708\n",
      "\n",
      " Train loss: 0.0010754041140899062 | Test loss: 1.9005  | Test acc: 0.7079\n",
      "\n",
      " Train loss: 0.001256388146430254 | Test loss: 1.9832  | Test acc: 0.7080\n",
      "\n",
      " Train loss: 0.001215243013575673 | Test loss: 2.1161  | Test acc: 0.7095\n",
      "\n",
      " Train loss: 0.0025395480915904045 | Test loss: 1.9254  | Test acc: 0.7318\n",
      "\n",
      " Train loss: 0.0006648896960541606 | Test loss: 2.0592  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.001232762006111443 | Test loss: 1.9501  | Test acc: 0.7490\n",
      "\n",
      " Train loss: 0.0017995528178289533 | Test loss: 1.9575  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0006164315273053944 | Test loss: 2.2144  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.0022503258660435677 | Test loss: 1.9886  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.0008385617984458804 | Test loss: 2.1621  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.00099127646535635 | Test loss: 1.8349  | Test acc: 0.7318\n",
      "\n",
      " Train loss: 0.001653305604122579 | Test loss: 1.6618  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0010029240511357784 | Test loss: 1.6767  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0015038333367556334 | Test loss: 1.8873  | Test acc: 0.7326\n",
      "\n",
      " Train loss: 0.0009281517122872174 | Test loss: 1.9413  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.0007910514250397682 | Test loss: 2.1417  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.0005131065263412893 | Test loss: 2.2304  | Test acc: 0.7167\n",
      "\n",
      " Train loss: 0.0014851453015580773 | Test loss: 1.9165  | Test acc: 0.7407\n",
      "\n",
      " Train loss: 0.0006604533409699798 | Test loss: 1.9669  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0007372208638116717 | Test loss: 2.2734  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0008386350236833096 | Test loss: 2.1765  | Test acc: 0.7076\n",
      "\n",
      " Train loss: 0.0021477998234331608 | Test loss: 1.6513  | Test acc: 0.7580\n",
      "\n",
      " Train loss: 0.0007971999584697187 | Test loss: 1.9767  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0007662998978048563 | Test loss: 2.4656  | Test acc: 0.6952\n",
      "\n",
      " Train loss: 0.0008800070500001311 | Test loss: 2.6329  | Test acc: 0.6818\n",
      "\n",
      " Train loss: 0.0012464080937206745 | Test loss: 1.8752  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.00034115646849386394 | Test loss: 1.5890  | Test acc: 0.7666\n",
      "\n",
      " Train loss: 0.0006844682502560318 | Test loss: 1.8581  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0021504228934645653 | Test loss: 2.2856  | Test acc: 0.6989\n",
      "\n",
      " Train loss: 0.0006284266128204763 | Test loss: 2.4014  | Test acc: 0.6832\n",
      "\n",
      " Train loss: 0.0014202735619619489 | Test loss: 2.1156  | Test acc: 0.6951\n",
      "\n",
      " Train loss: 0.000395975454011932 | Test loss: 1.9976  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0007220709230750799 | Test loss: 2.0798  | Test acc: 0.7250\n",
      "\n",
      " Train loss: 0.001404588227160275 | Test loss: 1.8669  | Test acc: 0.7311\n",
      "\n",
      " Train loss: 0.0009442358859814703 | Test loss: 1.7438  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0005839193472638726 | Test loss: 2.1644  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0005554555100388825 | Test loss: 2.1111  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0015191715210676193 | Test loss: 2.1296  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0014789827400818467 | Test loss: 2.1435  | Test acc: 0.7227\n",
      "\n",
      " Train loss: 0.0006440713186748326 | Test loss: 2.2844  | Test acc: 0.7434\n",
      "\n",
      " Train loss: 0.0008780098869465292 | Test loss: 2.8702  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.0013294138479977846 | Test loss: 2.0999  | Test acc: 0.7753\n",
      "\n",
      " Train loss: 0.0005977062974125147 | Test loss: 2.0695  | Test acc: 0.7591\n",
      "\n",
      " Train loss: 0.0008731678244657815 | Test loss: 2.1652  | Test acc: 0.7463\n",
      "\n",
      " Train loss: 0.001943583250977099 | Test loss: 1.9617  | Test acc: 0.7479\n",
      "\n",
      " Train loss: 0.0009596618474461138 | Test loss: 1.9490  | Test acc: 0.7478\n",
      "\n",
      " Train loss: 0.00038429300184361637 | Test loss: 2.5487  | Test acc: 0.6910\n",
      "\n",
      " Train loss: 0.0016668164171278477 | Test loss: 3.1341  | Test acc: 0.6613\n",
      "\n",
      " Train loss: 0.0015263058012351394 | Test loss: 3.7867  | Test acc: 0.6437\n",
      "\n",
      " Train loss: 0.00204829522408545 | Test loss: 2.2349  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0013397689908742905 | Test loss: 2.8872  | Test acc: 0.7016\n",
      "\n",
      " Train loss: 0.0006260296213440597 | Test loss: 3.5418  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0023515447974205017 | Test loss: 3.8835  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.0011502281995490193 | Test loss: 3.9268  | Test acc: 0.6795\n",
      "\n",
      " Train loss: 0.0035536042414605618 | Test loss: 2.8982  | Test acc: 0.6969\n",
      "\n",
      " Train loss: 0.00044341813190840185 | Test loss: 2.8618  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.0020657475106418133 | Test loss: 2.8460  | Test acc: 0.6395\n",
      "\n",
      " Train loss: 0.001139160362072289 | Test loss: 3.5493  | Test acc: 0.5936\n",
      "\n",
      " Train loss: 0.0020976250525563955 | Test loss: 4.3827  | Test acc: 0.5962\n",
      "\n",
      " Train loss: 0.003420851659029722 | Test loss: 2.6953  | Test acc: 0.6629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0008839473593980074 | Test loss: 2.4599  | Test acc: 0.6542\n",
      "\n",
      " Train loss: 0.0014907317236065865 | Test loss: 2.5045  | Test acc: 0.6587\n",
      "\n",
      " Train loss: 0.001970743527635932 | Test loss: 2.5801  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.0015525545459240675 | Test loss: 2.2842  | Test acc: 0.7047\n",
      "\n",
      " Train loss: 0.0019157391507178545 | Test loss: 2.8180  | Test acc: 0.6786\n",
      "\n",
      " Train loss: 0.0020690872333943844 | Test loss: 2.9353  | Test acc: 0.6631\n",
      "\n",
      " Train loss: 0.0009221364744007587 | Test loss: 2.1472  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.0013050873531028628 | Test loss: 1.6933  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0007798118167556822 | Test loss: 1.6432  | Test acc: 0.7675\n",
      "\n",
      " Train loss: 0.000985670369118452 | Test loss: 2.2142  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.0002566274197306484 | Test loss: 3.0363  | Test acc: 0.6937\n",
      "\n",
      " Train loss: 0.0002450975007377565 | Test loss: 4.6269  | Test acc: 0.6315\n",
      "\n",
      " Train loss: 0.003793043550103903 | Test loss: 2.8244  | Test acc: 0.7039\n",
      "\n",
      " Train loss: 0.002038712613284588 | Test loss: 2.3342  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0007007680833339691 | Test loss: 2.9864  | Test acc: 0.6622\n",
      "\n",
      " Train loss: 0.001358347712084651 | Test loss: 3.3954  | Test acc: 0.6451\n",
      "\n",
      " Train loss: 0.0020480738021433353 | Test loss: 2.7171  | Test acc: 0.7011\n",
      "\n",
      " Train loss: 0.0005718841566704214 | Test loss: 2.6329  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0009742327965795994 | Test loss: 2.6632  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0022004132624715567 | Test loss: 2.8209  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.0008997753029689193 | Test loss: 2.7280  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0016583481337875128 | Test loss: 2.6896  | Test acc: 0.7358\n",
      "\n",
      " Train loss: 0.0015129935927689075 | Test loss: 2.0815  | Test acc: 0.7609\n",
      "\n",
      " Train loss: 0.0011552866781130433 | Test loss: 2.1517  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0017895832424983382 | Test loss: 2.2149  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.0004580459208227694 | Test loss: 2.5013  | Test acc: 0.7154\n",
      "\n",
      " Train loss: 0.00256255641579628 | Test loss: 2.4037  | Test acc: 0.6986\n",
      "\n",
      " Train loss: 0.001632952713407576 | Test loss: 2.1971  | Test acc: 0.6986\n",
      "\n",
      " Train loss: 0.001281730248592794 | Test loss: 2.4527  | Test acc: 0.6991\n",
      "\n",
      " Train loss: 0.0021847793832421303 | Test loss: 1.7420  | Test acc: 0.7538\n",
      "\n",
      " Train loss: 0.0008440004312433302 | Test loss: 1.5418  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.0009137034649029374 | Test loss: 1.8760  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.0013986907433718443 | Test loss: 2.1422  | Test acc: 0.6716\n",
      "\n",
      " Train loss: 0.0016973252641037107 | Test loss: 2.0514  | Test acc: 0.6851\n",
      "\n",
      " Train loss: 0.0017479730304330587 | Test loss: 1.9604  | Test acc: 0.6985\n",
      "\n",
      " Train loss: 0.0008171988883987069 | Test loss: 2.0025  | Test acc: 0.6997\n",
      "\n",
      " Train loss: 0.0009718919754959643 | Test loss: 1.8066  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0008776906761340797 | Test loss: 1.8015  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.0005300008342601359 | Test loss: 2.0928  | Test acc: 0.7116\n",
      "\n",
      " Train loss: 0.0007509436109103262 | Test loss: 2.4134  | Test acc: 0.6838\n",
      "\n",
      " Train loss: 0.0021190657280385494 | Test loss: 1.9195  | Test acc: 0.7037\n",
      "Looked at 25600/ 60000 samples\n",
      "\n",
      " Train loss: 0.0016822648467496037 | Test loss: 1.4881  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.0006178652984090149 | Test loss: 1.6660  | Test acc: 0.7276\n",
      "\n",
      " Train loss: 0.0008260910399258137 | Test loss: 2.1256  | Test acc: 0.6930\n",
      "\n",
      " Train loss: 0.0017580346902832389 | Test loss: 1.9458  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0004922470543533564 | Test loss: 1.5735  | Test acc: 0.7533\n",
      "\n",
      " Train loss: 0.00047190493205562234 | Test loss: 1.6129  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.00041129274177365005 | Test loss: 2.1725  | Test acc: 0.7089\n",
      "\n",
      " Train loss: 0.001544192899018526 | Test loss: 2.2123  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.0033218327444046736 | Test loss: 1.8794  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0009406963363289833 | Test loss: 1.5574  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.001229398068971932 | Test loss: 1.8621  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0013395898276939988 | Test loss: 1.5206  | Test acc: 0.7341\n",
      "\n",
      " Train loss: 0.000741408730391413 | Test loss: 1.7191  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.0014912415063008666 | Test loss: 1.9490  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.002251354744657874 | Test loss: 1.5495  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.0009041801677085459 | Test loss: 2.4913  | Test acc: 0.6605\n",
      "\n",
      " Train loss: 0.0012144187930971384 | Test loss: 3.0565  | Test acc: 0.6279\n",
      "\n",
      " Train loss: 0.0015080701559782028 | Test loss: 1.8909  | Test acc: 0.6915\n",
      "\n",
      " Train loss: 0.0016315217362716794 | Test loss: 1.4662  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.0007851629634387791 | Test loss: 1.8179  | Test acc: 0.6768\n",
      "\n",
      " Train loss: 0.0012803206918761134 | Test loss: 2.4540  | Test acc: 0.6190\n",
      "\n",
      " Train loss: 0.00077709840843454 | Test loss: 2.4139  | Test acc: 0.6261\n",
      "\n",
      " Train loss: 0.0012726550921797752 | Test loss: 1.8851  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.0005043703131377697 | Test loss: 1.6670  | Test acc: 0.7222\n",
      "\n",
      " Train loss: 0.00285767181776464 | Test loss: 1.7383  | Test acc: 0.7384\n",
      "\n",
      " Train loss: 0.0005124386516399682 | Test loss: 2.2276  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.000984804006293416 | Test loss: 2.3521  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.0011801357613876462 | Test loss: 2.1614  | Test acc: 0.7013\n",
      "\n",
      " Train loss: 0.0016462095081806183 | Test loss: 1.7500  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0016911848215386271 | Test loss: 1.4397  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0007601589895784855 | Test loss: 1.3528  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0008400967344641685 | Test loss: 1.5113  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.0008251513936556876 | Test loss: 1.5356  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.001121362205594778 | Test loss: 1.5859  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.0010256899986416101 | Test loss: 1.5664  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.0008377584745176136 | Test loss: 2.0435  | Test acc: 0.6742\n",
      "\n",
      " Train loss: 0.0015174999134615064 | Test loss: 1.2181  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0007157725631259382 | Test loss: 1.2608  | Test acc: 0.7548\n",
      "\n",
      " Train loss: 0.00026720890309661627 | Test loss: 1.6393  | Test acc: 0.7163\n",
      "\n",
      " Train loss: 0.001647123252041638 | Test loss: 1.1503  | Test acc: 0.7697\n",
      "\n",
      " Train loss: 0.00044671259820461273 | Test loss: 1.4240  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.0011387206614017487 | Test loss: 1.4509  | Test acc: 0.7278\n",
      "\n",
      " Train loss: 0.0012184235965833068 | Test loss: 1.1813  | Test acc: 0.7726\n",
      "\n",
      " Train loss: 0.0005100260605104268 | Test loss: 1.5864  | Test acc: 0.7346\n",
      "\n",
      " Train loss: 0.0009803862776607275 | Test loss: 2.1327  | Test acc: 0.6921\n",
      "\n",
      " Train loss: 0.0015030009672045708 | Test loss: 1.7060  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0007286079344339669 | Test loss: 1.6753  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.0007550019072368741 | Test loss: 1.9138  | Test acc: 0.7017\n",
      "\n",
      " Train loss: 0.0007137806387618184 | Test loss: 2.3658  | Test acc: 0.6597\n",
      "\n",
      " Train loss: 0.0007831004913896322 | Test loss: 2.0322  | Test acc: 0.6794\n",
      "\n",
      " Train loss: 0.0005920320400036871 | Test loss: 1.5212  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.0006323723355308175 | Test loss: 1.3624  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.0015150775434449315 | Test loss: 1.3029  | Test acc: 0.7784\n",
      "\n",
      " Train loss: 0.0008768690750002861 | Test loss: 1.2467  | Test acc: 0.7841\n",
      "\n",
      " Train loss: 0.00027884088922291994 | Test loss: 1.2334  | Test acc: 0.7788\n",
      "\n",
      " Train loss: 0.0002951787319034338 | Test loss: 1.2545  | Test acc: 0.7681\n",
      "\n",
      " Train loss: 0.001764932763762772 | Test loss: 1.2005  | Test acc: 0.7868\n",
      "\n",
      " Train loss: 0.0011798418127000332 | Test loss: 1.3477  | Test acc: 0.7684\n",
      "\n",
      " Train loss: 0.0008095247903838754 | Test loss: 1.6156  | Test acc: 0.7564\n",
      "\n",
      " Train loss: 0.0008190830703824759 | Test loss: 1.8948  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0016192534239962697 | Test loss: 2.1076  | Test acc: 0.6688\n",
      "\n",
      " Train loss: 0.0009964096825569868 | Test loss: 2.0637  | Test acc: 0.6608\n",
      "\n",
      " Train loss: 0.0009509178344160318 | Test loss: 1.5801  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.000634237308986485 | Test loss: 1.6499  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0010141077218577266 | Test loss: 1.7883  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.0006627470720559359 | Test loss: 1.6912  | Test acc: 0.7640\n",
      "\n",
      " Train loss: 0.0010263074655085802 | Test loss: 1.5868  | Test acc: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.00164507154840976 | Test loss: 1.6233  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0005948232719674706 | Test loss: 1.9167  | Test acc: 0.6910\n",
      "\n",
      " Train loss: 0.0008796871406957507 | Test loss: 1.9502  | Test acc: 0.6815\n",
      "\n",
      " Train loss: 0.0007075899047777057 | Test loss: 1.7703  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.0006384658045135438 | Test loss: 1.7886  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.0008654978591948748 | Test loss: 1.7097  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0006063984474167228 | Test loss: 1.2770  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.00033155755954794586 | Test loss: 1.2303  | Test acc: 0.7791\n",
      "\n",
      " Train loss: 0.0008478799136355519 | Test loss: 1.2289  | Test acc: 0.7742\n",
      "\n",
      " Train loss: 0.0009038809221237898 | Test loss: 1.3191  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0008425147971138358 | Test loss: 1.3580  | Test acc: 0.7346\n",
      "\n",
      " Train loss: 0.0005984154413454235 | Test loss: 1.7171  | Test acc: 0.6837\n",
      "\n",
      " Train loss: 0.000995929935015738 | Test loss: 1.6854  | Test acc: 0.7011\n",
      "\n",
      " Train loss: 0.0009677709313109517 | Test loss: 1.4103  | Test acc: 0.7439\n",
      "\n",
      " Train loss: 0.0011848756112158298 | Test loss: 1.2283  | Test acc: 0.7665\n",
      "\n",
      " Train loss: 0.0007164773414842784 | Test loss: 1.1577  | Test acc: 0.7742\n",
      "\n",
      " Train loss: 0.0009304312407039106 | Test loss: 1.3076  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0007668972830288112 | Test loss: 1.3987  | Test acc: 0.7377\n",
      "\n",
      " Train loss: 0.0007413469720631838 | Test loss: 1.8813  | Test acc: 0.6917\n",
      "\n",
      " Train loss: 0.0005449776072055101 | Test loss: 2.0943  | Test acc: 0.6697\n",
      "\n",
      " Train loss: 0.0012149355607107282 | Test loss: 1.4723  | Test acc: 0.7311\n",
      "\n",
      " Train loss: 0.0009208855335600674 | Test loss: 1.1271  | Test acc: 0.7783\n",
      "\n",
      " Train loss: 0.0008547362522222102 | Test loss: 1.2111  | Test acc: 0.7735\n",
      "\n",
      " Train loss: 0.0005522422143258154 | Test loss: 1.3377  | Test acc: 0.7554\n",
      "\n",
      " Train loss: 0.0004826153162866831 | Test loss: 1.5667  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.001726378221064806 | Test loss: 1.9172  | Test acc: 0.6447\n",
      "\n",
      " Train loss: 0.0011496908264234662 | Test loss: 2.3936  | Test acc: 0.6071\n",
      "\n",
      " Train loss: 0.002081930637359619 | Test loss: 1.8599  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0003262473619543016 | Test loss: 1.9827  | Test acc: 0.6944\n",
      "\n",
      " Train loss: 0.0012024815659970045 | Test loss: 1.6069  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.0003259313525632024 | Test loss: 2.0178  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0006653471500612795 | Test loss: 1.9949  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0004993482143618166 | Test loss: 1.9708  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0010485213715583086 | Test loss: 1.4727  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.0011837099445983768 | Test loss: 1.6879  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0016497793840244412 | Test loss: 1.5280  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0004629027971532196 | Test loss: 1.5160  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.000495818501804024 | Test loss: 1.4662  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0005357749760150909 | Test loss: 1.5131  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0008285139338113368 | Test loss: 1.6225  | Test acc: 0.7256\n",
      "\n",
      " Train loss: 0.0005563739105127752 | Test loss: 1.6678  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0008737428579479456 | Test loss: 1.7553  | Test acc: 0.7152\n",
      "\n",
      " Train loss: 0.000861241715028882 | Test loss: 1.9205  | Test acc: 0.7044\n",
      "\n",
      " Train loss: 0.0005028351442888379 | Test loss: 1.8857  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.0011065516155213118 | Test loss: 1.8011  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0008702827035449445 | Test loss: 1.7809  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0014683433109894395 | Test loss: 1.7871  | Test acc: 0.6910\n",
      "\n",
      " Train loss: 0.0012722392566502094 | Test loss: 1.3342  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.0008131591603159904 | Test loss: 1.3724  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.0006073417607694864 | Test loss: 1.9050  | Test acc: 0.6948\n",
      "\n",
      " Train loss: 0.0007335331756621599 | Test loss: 1.8206  | Test acc: 0.7050\n",
      "\n",
      " Train loss: 0.0011224426561966538 | Test loss: 1.6516  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.0005387435667216778 | Test loss: 1.9888  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.0004200726398266852 | Test loss: 2.2574  | Test acc: 0.6983\n",
      "\n",
      " Train loss: 0.001480457023717463 | Test loss: 1.8664  | Test acc: 0.6783\n",
      "\n",
      " Train loss: 0.0009258996578864753 | Test loss: 1.8345  | Test acc: 0.6759\n",
      "\n",
      " Train loss: 0.0008458913071081042 | Test loss: 1.4900  | Test acc: 0.7237\n",
      "\n",
      " Train loss: 0.0011029919842258096 | Test loss: 1.4896  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0006352415075525641 | Test loss: 1.4110  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.00024450139608234167 | Test loss: 1.4806  | Test acc: 0.7506\n",
      "\n",
      " Train loss: 0.0009733660845085979 | Test loss: 1.5359  | Test acc: 0.7380\n",
      "\n",
      " Train loss: 0.0012686208356171846 | Test loss: 1.2980  | Test acc: 0.7653\n",
      "\n",
      " Train loss: 0.0009564964566379786 | Test loss: 1.3719  | Test acc: 0.7565\n",
      "\n",
      " Train loss: 0.0006041127489879727 | Test loss: 1.3839  | Test acc: 0.7497\n",
      "\n",
      " Train loss: 0.0011442983523011208 | Test loss: 1.5419  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0007882736972533166 | Test loss: 1.8284  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.0013710107887163758 | Test loss: 1.4758  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.000663422339130193 | Test loss: 1.5913  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0009184837690554559 | Test loss: 1.6851  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0009624318918213248 | Test loss: 1.6337  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.00033645250368863344 | Test loss: 1.5539  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0006458442658185959 | Test loss: 1.4669  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0004304664907976985 | Test loss: 1.4911  | Test acc: 0.7563\n",
      "\n",
      " Train loss: 0.001118905725888908 | Test loss: 1.4655  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0006940449820831418 | Test loss: 1.5353  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.0008579685818403959 | Test loss: 1.7137  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0011251411633566022 | Test loss: 1.6168  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.001048233243636787 | Test loss: 1.5022  | Test acc: 0.7424\n",
      "\n",
      " Train loss: 0.00045264395885169506 | Test loss: 1.5325  | Test acc: 0.7455\n",
      "\n",
      " Train loss: 0.000758698268327862 | Test loss: 1.5259  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0005457261577248573 | Test loss: 1.4823  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.0009623329387977719 | Test loss: 1.5403  | Test acc: 0.7266\n",
      "\n",
      " Train loss: 0.0015643042279407382 | Test loss: 1.8268  | Test acc: 0.6870\n",
      "\n",
      " Train loss: 0.0011286674998700619 | Test loss: 1.5225  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.0003442608576733619 | Test loss: 1.8640  | Test acc: 0.7001\n",
      "\n",
      " Train loss: 0.0012943167239427567 | Test loss: 1.9034  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.002548355609178543 | Test loss: 1.5506  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.0008463779813610017 | Test loss: 1.5827  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.001245641615241766 | Test loss: 2.5443  | Test acc: 0.6308\n",
      "\n",
      " Train loss: 0.0009006847976706922 | Test loss: 2.6970  | Test acc: 0.6166\n",
      "\n",
      " Train loss: 0.0018401122651994228 | Test loss: 1.9647  | Test acc: 0.6597\n",
      "\n",
      " Train loss: 0.0005126508767716587 | Test loss: 1.6228  | Test acc: 0.6852\n",
      "\n",
      " Train loss: 0.0006112098344601691 | Test loss: 1.9689  | Test acc: 0.6826\n",
      "\n",
      " Train loss: 0.0019059106707572937 | Test loss: 1.7991  | Test acc: 0.6636\n",
      "\n",
      " Train loss: 0.0008775168098509312 | Test loss: 1.3397  | Test acc: 0.7255\n",
      "\n",
      " Train loss: 0.0007106685661710799 | Test loss: 1.7086  | Test acc: 0.6845\n",
      "\n",
      " Train loss: 0.0008290928089991212 | Test loss: 2.2143  | Test acc: 0.6738\n",
      "\n",
      " Train loss: 0.0007413151324726641 | Test loss: 2.2183  | Test acc: 0.6747\n",
      "\n",
      " Train loss: 0.0010094844037666917 | Test loss: 1.5311  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0008598249405622482 | Test loss: 1.6911  | Test acc: 0.7054\n",
      "\n",
      " Train loss: 0.0007752350647933781 | Test loss: 1.7450  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.0014709039824083447 | Test loss: 1.7182  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.0008150914800353348 | Test loss: 1.9763  | Test acc: 0.6766\n",
      "\n",
      " Train loss: 0.0005452604964375496 | Test loss: 1.9781  | Test acc: 0.6819\n",
      "\n",
      " Train loss: 0.000342894927598536 | Test loss: 1.8790  | Test acc: 0.6819\n",
      "\n",
      " Train loss: 0.0007467195391654968 | Test loss: 1.7144  | Test acc: 0.6983\n",
      "\n",
      " Train loss: 0.0004772958636749536 | Test loss: 1.9602  | Test acc: 0.6882\n",
      "\n",
      " Train loss: 0.001657569664530456 | Test loss: 1.9424  | Test acc: 0.7108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0005169599899090827 | Test loss: 1.4859  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.001088857650756836 | Test loss: 1.1093  | Test acc: 0.7963\n",
      "\n",
      " Train loss: 0.0004468067199923098 | Test loss: 1.5392  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.000586304406169802 | Test loss: 2.1677  | Test acc: 0.7318\n",
      "\n",
      " Train loss: 0.0005023577832616866 | Test loss: 2.0332  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0005752818542532623 | Test loss: 1.6426  | Test acc: 0.7569\n",
      "\n",
      " Train loss: 0.0008122530998662114 | Test loss: 1.3464  | Test acc: 0.7793\n",
      "\n",
      " Train loss: 0.0007270500645972788 | Test loss: 1.4891  | Test acc: 0.7616\n",
      "\n",
      " Train loss: 0.00037315735244192183 | Test loss: 2.0521  | Test acc: 0.7226\n",
      "\n",
      " Train loss: 0.000525272567756474 | Test loss: 2.4431  | Test acc: 0.7059\n",
      "\n",
      " Train loss: 0.000829437340144068 | Test loss: 2.4657  | Test acc: 0.7089\n",
      "\n",
      " Train loss: 0.0011386714177206159 | Test loss: 2.2879  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.001410316675901413 | Test loss: 1.7637  | Test acc: 0.7025\n",
      "\n",
      " Train loss: 0.000994012225419283 | Test loss: 1.7633  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.001899190479889512 | Test loss: 2.4410  | Test acc: 0.6669\n",
      "\n",
      " Train loss: 0.0012537164147943258 | Test loss: 2.4337  | Test acc: 0.6745\n",
      "\n",
      " Train loss: 0.001283337944187224 | Test loss: 1.8723  | Test acc: 0.7184\n",
      "\n",
      " Train loss: 0.0007811952382326126 | Test loss: 1.8618  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.0005541495629586279 | Test loss: 1.8321  | Test acc: 0.7174\n",
      "\n",
      " Train loss: 0.000883022730704397 | Test loss: 1.4354  | Test acc: 0.7553\n",
      "\n",
      " Train loss: 0.0009507025824859738 | Test loss: 1.7050  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.00044221783173270524 | Test loss: 2.2795  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.001489301328547299 | Test loss: 2.6443  | Test acc: 0.7207\n",
      "\n",
      " Train loss: 0.0019144160905852914 | Test loss: 2.6491  | Test acc: 0.7165\n",
      "\n",
      " Train loss: 0.0010718269040808082 | Test loss: 2.6182  | Test acc: 0.6702\n",
      "\n",
      " Train loss: 0.0016949174460023642 | Test loss: 2.5787  | Test acc: 0.6640\n",
      "\n",
      " Train loss: 0.0005596168339252472 | Test loss: 3.1978  | Test acc: 0.6398\n",
      "\n",
      " Train loss: 0.0010144697735086083 | Test loss: 3.2117  | Test acc: 0.6558\n",
      "\n",
      " Train loss: 0.00227717193774879 | Test loss: 2.6511  | Test acc: 0.6954\n",
      "\n",
      " Train loss: 0.0013964998070150614 | Test loss: 1.9537  | Test acc: 0.7011\n",
      "\n",
      " Train loss: 0.0009306474239565432 | Test loss: 1.8126  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0007841811748221517 | Test loss: 1.7852  | Test acc: 0.7247\n",
      "\n",
      " Train loss: 0.0011568748159334064 | Test loss: 1.7675  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.001160829677246511 | Test loss: 1.8456  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.0009026879561133683 | Test loss: 1.5829  | Test acc: 0.7053\n",
      "\n",
      " Train loss: 0.0005204687477089465 | Test loss: 1.8886  | Test acc: 0.6638\n",
      "\n",
      " Train loss: 0.0006806158344261348 | Test loss: 2.4104  | Test acc: 0.6541\n",
      "\n",
      " Train loss: 0.0015126828802749515 | Test loss: 1.8556  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.0012817425886169076 | Test loss: 2.0206  | Test acc: 0.6796\n",
      "\n",
      " Train loss: 0.0009311547037214041 | Test loss: 2.0030  | Test acc: 0.6883\n",
      "\n",
      " Train loss: 0.0011109082261100411 | Test loss: 1.7927  | Test acc: 0.7235\n",
      "\n",
      " Train loss: 0.00046069046948105097 | Test loss: 2.2425  | Test acc: 0.6706\n",
      "\n",
      " Train loss: 0.0009782960405573249 | Test loss: 1.9996  | Test acc: 0.6667\n",
      "\n",
      " Train loss: 0.0008690092945471406 | Test loss: 2.1029  | Test acc: 0.6652\n",
      "\n",
      " Train loss: 0.001341974246315658 | Test loss: 2.3597  | Test acc: 0.6583\n",
      "\n",
      " Train loss: 0.0014368873089551926 | Test loss: 1.8425  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.0011019085068255663 | Test loss: 1.7405  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0010205721482634544 | Test loss: 1.8496  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0006052193930372596 | Test loss: 1.7868  | Test acc: 0.7340\n",
      "\n",
      " Train loss: 0.0013389610685408115 | Test loss: 1.5471  | Test acc: 0.7611\n",
      "\n",
      " Train loss: 0.0009485894115641713 | Test loss: 1.5671  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.0007981817470863461 | Test loss: 1.6015  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.0005974369705654681 | Test loss: 1.5436  | Test acc: 0.7616\n",
      "\n",
      " Train loss: 0.0004776284913532436 | Test loss: 1.7668  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.001099281944334507 | Test loss: 1.6205  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0005542137078009546 | Test loss: 1.5074  | Test acc: 0.7622\n",
      "\n",
      " Train loss: 0.0011929926695302129 | Test loss: 1.4011  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0008507432066835463 | Test loss: 1.9294  | Test acc: 0.6726\n",
      "\n",
      " Train loss: 0.0006807493628002703 | Test loss: 1.9406  | Test acc: 0.7097\n",
      "\n",
      " Train loss: 0.0017601643921807408 | Test loss: 1.4904  | Test acc: 0.7518\n",
      "\n",
      " Train loss: 0.00041989953024312854 | Test loss: 1.5420  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.00036783539690077305 | Test loss: 1.8436  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.001157112536020577 | Test loss: 1.7762  | Test acc: 0.7538\n",
      "\n",
      " Train loss: 0.0012714354088529944 | Test loss: 1.8426  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0015315621858462691 | Test loss: 1.9397  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0014533185167238116 | Test loss: 1.6325  | Test acc: 0.7464\n",
      "\n",
      " Train loss: 0.0004886426031589508 | Test loss: 1.5330  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.0009733897750265896 | Test loss: 1.4483  | Test acc: 0.7298\n",
      "\n",
      " Train loss: 0.00046653617755509913 | Test loss: 1.5925  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0003396110550966114 | Test loss: 1.7807  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0013280416605994105 | Test loss: 1.4241  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.0005524518201127648 | Test loss: 1.3835  | Test acc: 0.7634\n",
      "\n",
      " Train loss: 0.0008381720981560647 | Test loss: 1.4273  | Test acc: 0.7721\n",
      "\n",
      " Train loss: 0.0002493653155397624 | Test loss: 1.7852  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0004102395905647427 | Test loss: 2.8522  | Test acc: 0.6620\n",
      "\n",
      " Train loss: 0.001267435378395021 | Test loss: 1.9577  | Test acc: 0.7249\n",
      "\n",
      " Train loss: 0.0013334949035197496 | Test loss: 1.5558  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.000921251717954874 | Test loss: 1.9237  | Test acc: 0.6950\n",
      "\n",
      " Train loss: 0.0019145372789353132 | Test loss: 1.6630  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0010294676758348942 | Test loss: 1.7036  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0014317912282422185 | Test loss: 1.5133  | Test acc: 0.7539\n",
      "\n",
      " Train loss: 0.0003865541657432914 | Test loss: 1.6272  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0008087949245236814 | Test loss: 2.0306  | Test acc: 0.6814\n",
      "\n",
      " Train loss: 0.0005079948459751904 | Test loss: 1.7533  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.0011356514878571033 | Test loss: 1.4352  | Test acc: 0.7410\n",
      "\n",
      " Train loss: 0.0007828203961253166 | Test loss: 1.3287  | Test acc: 0.7683\n",
      "\n",
      " Train loss: 0.0010012477869167924 | Test loss: 1.7790  | Test acc: 0.7326\n",
      "\n",
      " Train loss: 0.0010144250700250268 | Test loss: 2.1261  | Test acc: 0.6917\n",
      "\n",
      " Train loss: 0.0009693792089819908 | Test loss: 1.7408  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.0010520161595195532 | Test loss: 1.3686  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.00020010300795547664 | Test loss: 1.5647  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0013447109377011657 | Test loss: 1.6399  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.0009655299363657832 | Test loss: 1.6750  | Test acc: 0.7123\n",
      "\n",
      " Train loss: 0.0012198652839288116 | Test loss: 1.6657  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.001003155135549605 | Test loss: 1.8131  | Test acc: 0.6955\n",
      "\n",
      " Train loss: 0.0008148245979100466 | Test loss: 2.5026  | Test acc: 0.6532\n",
      "\n",
      " Train loss: 0.0016927231336012483 | Test loss: 2.4398  | Test acc: 0.6380\n",
      "\n",
      " Train loss: 0.0015608782414346933 | Test loss: 1.5217  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0007011657580733299 | Test loss: 1.3309  | Test acc: 0.7748\n",
      "\n",
      " Train loss: 0.0007790494128130376 | Test loss: 1.6980  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0011752500431612134 | Test loss: 1.9798  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0016179706435650587 | Test loss: 2.0384  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.001126195420511067 | Test loss: 1.8209  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0014437525533139706 | Test loss: 1.4247  | Test acc: 0.7400\n",
      "\n",
      " Train loss: 0.0003902677563019097 | Test loss: 1.3647  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0005531214410439134 | Test loss: 1.2867  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.0007182020926848054 | Test loss: 1.3208  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0005584784667007625 | Test loss: 1.4134  | Test acc: 0.7434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0005330966669134796 | Test loss: 1.4010  | Test acc: 0.7501\n",
      "\n",
      " Train loss: 0.0004384852363727987 | Test loss: 1.4484  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.0004013266589026898 | Test loss: 1.5690  | Test acc: 0.7438\n",
      "\n",
      " Train loss: 0.0012723557883873582 | Test loss: 1.6459  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.0008941369014792144 | Test loss: 1.6649  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0003167919348925352 | Test loss: 1.6373  | Test acc: 0.7323\n",
      "\n",
      " Train loss: 0.000725907098967582 | Test loss: 1.5613  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.0008921074331738055 | Test loss: 1.3480  | Test acc: 0.7630\n",
      "\n",
      " Train loss: 0.0010107617126777768 | Test loss: 1.5764  | Test acc: 0.7298\n",
      "\n",
      " Train loss: 0.0005833689356222749 | Test loss: 1.5934  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0009265989065170288 | Test loss: 1.4609  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.0003382724244147539 | Test loss: 1.2925  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.00040160564822144806 | Test loss: 1.1925  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.000758569163735956 | Test loss: 1.2521  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0005234035779722035 | Test loss: 1.3871  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.000991750624962151 | Test loss: 1.3284  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0005672824336215854 | Test loss: 1.2907  | Test acc: 0.7407\n",
      "\n",
      " Train loss: 0.0009506626520305872 | Test loss: 1.1690  | Test acc: 0.7584\n",
      "\n",
      " Train loss: 0.0006608806434087455 | Test loss: 1.4200  | Test acc: 0.7124\n",
      "\n",
      " Train loss: 0.00035593382199294865 | Test loss: 1.8790  | Test acc: 0.6610\n",
      "\n",
      " Train loss: 0.0007727305637672544 | Test loss: 1.7594  | Test acc: 0.6789\n",
      "\n",
      " Train loss: 0.0010197088122367859 | Test loss: 1.5453  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.0005185441696085036 | Test loss: 1.5289  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.001018886687234044 | Test loss: 1.5172  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0007554940530098975 | Test loss: 1.3387  | Test acc: 0.7486\n",
      "\n",
      " Train loss: 0.00022024470672477037 | Test loss: 1.2786  | Test acc: 0.7554\n",
      "\n",
      " Train loss: 0.00026609990163706243 | Test loss: 1.3232  | Test acc: 0.7506\n",
      "\n",
      " Train loss: 0.0010318822460249066 | Test loss: 1.4462  | Test acc: 0.7281\n",
      "\n",
      " Train loss: 0.001029307721182704 | Test loss: 1.3317  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0009193825535476208 | Test loss: 1.2646  | Test acc: 0.7687\n",
      "\n",
      " Train loss: 0.0006446599145419896 | Test loss: 1.3630  | Test acc: 0.7662\n",
      "\n",
      " Train loss: 0.0009023605962283909 | Test loss: 1.4392  | Test acc: 0.7590\n",
      "\n",
      " Train loss: 0.0008245807839557528 | Test loss: 1.8216  | Test acc: 0.7179\n",
      "\n",
      " Train loss: 0.0008197134593501687 | Test loss: 1.9149  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.0010777030838653445 | Test loss: 1.7242  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.00033684074878692627 | Test loss: 1.7688  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.0008934548241086304 | Test loss: 1.5531  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.0008014619816094637 | Test loss: 1.8268  | Test acc: 0.7044\n",
      "\n",
      " Train loss: 0.0007516365149058402 | Test loss: 1.8165  | Test acc: 0.7148\n",
      "\n",
      " Train loss: 0.001355870976112783 | Test loss: 1.6370  | Test acc: 0.7530\n",
      "\n",
      " Train loss: 0.0011080083204433322 | Test loss: 1.6517  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0007915713358670473 | Test loss: 1.7036  | Test acc: 0.7434\n",
      "\n",
      " Train loss: 0.0014991500647738576 | Test loss: 1.6046  | Test acc: 0.7621\n",
      "\n",
      " Train loss: 0.0007198288221843541 | Test loss: 1.9799  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.0006835699314251542 | Test loss: 2.0267  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.0011399260256439447 | Test loss: 1.7700  | Test acc: 0.7138\n",
      "\n",
      " Train loss: 0.00045926409075036645 | Test loss: 1.4826  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0003431761870160699 | Test loss: 1.4279  | Test acc: 0.7258\n",
      "\n",
      " Train loss: 0.0008558538393117487 | Test loss: 2.1009  | Test acc: 0.6462\n",
      "\n",
      " Train loss: 0.0015260156942531466 | Test loss: 2.8319  | Test acc: 0.5837\n",
      "\n",
      " Train loss: 0.0021007752511650324 | Test loss: 2.0940  | Test acc: 0.6687\n",
      "\n",
      " Train loss: 0.0020292052067816257 | Test loss: 2.0647  | Test acc: 0.6799\n",
      "\n",
      " Train loss: 0.0010928651317954063 | Test loss: 2.1248  | Test acc: 0.6664\n",
      "\n",
      " Train loss: 0.0006736091454513371 | Test loss: 2.4081  | Test acc: 0.6365\n",
      "\n",
      " Train loss: 0.0013224657159298658 | Test loss: 3.1042  | Test acc: 0.6262\n",
      "\n",
      " Train loss: 0.0018790095346048474 | Test loss: 3.6288  | Test acc: 0.5592\n",
      "\n",
      " Train loss: 0.0022667241282761097 | Test loss: 3.8343  | Test acc: 0.6210\n",
      "\n",
      " Train loss: 0.0022585554979741573 | Test loss: 3.6865  | Test acc: 0.6499\n",
      "\n",
      " Train loss: 0.002929230686277151 | Test loss: 2.5639  | Test acc: 0.6407\n",
      "\n",
      " Train loss: 0.001651383237913251 | Test loss: 2.1350  | Test acc: 0.6609\n",
      "\n",
      " Train loss: 0.0016969848657026887 | Test loss: 3.5106  | Test acc: 0.5722\n",
      "\n",
      " Train loss: 0.0014696361031383276 | Test loss: 3.8714  | Test acc: 0.6017\n",
      "\n",
      " Train loss: 0.00208068429492414 | Test loss: 3.5139  | Test acc: 0.6164\n",
      "\n",
      " Train loss: 0.0012683728709816933 | Test loss: 2.4959  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0012703000102192163 | Test loss: 1.9401  | Test acc: 0.7477\n",
      "\n",
      " Train loss: 0.0010954828467220068 | Test loss: 2.5351  | Test acc: 0.7065\n",
      "\n",
      " Train loss: 0.0010367409558966756 | Test loss: 3.8243  | Test acc: 0.5992\n",
      "\n",
      " Train loss: 0.00174066296312958 | Test loss: 3.5740  | Test acc: 0.6257\n",
      "\n",
      " Train loss: 0.001069111400283873 | Test loss: 4.3045  | Test acc: 0.6431\n",
      "\n",
      " Train loss: 0.0016229418106377125 | Test loss: 4.5332  | Test acc: 0.6544\n",
      "\n",
      " Train loss: 0.002422673860564828 | Test loss: 2.9731  | Test acc: 0.6953\n",
      "\n",
      " Train loss: 0.002298509469255805 | Test loss: 2.3063  | Test acc: 0.7305\n",
      "\n",
      " Train loss: 0.001250986009836197 | Test loss: 3.6963  | Test acc: 0.6342\n",
      "\n",
      " Train loss: 0.0018366080475971103 | Test loss: 3.3089  | Test acc: 0.6757\n",
      "\n",
      " Train loss: 0.002011878415942192 | Test loss: 3.6532  | Test acc: 0.6724\n",
      "\n",
      " Train loss: 0.003222272265702486 | Test loss: 2.9929  | Test acc: 0.6850\n",
      "\n",
      " Train loss: 0.0004973158938810229 | Test loss: 2.8692  | Test acc: 0.6911\n",
      "\n",
      " Train loss: 0.0007277178228832781 | Test loss: 3.7638  | Test acc: 0.6401\n",
      "\n",
      " Train loss: 0.002209936035797 | Test loss: 3.8544  | Test acc: 0.6422\n",
      "\n",
      " Train loss: 0.0014321348862722516 | Test loss: 2.5231  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0006928949733264744 | Test loss: 2.5785  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0010275532258674502 | Test loss: 2.4442  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.0010265830205753446 | Test loss: 3.1942  | Test acc: 0.6903\n",
      "\n",
      " Train loss: 0.0011278304737061262 | Test loss: 3.5860  | Test acc: 0.6728\n",
      "\n",
      " Train loss: 0.0016457140445709229 | Test loss: 3.0778  | Test acc: 0.7078\n",
      "\n",
      " Train loss: 0.0010112581076100469 | Test loss: 3.1097  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.0017238251166418195 | Test loss: 4.3523  | Test acc: 0.6942\n",
      "\n",
      " Train loss: 0.0012870177160948515 | Test loss: 5.7338  | Test acc: 0.6640\n",
      "\n",
      " Train loss: 0.002770444843918085 | Test loss: 5.8461  | Test acc: 0.6559\n",
      "\n",
      " Train loss: 0.002199898473918438 | Test loss: 4.0436  | Test acc: 0.7034\n",
      "\n",
      " Train loss: 0.0005295109003782272 | Test loss: 4.4505  | Test acc: 0.6722\n",
      "\n",
      " Train loss: 0.0021746261045336723 | Test loss: 4.4604  | Test acc: 0.6836\n",
      "\n",
      " Train loss: 0.0014141518622636795 | Test loss: 3.9275  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.0016420204192399979 | Test loss: 2.8360  | Test acc: 0.7429\n",
      "\n",
      " Train loss: 0.0007428438984788954 | Test loss: 3.0971  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0013763151364400983 | Test loss: 3.5639  | Test acc: 0.6887\n",
      "\n",
      " Train loss: 0.0007464945083484054 | Test loss: 3.7224  | Test acc: 0.6800\n",
      "\n",
      " Train loss: 0.0024185373913496733 | Test loss: 3.2995  | Test acc: 0.7099\n",
      "\n",
      " Train loss: 0.001173058059066534 | Test loss: 3.1672  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0009903748286888003 | Test loss: 3.0321  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.002338949590921402 | Test loss: 3.2120  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.0012298611691221595 | Test loss: 3.2096  | Test acc: 0.7146\n",
      "\n",
      " Train loss: 0.0015681121731176972 | Test loss: 2.6555  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0013411922845989466 | Test loss: 2.4025  | Test acc: 0.7575\n",
      "\n",
      " Train loss: 0.0014236344723030925 | Test loss: 2.5690  | Test acc: 0.7276\n",
      "\n",
      " Train loss: 0.0007556526688858867 | Test loss: 4.4778  | Test acc: 0.6288\n",
      "\n",
      " Train loss: 0.0010042594512924552 | Test loss: 6.6707  | Test acc: 0.5764\n",
      "\n",
      " Train loss: 0.0028734118677675724 | Test loss: 4.8219  | Test acc: 0.6213\n",
      "\n",
      " Train loss: 0.0007303533493541181 | Test loss: 3.3877  | Test acc: 0.6714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.002729998668655753 | Test loss: 3.5027  | Test acc: 0.6671\n",
      "\n",
      " Train loss: 0.0004151520552113652 | Test loss: 4.2031  | Test acc: 0.6727\n",
      "\n",
      " Train loss: 0.002318581333383918 | Test loss: 3.9974  | Test acc: 0.6938\n",
      "\n",
      " Train loss: 0.0017648092471063137 | Test loss: 4.9187  | Test acc: 0.6432\n",
      "\n",
      " Train loss: 0.0031224479898810387 | Test loss: 5.2700  | Test acc: 0.6247\n",
      "\n",
      " Train loss: 0.003472104901447892 | Test loss: 3.2023  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0016449957620352507 | Test loss: 2.6511  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.0015311128227040172 | Test loss: 3.2309  | Test acc: 0.6937\n",
      "Looked at 38400/ 60000 samples\n",
      "\n",
      " Train loss: 0.0010416777804493904 | Test loss: 3.8197  | Test acc: 0.6559\n",
      "\n",
      " Train loss: 0.002895517973229289 | Test loss: 3.6562  | Test acc: 0.6648\n",
      "\n",
      " Train loss: 0.0021050015930086374 | Test loss: 3.7073  | Test acc: 0.6761\n",
      "\n",
      " Train loss: 0.001197335310280323 | Test loss: 2.9050  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.001778144738636911 | Test loss: 3.8055  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0020385601092129946 | Test loss: 4.6696  | Test acc: 0.6829\n",
      "\n",
      " Train loss: 0.0024538878351449966 | Test loss: 4.4305  | Test acc: 0.6746\n",
      "\n",
      " Train loss: 0.0015313175972551107 | Test loss: 3.4368  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0033363576512783766 | Test loss: 3.2926  | Test acc: 0.7098\n",
      "\n",
      " Train loss: 0.001662221155129373 | Test loss: 2.9825  | Test acc: 0.7153\n",
      "\n",
      " Train loss: 0.0016830527456477284 | Test loss: 4.2885  | Test acc: 0.6465\n",
      "\n",
      " Train loss: 0.0029011056758463383 | Test loss: 4.4724  | Test acc: 0.6378\n",
      "\n",
      " Train loss: 0.0037974868901073933 | Test loss: 2.7411  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0012964187189936638 | Test loss: 2.9282  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.001781577244400978 | Test loss: 3.7820  | Test acc: 0.6556\n",
      "\n",
      " Train loss: 0.003225242719054222 | Test loss: 3.2927  | Test acc: 0.6831\n",
      "\n",
      " Train loss: 0.0034100848715752363 | Test loss: 2.7720  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0005586516344919801 | Test loss: 4.3877  | Test acc: 0.6423\n",
      "\n",
      " Train loss: 0.0015078302239999175 | Test loss: 3.0671  | Test acc: 0.6818\n",
      "\n",
      " Train loss: 0.001983972731977701 | Test loss: 3.9085  | Test acc: 0.6277\n",
      "\n",
      " Train loss: 0.001765172928571701 | Test loss: 5.0800  | Test acc: 0.6185\n",
      "\n",
      " Train loss: 0.0027192209381610155 | Test loss: 4.1271  | Test acc: 0.6472\n",
      "\n",
      " Train loss: 0.0007383424672298133 | Test loss: 4.2641  | Test acc: 0.6350\n",
      "\n",
      " Train loss: 0.0036019780673086643 | Test loss: 4.5354  | Test acc: 0.6454\n",
      "\n",
      " Train loss: 0.0022286439780145884 | Test loss: 3.0847  | Test acc: 0.6686\n",
      "\n",
      " Train loss: 0.0010858289897441864 | Test loss: 3.7432  | Test acc: 0.6341\n",
      "\n",
      " Train loss: 0.002309155883267522 | Test loss: 3.1187  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.0017189437057822943 | Test loss: 2.7075  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.001692459685727954 | Test loss: 2.4844  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0013762745074927807 | Test loss: 2.6168  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.001763553824275732 | Test loss: 2.3987  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.00029018017812632024 | Test loss: 3.1558  | Test acc: 0.6986\n",
      "\n",
      " Train loss: 0.0007266575121320784 | Test loss: 3.6680  | Test acc: 0.6811\n",
      "\n",
      " Train loss: 0.002113599795848131 | Test loss: 3.9992  | Test acc: 0.6792\n",
      "\n",
      " Train loss: 0.0026733758859336376 | Test loss: 3.3307  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.0020121103152632713 | Test loss: 2.7015  | Test acc: 0.7435\n",
      "\n",
      " Train loss: 0.0014819244388490915 | Test loss: 3.4528  | Test acc: 0.6881\n",
      "\n",
      " Train loss: 0.002836064901202917 | Test loss: 3.1115  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0009567469242028892 | Test loss: 2.7384  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.0012219687923789024 | Test loss: 3.9680  | Test acc: 0.6692\n",
      "\n",
      " Train loss: 0.0017960038967430592 | Test loss: 4.7353  | Test acc: 0.6381\n",
      "\n",
      " Train loss: 0.0022870872635394335 | Test loss: 2.9585  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0010528131388127804 | Test loss: 2.2308  | Test acc: 0.7679\n",
      "\n",
      " Train loss: 0.001094854436814785 | Test loss: 3.4543  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.0009840542916208506 | Test loss: 4.7422  | Test acc: 0.6825\n",
      "\n",
      " Train loss: 0.001966718351468444 | Test loss: 5.2422  | Test acc: 0.6656\n",
      "\n",
      " Train loss: 0.002717630472034216 | Test loss: 4.3134  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.0034087514504790306 | Test loss: 2.5171  | Test acc: 0.7516\n",
      "\n",
      " Train loss: 0.0006934866541996598 | Test loss: 2.7516  | Test acc: 0.7008\n",
      "\n",
      " Train loss: 0.0014128813054412603 | Test loss: 3.0393  | Test acc: 0.6857\n",
      "\n",
      " Train loss: 0.001965207513421774 | Test loss: 3.3303  | Test acc: 0.6694\n",
      "\n",
      " Train loss: 0.001707468181848526 | Test loss: 2.9379  | Test acc: 0.7065\n",
      "\n",
      " Train loss: 0.0021763767581433058 | Test loss: 3.6002  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.001050407881848514 | Test loss: 3.9032  | Test acc: 0.7077\n",
      "\n",
      " Train loss: 0.0026972712948918343 | Test loss: 3.0376  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.0015293537871912122 | Test loss: 3.0736  | Test acc: 0.7101\n",
      "\n",
      " Train loss: 0.001695822225883603 | Test loss: 2.9884  | Test acc: 0.7281\n",
      "\n",
      " Train loss: 0.0015553564298897982 | Test loss: 3.3877  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.001957924570888281 | Test loss: 3.5920  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.0019277625251561403 | Test loss: 3.3356  | Test acc: 0.7152\n",
      "\n",
      " Train loss: 0.0018456985708326101 | Test loss: 4.2423  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0026950098108500242 | Test loss: 4.2224  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0018297894857823849 | Test loss: 3.4198  | Test acc: 0.7247\n",
      "\n",
      " Train loss: 0.0005754011799581349 | Test loss: 3.4010  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0006443061283789575 | Test loss: 3.7678  | Test acc: 0.6906\n",
      "\n",
      " Train loss: 0.002357474761083722 | Test loss: 3.6687  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0014788205735385418 | Test loss: 3.0719  | Test acc: 0.7079\n",
      "\n",
      " Train loss: 0.002240365371108055 | Test loss: 2.6428  | Test acc: 0.7205\n",
      "\n",
      " Train loss: 0.000869366864208132 | Test loss: 2.9495  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.0021090772934257984 | Test loss: 3.7129  | Test acc: 0.6708\n",
      "\n",
      " Train loss: 0.0017480686074122787 | Test loss: 3.9249  | Test acc: 0.6610\n",
      "\n",
      " Train loss: 0.0016338566783815622 | Test loss: 2.9665  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0008457471267320216 | Test loss: 3.2141  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.0023435745388269424 | Test loss: 3.3931  | Test acc: 0.7106\n",
      "\n",
      " Train loss: 0.0007146931602619588 | Test loss: 4.1174  | Test acc: 0.6602\n",
      "\n",
      " Train loss: 0.0011771827703341842 | Test loss: 5.8124  | Test acc: 0.5932\n",
      "\n",
      " Train loss: 0.003466278314590454 | Test loss: 5.8288  | Test acc: 0.5941\n",
      "\n",
      " Train loss: 0.0024518282152712345 | Test loss: 3.9491  | Test acc: 0.6648\n",
      "\n",
      " Train loss: 0.0026357874739915133 | Test loss: 3.1954  | Test acc: 0.6969\n",
      "\n",
      " Train loss: 0.0015388895990327 | Test loss: 3.4909  | Test acc: 0.6823\n",
      "\n",
      " Train loss: 0.0015931171365082264 | Test loss: 2.9370  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0006411561043933034 | Test loss: 3.4453  | Test acc: 0.6700\n",
      "\n",
      " Train loss: 0.0031967281829565763 | Test loss: 3.5182  | Test acc: 0.6814\n",
      "\n",
      " Train loss: 0.001971730263903737 | Test loss: 3.1246  | Test acc: 0.7161\n",
      "\n",
      " Train loss: 0.0012154907453805208 | Test loss: 6.0690  | Test acc: 0.6052\n",
      "\n",
      " Train loss: 0.003033759305253625 | Test loss: 5.8057  | Test acc: 0.6248\n",
      "\n",
      " Train loss: 0.0029366868548095226 | Test loss: 3.9997  | Test acc: 0.6894\n",
      "\n",
      " Train loss: 0.001851000590249896 | Test loss: 4.1246  | Test acc: 0.6820\n",
      "\n",
      " Train loss: 0.0025448070373386145 | Test loss: 4.2667  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.0016063704388216138 | Test loss: 4.9641  | Test acc: 0.7052\n",
      "\n",
      " Train loss: 0.002076356904581189 | Test loss: 8.7452  | Test acc: 0.5986\n",
      "\n",
      " Train loss: 0.005861090030521154 | Test loss: 4.7115  | Test acc: 0.6685\n",
      "\n",
      " Train loss: 0.002948913723230362 | Test loss: 3.5725  | Test acc: 0.6757\n",
      "\n",
      " Train loss: 0.0018784188432618976 | Test loss: 5.3257  | Test acc: 0.6446\n",
      "\n",
      " Train loss: 0.0028584273532032967 | Test loss: 6.3037  | Test acc: 0.6426\n",
      "\n",
      " Train loss: 0.0034562116488814354 | Test loss: 4.0087  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0016309305792674422 | Test loss: 3.5454  | Test acc: 0.6804\n",
      "\n",
      " Train loss: 0.0008627146016806364 | Test loss: 5.4457  | Test acc: 0.6534\n",
      "\n",
      " Train loss: 0.00015995929425116628 | Test loss: 9.1541  | Test acc: 0.5832\n",
      "\n",
      " Train loss: 0.0031379936262965202 | Test loss: 7.9397  | Test acc: 0.6128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0028311796486377716 | Test loss: 7.0448  | Test acc: 0.6770\n",
      "\n",
      " Train loss: 0.0025178687646985054 | Test loss: 7.1059  | Test acc: 0.6474\n",
      "\n",
      " Train loss: 0.005048652179539204 | Test loss: 5.9060  | Test acc: 0.6936\n",
      "\n",
      " Train loss: 0.0034605171531438828 | Test loss: 6.2201  | Test acc: 0.6769\n",
      "\n",
      " Train loss: 0.0052428655326366425 | Test loss: 4.1395  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.004176456481218338 | Test loss: 6.9500  | Test acc: 0.6596\n",
      "\n",
      " Train loss: 0.003993787802755833 | Test loss: 11.8885  | Test acc: 0.6270\n",
      "\n",
      " Train loss: 0.00529072992503643 | Test loss: 13.8525  | Test acc: 0.5762\n",
      "\n",
      " Train loss: 0.007866665720939636 | Test loss: 8.8357  | Test acc: 0.5915\n",
      "\n",
      " Train loss: 0.002309771254658699 | Test loss: 5.2635  | Test acc: 0.6462\n",
      "\n",
      " Train loss: 0.0016875391593202949 | Test loss: 6.8741  | Test acc: 0.6270\n",
      "\n",
      " Train loss: 0.0032621666323393583 | Test loss: 6.2984  | Test acc: 0.6431\n",
      "\n",
      " Train loss: 0.002252347068861127 | Test loss: 5.1040  | Test acc: 0.6678\n",
      "\n",
      " Train loss: 0.002499512629583478 | Test loss: 4.3234  | Test acc: 0.6903\n",
      "\n",
      " Train loss: 0.0014272218104451895 | Test loss: 4.7470  | Test acc: 0.6871\n",
      "\n",
      " Train loss: 0.0024122113827615976 | Test loss: 4.1771  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0013084723614156246 | Test loss: 3.7949  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.0005626518395729363 | Test loss: 6.5038  | Test acc: 0.6372\n",
      "\n",
      " Train loss: 0.005340884439647198 | Test loss: 5.9330  | Test acc: 0.6418\n",
      "\n",
      " Train loss: 0.004424822051078081 | Test loss: 4.0838  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0028240992687642574 | Test loss: 3.9278  | Test acc: 0.6894\n",
      "\n",
      " Train loss: 0.0035897884517908096 | Test loss: 5.4305  | Test acc: 0.6393\n",
      "\n",
      " Train loss: 0.0021577628795057535 | Test loss: 6.4446  | Test acc: 0.6224\n",
      "\n",
      " Train loss: 0.0045640915632247925 | Test loss: 5.1131  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0010825624922290444 | Test loss: 5.0876  | Test acc: 0.7180\n",
      "\n",
      " Train loss: 0.005965338554233313 | Test loss: 3.8067  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.000770666403695941 | Test loss: 3.9857  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0026027257554233074 | Test loss: 3.8173  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0025822941679507494 | Test loss: 3.9572  | Test acc: 0.6983\n",
      "\n",
      " Train loss: 0.004320123698562384 | Test loss: 4.1976  | Test acc: 0.6786\n",
      "\n",
      " Train loss: 0.00281390524469316 | Test loss: 3.6897  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.0012075008125975728 | Test loss: 4.3972  | Test acc: 0.6879\n",
      "\n",
      " Train loss: 0.0017087392043322325 | Test loss: 4.6471  | Test acc: 0.6976\n",
      "\n",
      " Train loss: 0.0023445335682481527 | Test loss: 3.9143  | Test acc: 0.7210\n",
      "\n",
      " Train loss: 0.0021606513764709234 | Test loss: 3.0484  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.0013243879657238722 | Test loss: 3.6603  | Test acc: 0.6967\n",
      "\n",
      " Train loss: 0.000793642655480653 | Test loss: 6.2539  | Test acc: 0.6451\n",
      "\n",
      " Train loss: 0.0038097966462373734 | Test loss: 5.0121  | Test acc: 0.6460\n",
      "\n",
      " Train loss: 0.003683797549456358 | Test loss: 3.9475  | Test acc: 0.6770\n",
      "\n",
      " Train loss: 0.004037819337099791 | Test loss: 3.3991  | Test acc: 0.7337\n",
      "\n",
      " Train loss: 0.001557069830596447 | Test loss: 4.3802  | Test acc: 0.6867\n",
      "\n",
      " Train loss: 0.0014178301207721233 | Test loss: 4.1472  | Test acc: 0.6849\n",
      "\n",
      " Train loss: 0.001757563091814518 | Test loss: 3.8855  | Test acc: 0.6658\n",
      "\n",
      " Train loss: 0.001731083495542407 | Test loss: 3.6836  | Test acc: 0.6708\n",
      "\n",
      " Train loss: 0.0007812804542481899 | Test loss: 5.4711  | Test acc: 0.6094\n",
      "\n",
      " Train loss: 0.004080288577824831 | Test loss: 5.0914  | Test acc: 0.6438\n",
      "\n",
      " Train loss: 0.0019045108929276466 | Test loss: 5.6624  | Test acc: 0.6412\n",
      "\n",
      " Train loss: 0.0036245102528482676 | Test loss: 4.2920  | Test acc: 0.7057\n",
      "\n",
      " Train loss: 0.00195485632866621 | Test loss: 3.8514  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.004503658041357994 | Test loss: 9.7754  | Test acc: 0.6293\n",
      "\n",
      " Train loss: 0.006193932611495256 | Test loss: 6.9218  | Test acc: 0.6679\n",
      "\n",
      " Train loss: 0.002949148416519165 | Test loss: 11.0415  | Test acc: 0.5752\n",
      "\n",
      " Train loss: 0.006302928552031517 | Test loss: 4.6674  | Test acc: 0.7297\n",
      "\n",
      " Train loss: 0.0026883180253207684 | Test loss: 5.3924  | Test acc: 0.7287\n",
      "\n",
      " Train loss: 0.001673478982411325 | Test loss: 7.0346  | Test acc: 0.7144\n",
      "\n",
      " Train loss: 0.003361017443239689 | Test loss: 6.7025  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.006803910713642836 | Test loss: 6.8216  | Test acc: 0.6975\n",
      "\n",
      " Train loss: 0.003001950215548277 | Test loss: 10.6097  | Test acc: 0.5913\n",
      "\n",
      " Train loss: 0.006487688515335321 | Test loss: 10.4129  | Test acc: 0.5943\n",
      "\n",
      " Train loss: 0.004295002203434706 | Test loss: 6.5253  | Test acc: 0.6655\n",
      "\n",
      " Train loss: 0.004341759718954563 | Test loss: 5.1272  | Test acc: 0.7091\n",
      "\n",
      " Train loss: 0.0024172121193259954 | Test loss: 6.6498  | Test acc: 0.7055\n",
      "\n",
      " Train loss: 0.0038334287237375975 | Test loss: 7.7199  | Test acc: 0.6843\n",
      "\n",
      " Train loss: 0.005719777196645737 | Test loss: 6.1973  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.001582585391588509 | Test loss: 5.0236  | Test acc: 0.7358\n",
      "\n",
      " Train loss: 0.0004981643287464976 | Test loss: 4.8009  | Test acc: 0.7362\n",
      "\n",
      " Train loss: 0.005481809843331575 | Test loss: 5.3340  | Test acc: 0.6920\n",
      "\n",
      " Train loss: 0.001142102642916143 | Test loss: 5.6613  | Test acc: 0.6811\n",
      "\n",
      " Train loss: 0.004373813048005104 | Test loss: 4.4295  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.0025167609564960003 | Test loss: 5.6265  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.0016521431971341372 | Test loss: 6.2994  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.000691138906404376 | Test loss: 6.7937  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0055928160436451435 | Test loss: 6.0260  | Test acc: 0.6756\n",
      "\n",
      " Train loss: 0.0029647613409906626 | Test loss: 6.6711  | Test acc: 0.6387\n",
      "\n",
      " Train loss: 0.005164564121514559 | Test loss: 4.1041  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.001213467912748456 | Test loss: 4.5892  | Test acc: 0.7193\n",
      "\n",
      " Train loss: 0.002257236046716571 | Test loss: 6.9904  | Test acc: 0.6706\n",
      "\n",
      " Train loss: 0.0027984546031802893 | Test loss: 6.4477  | Test acc: 0.6870\n",
      "\n",
      " Train loss: 0.002725873375311494 | Test loss: 4.3446  | Test acc: 0.7340\n",
      "\n",
      " Train loss: 0.0006417166441679001 | Test loss: 3.9112  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.0023585353046655655 | Test loss: 3.6232  | Test acc: 0.7319\n",
      "\n",
      " Train loss: 0.0020797764882445335 | Test loss: 3.5978  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.0020280908793210983 | Test loss: 3.9953  | Test acc: 0.7204\n",
      "\n",
      " Train loss: 0.0019221699330955744 | Test loss: 5.0619  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.003100913716480136 | Test loss: 5.2265  | Test acc: 0.6552\n",
      "\n",
      " Train loss: 0.0024423038121312857 | Test loss: 4.2471  | Test acc: 0.7161\n",
      "\n",
      " Train loss: 0.0017394853057339787 | Test loss: 4.3598  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.003942078445106745 | Test loss: 4.2075  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.0019600014202296734 | Test loss: 4.1733  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0015053970273584127 | Test loss: 4.7315  | Test acc: 0.6832\n",
      "\n",
      " Train loss: 0.002720630494877696 | Test loss: 4.0546  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.0009068215731531382 | Test loss: 3.3560  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0025437844451516867 | Test loss: 3.3778  | Test acc: 0.7501\n",
      "\n",
      " Train loss: 0.0017299045575782657 | Test loss: 4.1893  | Test acc: 0.7255\n",
      "\n",
      " Train loss: 0.002052773954346776 | Test loss: 5.5749  | Test acc: 0.6698\n",
      "\n",
      " Train loss: 0.0011583906598389149 | Test loss: 5.6161  | Test acc: 0.6868\n",
      "\n",
      " Train loss: 0.004902078304439783 | Test loss: 4.2593  | Test acc: 0.7162\n",
      "\n",
      " Train loss: 0.000939174962695688 | Test loss: 4.0675  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.002516701817512512 | Test loss: 4.5911  | Test acc: 0.6751\n",
      "\n",
      " Train loss: 0.003470316529273987 | Test loss: 5.7572  | Test acc: 0.6492\n",
      "\n",
      " Train loss: 0.003366034245118499 | Test loss: 5.8643  | Test acc: 0.6397\n",
      "\n",
      " Train loss: 0.0016531005967408419 | Test loss: 5.0435  | Test acc: 0.6571\n",
      "\n",
      " Train loss: 0.0019519907655194402 | Test loss: 3.8058  | Test acc: 0.7007\n",
      "\n",
      " Train loss: 0.0009093567496165633 | Test loss: 3.7640  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.0015975700225681067 | Test loss: 3.2929  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.002064472297206521 | Test loss: 3.0143  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.0008480654796585441 | Test loss: 3.1550  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.0018850852502509952 | Test loss: 3.2325  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.0018700120272114873 | Test loss: 2.7622  | Test acc: 0.7593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0010868287645280361 | Test loss: 2.7295  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.003166841808706522 | Test loss: 2.9981  | Test acc: 0.7407\n",
      "\n",
      " Train loss: 0.0002427496074233204 | Test loss: 3.7253  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.0012967842631042004 | Test loss: 4.7834  | Test acc: 0.6621\n",
      "\n",
      " Train loss: 0.003543223487213254 | Test loss: 4.0436  | Test acc: 0.6799\n",
      "\n",
      " Train loss: 0.0018554194830358028 | Test loss: 3.7280  | Test acc: 0.6776\n",
      "\n",
      " Train loss: 0.0027724532410502434 | Test loss: 2.8836  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0005496304947882891 | Test loss: 3.3884  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.0006859211716800928 | Test loss: 4.1378  | Test acc: 0.6806\n",
      "\n",
      " Train loss: 0.0003923270560335368 | Test loss: 4.5482  | Test acc: 0.6760\n",
      "\n",
      " Train loss: 0.0018463070737197995 | Test loss: 4.6208  | Test acc: 0.6944\n",
      "\n",
      " Train loss: 0.0015813683858141303 | Test loss: 4.6892  | Test acc: 0.6861\n",
      "\n",
      " Train loss: 0.001602456672117114 | Test loss: 4.4206  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0010537231573835015 | Test loss: 3.8523  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.0019458559108898044 | Test loss: 3.7806  | Test acc: 0.6790\n",
      "\n",
      " Train loss: 0.0014721322804689407 | Test loss: 4.0843  | Test acc: 0.6657\n",
      "\n",
      " Train loss: 0.003404220100492239 | Test loss: 3.2870  | Test acc: 0.7424\n",
      "\n",
      " Train loss: 0.0012052144156768918 | Test loss: 3.8189  | Test acc: 0.7205\n",
      "\n",
      " Train loss: 0.0009333111811429262 | Test loss: 4.1931  | Test acc: 0.6991\n",
      "\n",
      " Train loss: 0.0022398768924176693 | Test loss: 4.0061  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0022024500649422407 | Test loss: 3.2052  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.0005399303045123816 | Test loss: 3.0944  | Test acc: 0.7469\n",
      "\n",
      " Train loss: 0.0030325711704790592 | Test loss: 3.0862  | Test acc: 0.7459\n",
      "\n",
      " Train loss: 0.0010999497026205063 | Test loss: 3.4361  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.001792223658412695 | Test loss: 4.1908  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0015694095054641366 | Test loss: 4.6527  | Test acc: 0.6924\n",
      "\n",
      " Train loss: 0.004545735660940409 | Test loss: 4.1059  | Test acc: 0.6975\n",
      "\n",
      " Train loss: 0.001347614685073495 | Test loss: 3.3542  | Test acc: 0.7276\n",
      "\n",
      " Train loss: 0.0034595418255776167 | Test loss: 2.6631  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.002159716794267297 | Test loss: 3.1758  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.001928960788063705 | Test loss: 3.6421  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0017544056754559278 | Test loss: 4.1186  | Test acc: 0.6920\n",
      "\n",
      " Train loss: 0.0023185452446341515 | Test loss: 4.2646  | Test acc: 0.6781\n",
      "\n",
      " Train loss: 0.0029691613744944334 | Test loss: 3.5163  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.002799809677526355 | Test loss: 3.1926  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.0014509912580251694 | Test loss: 4.9938  | Test acc: 0.6143\n",
      "\n",
      " Train loss: 0.0021180054172873497 | Test loss: 4.7553  | Test acc: 0.6350\n",
      "\n",
      " Train loss: 0.001667198957875371 | Test loss: 4.4198  | Test acc: 0.6687\n",
      "\n",
      " Train loss: 0.0014540060656145215 | Test loss: 3.9231  | Test acc: 0.6856\n",
      "\n",
      " Train loss: 0.0020762223284691572 | Test loss: 3.4250  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0028747806791216135 | Test loss: 2.7332  | Test acc: 0.7724\n",
      "\n",
      " Train loss: 0.0019393685506656766 | Test loss: 2.9126  | Test acc: 0.7672\n",
      "\n",
      " Train loss: 0.0009819624247029424 | Test loss: 3.8606  | Test acc: 0.7323\n",
      "\n",
      " Train loss: 0.0007102452800609171 | Test loss: 3.8027  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.001166149158962071 | Test loss: 3.2953  | Test acc: 0.7426\n",
      "\n",
      " Train loss: 0.0012438278645277023 | Test loss: 3.2443  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.0031981435604393482 | Test loss: 4.0595  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0006382081191986799 | Test loss: 5.7503  | Test acc: 0.6560\n",
      "\n",
      " Train loss: 0.0012321145040914416 | Test loss: 6.6000  | Test acc: 0.6604\n",
      "\n",
      " Train loss: 0.0038339716847985983 | Test loss: 3.8337  | Test acc: 0.7333\n",
      "\n",
      " Train loss: 0.0008394682663492858 | Test loss: 3.5416  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0022654870990663767 | Test loss: 5.5735  | Test acc: 0.6606\n",
      "\n",
      " Train loss: 0.002823034068569541 | Test loss: 6.8441  | Test acc: 0.6297\n",
      "\n",
      " Train loss: 0.0037134001031517982 | Test loss: 5.8943  | Test acc: 0.6605\n",
      "\n",
      " Train loss: 0.003404679475352168 | Test loss: 4.1396  | Test acc: 0.6989\n",
      "\n",
      " Train loss: 0.0015087638748809695 | Test loss: 4.1620  | Test acc: 0.6728\n",
      "\n",
      " Train loss: 0.0014172716764733195 | Test loss: 4.0879  | Test acc: 0.6788\n",
      "\n",
      " Train loss: 0.0016366472700610757 | Test loss: 3.8058  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.001764087937772274 | Test loss: 4.0820  | Test acc: 0.6950\n",
      "\n",
      " Train loss: 0.0017400895012542605 | Test loss: 4.9242  | Test acc: 0.6645\n",
      "\n",
      " Train loss: 0.0015136696165427566 | Test loss: 5.1051  | Test acc: 0.6672\n",
      "\n",
      " Train loss: 0.0019973060116171837 | Test loss: 3.5523  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.0023399877827614546 | Test loss: 2.9557  | Test acc: 0.7298\n",
      "\n",
      " Train loss: 0.002065680455416441 | Test loss: 3.3432  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.002625798573717475 | Test loss: 2.8809  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.001581314136274159 | Test loss: 3.1163  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.0017433250322937965 | Test loss: 3.6825  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.0003685163683257997 | Test loss: 5.6110  | Test acc: 0.6525\n",
      "\n",
      " Train loss: 0.003190635470673442 | Test loss: 5.3760  | Test acc: 0.6645\n",
      "\n",
      " Train loss: 0.0021929428912699223 | Test loss: 6.4030  | Test acc: 0.6488\n",
      "\n",
      " Train loss: 0.004025429952889681 | Test loss: 5.7903  | Test acc: 0.6638\n",
      "\n",
      " Train loss: 0.0027115331031382084 | Test loss: 2.7753  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.0022019147872924805 | Test loss: 3.6804  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0030284191016107798 | Test loss: 5.9583  | Test acc: 0.6464\n",
      "\n",
      " Train loss: 0.0029733378905802965 | Test loss: 7.0137  | Test acc: 0.6034\n",
      "\n",
      " Train loss: 0.004069867543876171 | Test loss: 5.0564  | Test acc: 0.6637\n",
      "\n",
      " Train loss: 0.001909497077576816 | Test loss: 4.3287  | Test acc: 0.6635\n",
      "\n",
      " Train loss: 0.0020785422530025244 | Test loss: 4.1211  | Test acc: 0.6569\n",
      "\n",
      " Train loss: 0.00113015272654593 | Test loss: 3.6220  | Test acc: 0.6764\n",
      "\n",
      " Train loss: 0.001730990712530911 | Test loss: 3.3219  | Test acc: 0.7025\n",
      "\n",
      " Train loss: 0.0014340720372274518 | Test loss: 2.9155  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.0013233076315373182 | Test loss: 3.9673  | Test acc: 0.6690\n",
      "\n",
      " Train loss: 0.0011535633821040392 | Test loss: 4.8647  | Test acc: 0.6468\n",
      "\n",
      " Train loss: 0.0011923258425667882 | Test loss: 3.7788  | Test acc: 0.7108\n",
      "\n",
      " Train loss: 0.002152725588530302 | Test loss: 3.7937  | Test acc: 0.6817\n",
      "\n",
      " Train loss: 0.0023441764060407877 | Test loss: 3.5386  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.0030267757829278708 | Test loss: 3.9768  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.002834461396560073 | Test loss: 4.3839  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.002472836058586836 | Test loss: 4.3570  | Test acc: 0.6993\n",
      "\n",
      " Train loss: 0.003422053065150976 | Test loss: 3.6348  | Test acc: 0.7024\n",
      "\n",
      " Train loss: 0.0013157045468688011 | Test loss: 3.6077  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.00228050141595304 | Test loss: 2.9312  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0011717983288690448 | Test loss: 2.8768  | Test acc: 0.7796\n",
      "\n",
      " Train loss: 0.0014921199763193727 | Test loss: 3.7491  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0011503143468871713 | Test loss: 4.3914  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0014659399166703224 | Test loss: 3.9834  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0010209347819909453 | Test loss: 3.6911  | Test acc: 0.7463\n",
      "\n",
      " Train loss: 0.0016090860590338707 | Test loss: 3.3659  | Test acc: 0.7604\n",
      "\n",
      " Train loss: 0.0015782997943460941 | Test loss: 3.5353  | Test acc: 0.7441\n",
      "\n",
      " Train loss: 0.002503448398783803 | Test loss: 3.9835  | Test acc: 0.6983\n",
      "\n",
      " Train loss: 0.0011930010514333844 | Test loss: 3.7953  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.002411274239420891 | Test loss: 3.5500  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.0031887448858469725 | Test loss: 4.0892  | Test acc: 0.6902\n",
      "\n",
      " Train loss: 0.0014477964723482728 | Test loss: 4.0662  | Test acc: 0.6920\n",
      "\n",
      " Train loss: 0.0032425285317003727 | Test loss: 3.1699  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.001869813771918416 | Test loss: 2.8742  | Test acc: 0.7665\n",
      "\n",
      " Train loss: 0.0011899785604327917 | Test loss: 2.8780  | Test acc: 0.7643\n",
      "\n",
      " Train loss: 0.0005574882961809635 | Test loss: 3.6429  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.002894930075854063 | Test loss: 3.3275  | Test acc: 0.7424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0038080832455307245 | Test loss: 3.1597  | Test acc: 0.7526\n",
      "\n",
      " Train loss: 0.000408864114433527 | Test loss: 3.1941  | Test acc: 0.7521\n",
      "\n",
      " Train loss: 0.0017962870188057423 | Test loss: 3.0601  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0001878932089312002 | Test loss: 3.2092  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.0032414791639894247 | Test loss: 3.0940  | Test acc: 0.7167\n",
      "\n",
      " Train loss: 0.001753206946887076 | Test loss: 3.3014  | Test acc: 0.6911\n",
      "\n",
      " Train loss: 0.0014776657335460186 | Test loss: 3.2010  | Test acc: 0.6929\n",
      "\n",
      " Train loss: 0.0033032053615897894 | Test loss: 2.9705  | Test acc: 0.6954\n",
      "\n",
      " Train loss: 0.003614760935306549 | Test loss: 2.8439  | Test acc: 0.6899\n",
      "\n",
      " Train loss: 0.0005594975664280355 | Test loss: 2.8641  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0019300754647701979 | Test loss: 3.2785  | Test acc: 0.6879\n",
      "\n",
      " Train loss: 0.0017097503878176212 | Test loss: 2.7447  | Test acc: 0.7052\n",
      "\n",
      " Train loss: 0.0019067635294049978 | Test loss: 1.8403  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.0013361808378249407 | Test loss: 2.9075  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.001553787849843502 | Test loss: 3.5894  | Test acc: 0.7305\n",
      "\n",
      " Train loss: 0.001670671277679503 | Test loss: 4.1704  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0027717852499336004 | Test loss: 3.7899  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.0022320544812828302 | Test loss: 2.9029  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0030254905577749014 | Test loss: 2.4653  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0004960494698025286 | Test loss: 3.2447  | Test acc: 0.6474\n",
      "\n",
      " Train loss: 0.001920255715958774 | Test loss: 2.9507  | Test acc: 0.6528\n",
      "\n",
      " Train loss: 0.0026358445174992085 | Test loss: 4.1285  | Test acc: 0.6126\n",
      "\n",
      " Train loss: 0.002272911136969924 | Test loss: 4.2162  | Test acc: 0.6669\n",
      "\n",
      " Train loss: 0.0017674145055934787 | Test loss: 4.6757  | Test acc: 0.6669\n",
      "\n",
      " Train loss: 0.0016192706534639 | Test loss: 4.1328  | Test acc: 0.6629\n",
      "\n",
      " Train loss: 0.0023095409851521254 | Test loss: 3.4441  | Test acc: 0.6754\n",
      "\n",
      " Train loss: 0.0015883222222328186 | Test loss: 2.7487  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0015358154196292162 | Test loss: 3.0188  | Test acc: 0.7144\n",
      "\n",
      " Train loss: 0.0015967063372954726 | Test loss: 3.7839  | Test acc: 0.6773\n",
      "\n",
      " Train loss: 0.0034705044236034155 | Test loss: 4.6874  | Test acc: 0.6084\n",
      "\n",
      " Train loss: 0.0023493056651204824 | Test loss: 4.1832  | Test acc: 0.6177\n",
      "\n",
      " Train loss: 0.003028779523447156 | Test loss: 2.6321  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0017261859029531479 | Test loss: 2.3596  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0010006178636103868 | Test loss: 2.7634  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.0019265003502368927 | Test loss: 3.1804  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.000584073131904006 | Test loss: 3.4876  | Test acc: 0.6939\n",
      "\n",
      " Train loss: 0.0010924109956249595 | Test loss: 3.1674  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0018627903191372752 | Test loss: 2.5178  | Test acc: 0.7276\n",
      "\n",
      " Train loss: 0.0017194519750773907 | Test loss: 1.9057  | Test acc: 0.7903\n",
      "\n",
      " Train loss: 0.000307313195662573 | Test loss: 1.8773  | Test acc: 0.7949\n",
      "\n",
      " Train loss: 0.0009210327407345176 | Test loss: 2.1461  | Test acc: 0.7654\n",
      "\n",
      " Train loss: 0.000861557200551033 | Test loss: 2.1956  | Test acc: 0.7665\n",
      "\n",
      " Train loss: 0.0013136212946847081 | Test loss: 2.2915  | Test acc: 0.7679\n",
      "\n",
      " Train loss: 0.0016112271696329117 | Test loss: 2.3331  | Test acc: 0.7643\n",
      "\n",
      " Train loss: 0.002661721548065543 | Test loss: 2.4471  | Test acc: 0.7548\n",
      "\n",
      " Train loss: 0.0014902567490935326 | Test loss: 2.5605  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.001031674211844802 | Test loss: 2.3695  | Test acc: 0.7492\n",
      "\n",
      " Train loss: 0.000865667243488133 | Test loss: 2.1999  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0010241195559501648 | Test loss: 1.8163  | Test acc: 0.7799\n",
      "\n",
      " Train loss: 0.0005778295453637838 | Test loss: 1.9482  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0004458879993762821 | Test loss: 2.0544  | Test acc: 0.7489\n",
      "\n",
      " Train loss: 0.00036286114482209086 | Test loss: 1.8411  | Test acc: 0.7716\n",
      "\n",
      " Train loss: 0.0007979756919667125 | Test loss: 2.0212  | Test acc: 0.7758\n",
      "\n",
      " Train loss: 0.0009300117962993681 | Test loss: 2.5029  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0011185016483068466 | Test loss: 3.1155  | Test acc: 0.7343\n",
      "\n",
      " Train loss: 0.0009142594062723219 | Test loss: 3.5035  | Test acc: 0.7064\n",
      "\n",
      " Train loss: 0.00011608502245508134 | Test loss: 3.9515  | Test acc: 0.6777\n",
      "\n",
      " Train loss: 0.0037785565946251154 | Test loss: 2.6198  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.0008401739760302007 | Test loss: 2.1559  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.001016879454255104 | Test loss: 2.5511  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.0017722315387800336 | Test loss: 2.2926  | Test acc: 0.7173\n",
      "\n",
      " Train loss: 0.0005842330283485353 | Test loss: 2.8292  | Test acc: 0.7072\n",
      "\n",
      " Train loss: 0.0016557396156713367 | Test loss: 3.4165  | Test acc: 0.6650\n",
      "\n",
      " Train loss: 0.0009104665950872004 | Test loss: 3.5492  | Test acc: 0.6691\n",
      "\n",
      " Train loss: 0.0013500252971425653 | Test loss: 2.5986  | Test acc: 0.7428\n",
      "\n",
      " Train loss: 0.0015928888460621238 | Test loss: 1.9105  | Test acc: 0.7785\n",
      "\n",
      " Train loss: 0.001748025300912559 | Test loss: 2.0807  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0010781317250803113 | Test loss: 2.6439  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.001448951312340796 | Test loss: 3.0354  | Test acc: 0.7266\n",
      "\n",
      " Train loss: 0.001080490997992456 | Test loss: 3.6873  | Test acc: 0.7007\n",
      "\n",
      " Train loss: 0.0007515219622291625 | Test loss: 4.1388  | Test acc: 0.6792\n",
      "\n",
      " Train loss: 0.001601281575858593 | Test loss: 3.8523  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0019536931067705154 | Test loss: 2.0679  | Test acc: 0.7776\n",
      "\n",
      " Train loss: 0.0006836974644102156 | Test loss: 2.3430  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0022650528699159622 | Test loss: 2.7084  | Test acc: 0.7266\n",
      "\n",
      " Train loss: 0.0008137299446389079 | Test loss: 4.0944  | Test acc: 0.6697\n",
      "\n",
      " Train loss: 0.0014882647665217519 | Test loss: 3.3549  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0010237874230369925 | Test loss: 2.6377  | Test acc: 0.7707\n",
      "\n",
      " Train loss: 0.001398962689563632 | Test loss: 2.4452  | Test acc: 0.7675\n",
      "\n",
      " Train loss: 0.0012353628408163786 | Test loss: 2.8214  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0016175189521163702 | Test loss: 2.8515  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.003018861636519432 | Test loss: 3.3117  | Test acc: 0.6970\n",
      "Looked at 51200/ 60000 samples\n",
      "\n",
      " Train loss: 0.0006551548722200096 | Test loss: 3.4970  | Test acc: 0.6845\n",
      "\n",
      " Train loss: 0.0009515170240774751 | Test loss: 2.9694  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0008804561803117394 | Test loss: 3.3269  | Test acc: 0.7008\n",
      "\n",
      " Train loss: 0.002835310762748122 | Test loss: 2.9350  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0033996787387877703 | Test loss: 3.0503  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.0011250769020989537 | Test loss: 3.7089  | Test acc: 0.6862\n",
      "\n",
      " Train loss: 0.0017192583763971925 | Test loss: 3.5124  | Test acc: 0.6896\n",
      "\n",
      " Train loss: 0.0013478894252330065 | Test loss: 2.8064  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.0012677897466346622 | Test loss: 2.9556  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.003216678975149989 | Test loss: 2.8199  | Test acc: 0.7361\n",
      "\n",
      " Train loss: 0.0006395715172402561 | Test loss: 2.4534  | Test acc: 0.7577\n",
      "\n",
      " Train loss: 0.0006499288138002157 | Test loss: 2.5668  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.002804490039125085 | Test loss: 2.4053  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.0017898030346259475 | Test loss: 2.5343  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0020535425283014774 | Test loss: 2.8772  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.0009570890688337386 | Test loss: 3.4056  | Test acc: 0.6863\n",
      "\n",
      " Train loss: 0.0010588656878098845 | Test loss: 4.2586  | Test acc: 0.6256\n",
      "\n",
      " Train loss: 0.0047196815721690655 | Test loss: 3.9301  | Test acc: 0.6481\n",
      "\n",
      " Train loss: 0.0019467876991257071 | Test loss: 2.7651  | Test acc: 0.7501\n",
      "\n",
      " Train loss: 0.001193878473713994 | Test loss: 3.3902  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.0011023960541933775 | Test loss: 3.6134  | Test acc: 0.6926\n",
      "\n",
      " Train loss: 0.002316087018698454 | Test loss: 2.9316  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0026786711532622576 | Test loss: 3.1834  | Test acc: 0.6506\n",
      "\n",
      " Train loss: 0.0007972123567014933 | Test loss: 3.4119  | Test acc: 0.6771\n",
      "\n",
      " Train loss: 0.0012476872652769089 | Test loss: 4.1323  | Test acc: 0.6562\n",
      "\n",
      " Train loss: 0.001868190593086183 | Test loss: 3.7655  | Test acc: 0.6846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.001607099431566894 | Test loss: 3.7492  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.0013589111622422934 | Test loss: 3.2343  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.002551889978349209 | Test loss: 2.6777  | Test acc: 0.7149\n",
      "\n",
      " Train loss: 0.003039794974029064 | Test loss: 2.3191  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.0011780825443565845 | Test loss: 2.5362  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.002535001141950488 | Test loss: 3.5835  | Test acc: 0.7079\n",
      "\n",
      " Train loss: 0.0009010218200273812 | Test loss: 4.6060  | Test acc: 0.6734\n",
      "\n",
      " Train loss: 0.002572376513853669 | Test loss: 4.4041  | Test acc: 0.6868\n",
      "\n",
      " Train loss: 0.0022034526336938143 | Test loss: 3.4265  | Test acc: 0.7318\n",
      "\n",
      " Train loss: 0.0015338393859565258 | Test loss: 2.9990  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.001086900825612247 | Test loss: 2.9370  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0009955315617844462 | Test loss: 2.9964  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.0013844252098351717 | Test loss: 3.3885  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0011082293931394815 | Test loss: 3.6292  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0009268817957490683 | Test loss: 3.3222  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.001232039649039507 | Test loss: 3.7389  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.00032475011539645493 | Test loss: 5.1932  | Test acc: 0.6961\n",
      "\n",
      " Train loss: 0.002627264941111207 | Test loss: 3.7030  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.003313611261546612 | Test loss: 3.7647  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.0013389986706897616 | Test loss: 4.2317  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0010295258834958076 | Test loss: 4.7386  | Test acc: 0.7316\n",
      "\n",
      " Train loss: 0.0026103737764060497 | Test loss: 5.7877  | Test acc: 0.6983\n",
      "\n",
      " Train loss: 0.002670282032340765 | Test loss: 6.2736  | Test acc: 0.6712\n",
      "\n",
      " Train loss: 0.0032705652993172407 | Test loss: 5.0116  | Test acc: 0.6402\n",
      "\n",
      " Train loss: 0.0018858590628951788 | Test loss: 4.2558  | Test acc: 0.6723\n",
      "\n",
      " Train loss: 0.002526788040995598 | Test loss: 3.3511  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.0015533538535237312 | Test loss: 4.4401  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0034253934863954782 | Test loss: 5.1870  | Test acc: 0.6601\n",
      "\n",
      " Train loss: 0.0018987244693562388 | Test loss: 4.6243  | Test acc: 0.6548\n",
      "\n",
      " Train loss: 0.0028615600895136595 | Test loss: 6.0150  | Test acc: 0.6100\n",
      "\n",
      " Train loss: 0.0030709074344486 | Test loss: 6.7135  | Test acc: 0.6194\n",
      "\n",
      " Train loss: 0.0032789590768516064 | Test loss: 5.1804  | Test acc: 0.6565\n",
      "\n",
      " Train loss: 0.0015588661190122366 | Test loss: 4.8221  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.003953893668949604 | Test loss: 4.9689  | Test acc: 0.7098\n",
      "\n",
      " Train loss: 0.003927571699023247 | Test loss: 4.6870  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.0035301856696605682 | Test loss: 3.7057  | Test acc: 0.7253\n",
      "\n",
      " Train loss: 0.0012843169970437884 | Test loss: 3.2722  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.001246253727003932 | Test loss: 3.6539  | Test acc: 0.6842\n",
      "\n",
      " Train loss: 0.0012403579894453287 | Test loss: 4.8799  | Test acc: 0.6418\n",
      "\n",
      " Train loss: 0.002535919426009059 | Test loss: 4.2845  | Test acc: 0.6690\n",
      "\n",
      " Train loss: 0.0028839451260864735 | Test loss: 3.3537  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0030742757953703403 | Test loss: 3.3941  | Test acc: 0.7410\n",
      "\n",
      " Train loss: 0.0014209357323125005 | Test loss: 3.8748  | Test acc: 0.7144\n",
      "\n",
      " Train loss: 0.0004320670268498361 | Test loss: 3.8833  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0014846626436337829 | Test loss: 3.9935  | Test acc: 0.7012\n",
      "\n",
      " Train loss: 0.0033271810971200466 | Test loss: 4.4080  | Test acc: 0.6924\n",
      "\n",
      " Train loss: 0.0011634689290076494 | Test loss: 4.7259  | Test acc: 0.6523\n",
      "\n",
      " Train loss: 0.0016070050187408924 | Test loss: 4.8454  | Test acc: 0.6361\n",
      "\n",
      " Train loss: 0.0024889057967811823 | Test loss: 4.4625  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.0034741649869829416 | Test loss: 4.2852  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.0038384515792131424 | Test loss: 4.2924  | Test acc: 0.7158\n",
      "\n",
      " Train loss: 0.0023119396064430475 | Test loss: 3.8926  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.0028827672358602285 | Test loss: 4.2757  | Test acc: 0.7001\n",
      "\n",
      " Train loss: 0.0016661562258377671 | Test loss: 3.8526  | Test acc: 0.7038\n",
      "\n",
      " Train loss: 0.001781623694114387 | Test loss: 3.8659  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.003228873712942004 | Test loss: 4.8824  | Test acc: 0.6615\n",
      "\n",
      " Train loss: 0.0037891995161771774 | Test loss: 3.8183  | Test acc: 0.7016\n",
      "\n",
      " Train loss: 0.002861899323761463 | Test loss: 3.3951  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0016357642598450184 | Test loss: 3.9726  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0022787994239479303 | Test loss: 3.4276  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0011803822126239538 | Test loss: 5.7294  | Test acc: 0.6411\n",
      "\n",
      " Train loss: 0.0024397270753979683 | Test loss: 6.5639  | Test acc: 0.6263\n",
      "\n",
      " Train loss: 0.0038120087701827288 | Test loss: 5.4366  | Test acc: 0.6736\n",
      "\n",
      " Train loss: 0.0021170799154788256 | Test loss: 4.5779  | Test acc: 0.6911\n",
      "\n",
      " Train loss: 0.0015481747686862946 | Test loss: 4.0064  | Test acc: 0.6854\n",
      "\n",
      " Train loss: 0.00206947629339993 | Test loss: 3.5681  | Test acc: 0.6923\n",
      "\n",
      " Train loss: 0.0010230573825538158 | Test loss: 3.6873  | Test acc: 0.6977\n",
      "\n",
      " Train loss: 0.0015954998089000583 | Test loss: 3.2657  | Test acc: 0.7301\n",
      "\n",
      " Train loss: 0.000652112124953419 | Test loss: 3.7720  | Test acc: 0.7121\n",
      "\n",
      " Train loss: 0.0021919873543083668 | Test loss: 3.9437  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.001155301695689559 | Test loss: 4.2774  | Test acc: 0.6760\n",
      "\n",
      " Train loss: 0.002839643508195877 | Test loss: 3.5464  | Test acc: 0.7080\n",
      "\n",
      " Train loss: 0.0016925280215218663 | Test loss: 3.6034  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0017616470577195287 | Test loss: 3.5160  | Test acc: 0.7153\n",
      "\n",
      " Train loss: 0.001837066258303821 | Test loss: 3.0844  | Test acc: 0.7337\n",
      "\n",
      " Train loss: 0.0013903097715228796 | Test loss: 3.1522  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0011054035276174545 | Test loss: 4.4072  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.0020398893393576145 | Test loss: 4.6168  | Test acc: 0.6924\n",
      "\n",
      " Train loss: 0.0013124236138537526 | Test loss: 3.6498  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.0003844898601528257 | Test loss: 2.8788  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.0023793685249984264 | Test loss: 2.6242  | Test acc: 0.7562\n",
      "\n",
      " Train loss: 0.0006784136639907956 | Test loss: 2.6461  | Test acc: 0.7519\n",
      "\n",
      " Train loss: 0.0006260995287448168 | Test loss: 2.7438  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0014473387273028493 | Test loss: 2.6185  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.00240137311629951 | Test loss: 2.9286  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.0005589908687397838 | Test loss: 3.3804  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0010880589252337813 | Test loss: 3.4890  | Test acc: 0.6821\n",
      "\n",
      " Train loss: 0.0013038935139775276 | Test loss: 2.7980  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0009705983684398234 | Test loss: 2.5613  | Test acc: 0.7531\n",
      "\n",
      " Train loss: 0.001111556077376008 | Test loss: 2.8361  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.0013465792872011662 | Test loss: 3.2857  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.002272364916279912 | Test loss: 3.4628  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.0009009703062474728 | Test loss: 3.4559  | Test acc: 0.7222\n",
      "\n",
      " Train loss: 0.00038720094016753137 | Test loss: 3.3032  | Test acc: 0.7304\n",
      "\n",
      " Train loss: 0.0006723245023749769 | Test loss: 3.0491  | Test acc: 0.7380\n",
      "\n",
      " Train loss: 0.001235979376360774 | Test loss: 2.8753  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.0012959626037627459 | Test loss: 3.2925  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.0010108030401170254 | Test loss: 3.3970  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0017214970430359244 | Test loss: 3.7026  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.0013131604064255953 | Test loss: 3.1302  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.002480732509866357 | Test loss: 2.1876  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0015281399246305227 | Test loss: 2.0620  | Test acc: 0.7772\n",
      "\n",
      " Train loss: 0.001364501309581101 | Test loss: 2.5294  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.00111941690556705 | Test loss: 3.0886  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.0012225126847624779 | Test loss: 2.8923  | Test acc: 0.7114\n",
      "\n",
      " Train loss: 0.001381079200655222 | Test loss: 2.3633  | Test acc: 0.7250\n",
      "\n",
      " Train loss: 0.0010664928704500198 | Test loss: 2.3322  | Test acc: 0.6960\n",
      "\n",
      " Train loss: 0.0008506847661919892 | Test loss: 2.9921  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0008552729268558323 | Test loss: 4.0305  | Test acc: 0.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0027094390243291855 | Test loss: 4.0085  | Test acc: 0.6697\n",
      "\n",
      " Train loss: 0.0011213585967198014 | Test loss: 3.1749  | Test acc: 0.6601\n",
      "\n",
      " Train loss: 0.003147626295685768 | Test loss: 2.7340  | Test acc: 0.6848\n",
      "\n",
      " Train loss: 0.0018499611178413033 | Test loss: 4.5133  | Test acc: 0.6246\n",
      "\n",
      " Train loss: 0.003472123062238097 | Test loss: 3.6697  | Test acc: 0.6718\n",
      "\n",
      " Train loss: 0.002437426010146737 | Test loss: 2.4134  | Test acc: 0.7123\n",
      "\n",
      " Train loss: 0.0021889901254326105 | Test loss: 2.3823  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.0013358424184843898 | Test loss: 3.1198  | Test acc: 0.7106\n",
      "\n",
      " Train loss: 0.001288596191443503 | Test loss: 4.2362  | Test acc: 0.6668\n",
      "\n",
      " Train loss: 0.0019807268399745226 | Test loss: 4.6066  | Test acc: 0.6429\n",
      "\n",
      " Train loss: 0.0024220377672463655 | Test loss: 4.4215  | Test acc: 0.6213\n",
      "\n",
      " Train loss: 0.0018949871882796288 | Test loss: 4.4584  | Test acc: 0.6209\n",
      "\n",
      " Train loss: 0.00316299544647336 | Test loss: 5.1112  | Test acc: 0.5765\n",
      "\n",
      " Train loss: 0.0037484201602637768 | Test loss: 3.4716  | Test acc: 0.7007\n",
      "\n",
      " Train loss: 0.001511403825134039 | Test loss: 3.3371  | Test acc: 0.6637\n",
      "\n",
      " Train loss: 0.0008614546386525035 | Test loss: 5.3941  | Test acc: 0.6270\n",
      "\n",
      " Train loss: 0.0021978693548589945 | Test loss: 4.9947  | Test acc: 0.6424\n",
      "\n",
      " Train loss: 0.0016520345816388726 | Test loss: 3.6887  | Test acc: 0.6885\n",
      "\n",
      " Train loss: 0.0035959677770733833 | Test loss: 2.6606  | Test acc: 0.7490\n",
      "\n",
      " Train loss: 0.00032429079874418676 | Test loss: 3.9954  | Test acc: 0.7112\n",
      "\n",
      " Train loss: 0.0018376857042312622 | Test loss: 5.3317  | Test acc: 0.6711\n",
      "\n",
      " Train loss: 0.0021983939222991467 | Test loss: 6.2061  | Test acc: 0.6460\n",
      "\n",
      " Train loss: 0.002300608903169632 | Test loss: 5.8465  | Test acc: 0.6418\n",
      "\n",
      " Train loss: 0.0031452185939997435 | Test loss: 6.9756  | Test acc: 0.6032\n",
      "\n",
      " Train loss: 0.002238607732579112 | Test loss: 6.2115  | Test acc: 0.6705\n",
      "\n",
      " Train loss: 0.0021784408017992973 | Test loss: 5.8924  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.003616876667365432 | Test loss: 4.9794  | Test acc: 0.7089\n",
      "\n",
      " Train loss: 0.004481172189116478 | Test loss: 4.3196  | Test acc: 0.7149\n",
      "\n",
      " Train loss: 0.002263052621856332 | Test loss: 4.7186  | Test acc: 0.7184\n",
      "\n",
      " Train loss: 0.0038431412540376186 | Test loss: 6.3787  | Test acc: 0.6795\n",
      "\n",
      " Train loss: 0.002175337867811322 | Test loss: 6.2772  | Test acc: 0.6759\n",
      "\n",
      " Train loss: 0.0024420793633908033 | Test loss: 4.4933  | Test acc: 0.7204\n",
      "\n",
      " Train loss: 0.001953110215254128 | Test loss: 3.9688  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.0016678596148267388 | Test loss: 4.5233  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.004696338437497616 | Test loss: 3.8325  | Test acc: 0.7495\n",
      "\n",
      " Train loss: 0.0009206039248965681 | Test loss: 3.5646  | Test acc: 0.7655\n",
      "\n",
      " Train loss: 0.0030504418537020683 | Test loss: 3.7088  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.0006574610015377402 | Test loss: 3.9870  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.0030208395328372717 | Test loss: 3.8734  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.002189608523622155 | Test loss: 3.7266  | Test acc: 0.7803\n",
      "\n",
      " Train loss: 0.0025545808020979166 | Test loss: 3.1334  | Test acc: 0.7837\n",
      "\n",
      " Train loss: 0.0019652682822197676 | Test loss: 3.7993  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.0026849498972296715 | Test loss: 4.1716  | Test acc: 0.7262\n",
      "\n",
      " Train loss: 0.0008407995337620378 | Test loss: 3.9654  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.0007321248995140195 | Test loss: 3.5585  | Test acc: 0.7644\n",
      "\n",
      " Train loss: 0.001293882611207664 | Test loss: 3.3367  | Test acc: 0.7707\n",
      "\n",
      " Train loss: 0.0018578494200482965 | Test loss: 2.6184  | Test acc: 0.7976\n",
      "\n",
      " Train loss: 0.00029942969558760524 | Test loss: 3.0293  | Test acc: 0.7649\n",
      "\n",
      " Train loss: 0.0006549062090925872 | Test loss: 3.7040  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0008688302477821708 | Test loss: 3.8601  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0018942489987239242 | Test loss: 3.0900  | Test acc: 0.7550\n",
      "\n",
      " Train loss: 0.0021678463090211153 | Test loss: 3.7190  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.001772817107848823 | Test loss: 4.5316  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0015853779623284936 | Test loss: 4.0113  | Test acc: 0.7281\n",
      "\n",
      " Train loss: 0.0025948600377887487 | Test loss: 3.4369  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.00019809648802038282 | Test loss: 3.8877  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0016516936011612415 | Test loss: 4.6655  | Test acc: 0.6802\n",
      "\n",
      " Train loss: 0.0008466803701594472 | Test loss: 5.6075  | Test acc: 0.6705\n",
      "\n",
      " Train loss: 0.001846978673711419 | Test loss: 5.4601  | Test acc: 0.6912\n",
      "\n",
      " Train loss: 0.002300478983670473 | Test loss: 4.8416  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.005264362785965204 | Test loss: 3.9569  | Test acc: 0.7332\n",
      "\n",
      " Train loss: 0.0024074933025985956 | Test loss: 2.8138  | Test acc: 0.7763\n",
      "\n",
      " Train loss: 0.002028785878792405 | Test loss: 3.3673  | Test acc: 0.7122\n",
      "\n",
      " Train loss: 0.0013380555901676416 | Test loss: 4.4242  | Test acc: 0.6811\n",
      "\n",
      " Train loss: 0.0011966029414907098 | Test loss: 4.9365  | Test acc: 0.6797\n",
      "\n",
      " Train loss: 0.0033792448230087757 | Test loss: 4.2922  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0025767169427126646 | Test loss: 3.1873  | Test acc: 0.7247\n",
      "\n",
      " Train loss: 0.0006362215499393642 | Test loss: 4.4314  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.002100530778989196 | Test loss: 4.8230  | Test acc: 0.6764\n",
      "\n",
      " Train loss: 0.0035003225784748793 | Test loss: 4.1928  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0005949867190793157 | Test loss: 4.6354  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.0017110825283452868 | Test loss: 3.5135  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0016559985233470798 | Test loss: 2.8901  | Test acc: 0.7399\n",
      "\n",
      " Train loss: 0.0005948320031166077 | Test loss: 3.8502  | Test acc: 0.6856\n",
      "\n",
      " Train loss: 0.0012609614059329033 | Test loss: 6.3298  | Test acc: 0.6140\n",
      "\n",
      " Train loss: 0.0037859848234802485 | Test loss: 7.1896  | Test acc: 0.6002\n",
      "\n",
      " Train loss: 0.0032913603354245424 | Test loss: 5.8460  | Test acc: 0.6443\n",
      "\n",
      " Train loss: 0.002151878783479333 | Test loss: 6.2005  | Test acc: 0.6798\n",
      "\n",
      " Train loss: 0.004649396985769272 | Test loss: 5.8410  | Test acc: 0.6833\n",
      "\n",
      " Train loss: 0.0019814970437437296 | Test loss: 4.6581  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0011727166129276156 | Test loss: 5.9366  | Test acc: 0.6757\n",
      "\n",
      " Train loss: 0.0027472989168018103 | Test loss: 5.1287  | Test acc: 0.7310\n",
      "\n",
      " Train loss: 0.0015860049752518535 | Test loss: 4.4347  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.0015617328463122249 | Test loss: 3.8052  | Test acc: 0.7479\n",
      "\n",
      " Train loss: 0.0012068060459569097 | Test loss: 4.9712  | Test acc: 0.6779\n",
      "\n",
      " Train loss: 0.0015384787693619728 | Test loss: 5.8463  | Test acc: 0.6437\n",
      "\n",
      " Train loss: 0.0019967358093708754 | Test loss: 5.3488  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.0031218978110700846 | Test loss: 6.1543  | Test acc: 0.6912\n",
      "\n",
      " Train loss: 0.005195443518459797 | Test loss: 8.7375  | Test acc: 0.6392\n",
      "\n",
      " Train loss: 0.004215506836771965 | Test loss: 12.2786  | Test acc: 0.6024\n",
      "\n",
      " Train loss: 0.002558900974690914 | Test loss: 12.7983  | Test acc: 0.5870\n",
      "\n",
      " Train loss: 0.004535263404250145 | Test loss: 9.8883  | Test acc: 0.6208\n",
      "\n",
      " Train loss: 0.00622910400852561 | Test loss: 8.5397  | Test acc: 0.6561\n",
      "\n",
      " Train loss: 0.008736517280340195 | Test loss: 5.6236  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.0007703325245529413 | Test loss: 8.2086  | Test acc: 0.6185\n",
      "\n",
      " Train loss: 0.004094831645488739 | Test loss: 10.8287  | Test acc: 0.5749\n",
      "\n",
      " Train loss: 0.004171713721007109 | Test loss: 8.5229  | Test acc: 0.6229\n",
      "\n",
      " Train loss: 0.007773214019834995 | Test loss: 5.1039  | Test acc: 0.7044\n",
      "\n",
      " Train loss: 0.0012149029644206166 | Test loss: 5.0519  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.00144245196133852 | Test loss: 7.3098  | Test acc: 0.6906\n",
      "\n",
      " Train loss: 0.0048135556280612946 | Test loss: 7.9101  | Test acc: 0.6853\n",
      "\n",
      " Train loss: 0.0026051027234643698 | Test loss: 6.9541  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0014030690072104335 | Test loss: 7.2424  | Test acc: 0.6932\n",
      "\n",
      " Train loss: 0.003645974677056074 | Test loss: 6.6545  | Test acc: 0.7006\n",
      "\n",
      " Train loss: 0.0027401188854128122 | Test loss: 7.3798  | Test acc: 0.6541\n",
      "\n",
      " Train loss: 0.0031931293196976185 | Test loss: 6.5399  | Test acc: 0.6925\n",
      "\n",
      " Train loss: 0.0030131370294839144 | Test loss: 9.4172  | Test acc: 0.6286\n",
      "\n",
      " Train loss: 0.0029271207749843597 | Test loss: 12.2068  | Test acc: 0.6349\n",
      "\n",
      " Train loss: 0.0016071484424173832 | Test loss: 13.0369  | Test acc: 0.6445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.004779189359396696 | Test loss: 9.4206  | Test acc: 0.6744\n",
      "\n",
      " Train loss: 0.002519560744985938 | Test loss: 8.4127  | Test acc: 0.6976\n",
      "\n",
      " Train loss: 0.0025022064801305532 | Test loss: 8.1457  | Test acc: 0.7017\n",
      "\n",
      " Train loss: 0.0045996736735105515 | Test loss: 8.4495  | Test acc: 0.6859\n",
      "\n",
      " Train loss: 0.004585843533277512 | Test loss: 6.7376  | Test acc: 0.6962\n",
      "\n",
      " Train loss: 0.004624647554010153 | Test loss: 6.7076  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0038701887242496014 | Test loss: 7.4045  | Test acc: 0.7037\n",
      "\n",
      " Train loss: 0.002994913375005126 | Test loss: 6.8820  | Test acc: 0.6874\n",
      "\n",
      " Train loss: 0.0027242011856287718 | Test loss: 7.5262  | Test acc: 0.6757\n",
      "\n",
      " Train loss: 0.003504300257191062 | Test loss: 7.3540  | Test acc: 0.6838\n",
      "\n",
      " Train loss: 0.004185730125755072 | Test loss: 7.2964  | Test acc: 0.6924\n",
      "\n",
      " Train loss: 0.004178323317319155 | Test loss: 7.1766  | Test acc: 0.6764\n",
      "\n",
      " Train loss: 0.0023820686619728804 | Test loss: 6.3374  | Test acc: 0.6886\n",
      "\n",
      " Train loss: 0.001092857914045453 | Test loss: 5.3807  | Test acc: 0.7176\n",
      "\n",
      " Train loss: 0.0015136467991396785 | Test loss: 5.2215  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.002280367538332939 | Test loss: 6.1025  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.002739272778853774 | Test loss: 5.5473  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.005396377760916948 | Test loss: 5.1386  | Test acc: 0.7461\n",
      "\n",
      " Train loss: 0.004165359307080507 | Test loss: 5.7650  | Test acc: 0.7340\n",
      "\n",
      " Train loss: 0.0030916372779756784 | Test loss: 8.1905  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.007024759892374277 | Test loss: 5.8252  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.00620367843657732 | Test loss: 5.6599  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0022011972032487392 | Test loss: 6.4923  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0030146855860948563 | Test loss: 4.0667  | Test acc: 0.7680\n",
      "\n",
      " Train loss: 0.0014556501992046833 | Test loss: 4.7660  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.002465681405737996 | Test loss: 6.2094  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.006082457955926657 | Test loss: 4.7603  | Test acc: 0.7516\n",
      "\n",
      " Train loss: 0.002831149846315384 | Test loss: 4.3136  | Test acc: 0.7589\n",
      "\n",
      " Train loss: 0.004312427714467049 | Test loss: 4.9095  | Test acc: 0.7376\n",
      "\n",
      " Train loss: 0.0028728926554322243 | Test loss: 5.5966  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.0026607222389429808 | Test loss: 5.5661  | Test acc: 0.7305\n",
      "Epoch 1\n",
      "------\n",
      "Looked at 0/ 60000 samples\n",
      "\n",
      " Train loss: 0.003408291842788458 | Test loss: 4.7634  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0011812489246949553 | Test loss: 5.6782  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.002704792423173785 | Test loss: 5.6731  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.002712379675358534 | Test loss: 5.2923  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.002311896299943328 | Test loss: 4.5018  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.0020957922097295523 | Test loss: 5.0366  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.0025389697402715683 | Test loss: 5.1605  | Test acc: 0.7080\n",
      "\n",
      " Train loss: 0.0020488800946623087 | Test loss: 5.7202  | Test acc: 0.6627\n",
      "\n",
      " Train loss: 0.0026319166645407677 | Test loss: 5.6376  | Test acc: 0.6515\n",
      "\n",
      " Train loss: 0.003221692983061075 | Test loss: 4.6475  | Test acc: 0.6875\n",
      "\n",
      " Train loss: 0.0017563092987984419 | Test loss: 3.8667  | Test acc: 0.7192\n",
      "\n",
      " Train loss: 0.0020217045675963163 | Test loss: 4.2341  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.00062985421391204 | Test loss: 5.8352  | Test acc: 0.6827\n",
      "\n",
      " Train loss: 0.0036898308899253607 | Test loss: 6.1222  | Test acc: 0.6727\n",
      "\n",
      " Train loss: 0.0028988865669816732 | Test loss: 5.2897  | Test acc: 0.6931\n",
      "\n",
      " Train loss: 0.00295323901809752 | Test loss: 4.0574  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.001695761689916253 | Test loss: 4.1190  | Test acc: 0.7122\n",
      "\n",
      " Train loss: 0.0021222438663244247 | Test loss: 3.9847  | Test acc: 0.7460\n",
      "\n",
      " Train loss: 0.001505218562670052 | Test loss: 4.1844  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.002193131484091282 | Test loss: 4.3813  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0022269650362432003 | Test loss: 4.2296  | Test acc: 0.7346\n",
      "\n",
      " Train loss: 0.0017343306681141257 | Test loss: 4.1788  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.0017614252865314484 | Test loss: 4.6146  | Test acc: 0.6938\n",
      "\n",
      " Train loss: 0.005408445373177528 | Test loss: 4.6886  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.002561847912147641 | Test loss: 3.7511  | Test acc: 0.6972\n",
      "\n",
      " Train loss: 0.002443907782435417 | Test loss: 3.1733  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.001018464332446456 | Test loss: 2.9261  | Test acc: 0.7423\n",
      "\n",
      " Train loss: 0.0008067954913713038 | Test loss: 3.5086  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.0011586645850911736 | Test loss: 3.8480  | Test acc: 0.7268\n",
      "\n",
      " Train loss: 0.0020678990986198187 | Test loss: 4.1512  | Test acc: 0.7101\n",
      "\n",
      " Train loss: 0.0013572194147855043 | Test loss: 6.1615  | Test acc: 0.6599\n",
      "\n",
      " Train loss: 0.003927970305085182 | Test loss: 6.1628  | Test acc: 0.6602\n",
      "\n",
      " Train loss: 0.0030292372684925795 | Test loss: 3.8955  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0032083592377603054 | Test loss: 2.9838  | Test acc: 0.7442\n",
      "\n",
      " Train loss: 0.0008583512390032411 | Test loss: 3.4486  | Test acc: 0.7179\n",
      "\n",
      " Train loss: 0.002188789891079068 | Test loss: 3.3440  | Test acc: 0.7174\n",
      "\n",
      " Train loss: 0.001823093043640256 | Test loss: 3.2169  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.0008365071844309568 | Test loss: 3.3511  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.0015178442699834704 | Test loss: 4.9278  | Test acc: 0.6902\n",
      "\n",
      " Train loss: 0.0017331524286419153 | Test loss: 5.5542  | Test acc: 0.6813\n",
      "\n",
      " Train loss: 0.003977851010859013 | Test loss: 4.3918  | Test acc: 0.7222\n",
      "\n",
      " Train loss: 0.0017547240713611245 | Test loss: 3.7173  | Test acc: 0.7448\n",
      "\n",
      " Train loss: 0.0005779596394859254 | Test loss: 4.5013  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.001920534297823906 | Test loss: 4.5191  | Test acc: 0.6877\n",
      "\n",
      " Train loss: 0.0029034779872745275 | Test loss: 3.4428  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.0024589160457253456 | Test loss: 3.0195  | Test acc: 0.7833\n",
      "\n",
      " Train loss: 0.0007856014999561012 | Test loss: 3.2660  | Test acc: 0.7827\n",
      "\n",
      " Train loss: 0.005360520910471678 | Test loss: 3.2656  | Test acc: 0.7741\n",
      "\n",
      " Train loss: 0.0014207653002813458 | Test loss: 3.7411  | Test acc: 0.7701\n",
      "\n",
      " Train loss: 0.002339580561965704 | Test loss: 3.7580  | Test acc: 0.7642\n",
      "\n",
      " Train loss: 0.0013020822079852223 | Test loss: 3.2256  | Test acc: 0.7723\n",
      "\n",
      " Train loss: 0.000348366069374606 | Test loss: 3.3012  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.0004938665661029518 | Test loss: 3.6311  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0018227758118882775 | Test loss: 3.8000  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0019206430297344923 | Test loss: 3.5790  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0011899421224370599 | Test loss: 3.2322  | Test acc: 0.7793\n",
      "\n",
      " Train loss: 0.003659342648461461 | Test loss: 3.1127  | Test acc: 0.7795\n",
      "\n",
      " Train loss: 0.003320015035569668 | Test loss: 2.8144  | Test acc: 0.7798\n",
      "\n",
      " Train loss: 0.001384965144097805 | Test loss: 2.6570  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0007256775279529393 | Test loss: 3.2523  | Test acc: 0.7224\n",
      "\n",
      " Train loss: 0.001306926249526441 | Test loss: 3.0549  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.0011688735103234649 | Test loss: 2.5879  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0014586769975721836 | Test loss: 2.4933  | Test acc: 0.7655\n",
      "\n",
      " Train loss: 0.0006298249354586005 | Test loss: 2.7363  | Test acc: 0.7682\n",
      "\n",
      " Train loss: 0.002670910209417343 | Test loss: 3.0640  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.00098027556668967 | Test loss: 2.7870  | Test acc: 0.7605\n",
      "\n",
      " Train loss: 0.0005813163588754833 | Test loss: 2.6638  | Test acc: 0.7553\n",
      "\n",
      " Train loss: 0.0013505559181794524 | Test loss: 2.3728  | Test acc: 0.7590\n",
      "\n",
      " Train loss: 0.0021809192840009928 | Test loss: 2.8789  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.002358662895858288 | Test loss: 3.5301  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0016289368504658341 | Test loss: 3.8417  | Test acc: 0.6834\n",
      "\n",
      " Train loss: 0.0013542218366637826 | Test loss: 3.6855  | Test acc: 0.6918\n",
      "\n",
      " Train loss: 0.0019143258687108755 | Test loss: 2.7317  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.0013345112092792988 | Test loss: 2.5726  | Test acc: 0.7414\n",
      "\n",
      " Train loss: 0.0009218632476404309 | Test loss: 2.6105  | Test acc: 0.7575\n",
      "\n",
      " Train loss: 0.001990143908187747 | Test loss: 2.7661  | Test acc: 0.7611\n",
      "\n",
      " Train loss: 0.0003963087219744921 | Test loss: 3.3114  | Test acc: 0.7349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0011464088456705213 | Test loss: 4.4618  | Test acc: 0.6827\n",
      "\n",
      " Train loss: 0.0012994292192161083 | Test loss: 4.0989  | Test acc: 0.6952\n",
      "\n",
      " Train loss: 0.0019736499525606632 | Test loss: 3.3915  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0020964399445801973 | Test loss: 2.8425  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.0007394003332592547 | Test loss: 3.2089  | Test acc: 0.7057\n",
      "\n",
      " Train loss: 0.0013850316172465682 | Test loss: 3.0996  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.0017689312808215618 | Test loss: 2.5686  | Test acc: 0.7561\n",
      "\n",
      " Train loss: 0.0007854588329792023 | Test loss: 2.6283  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0012346511939540505 | Test loss: 3.0987  | Test acc: 0.7591\n",
      "\n",
      " Train loss: 0.0006907981587573886 | Test loss: 4.1144  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0009788768365979195 | Test loss: 3.5151  | Test acc: 0.7561\n",
      "\n",
      " Train loss: 0.0017581938300281763 | Test loss: 3.0503  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0010364314075559378 | Test loss: 3.2096  | Test acc: 0.7446\n",
      "\n",
      " Train loss: 0.0014097102684900165 | Test loss: 3.2083  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0004475791356526315 | Test loss: 3.4438  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.003097004257142544 | Test loss: 3.8052  | Test acc: 0.7337\n",
      "\n",
      " Train loss: 0.002138192765414715 | Test loss: 5.4776  | Test acc: 0.6742\n",
      "\n",
      " Train loss: 0.002074618823826313 | Test loss: 6.8273  | Test acc: 0.6594\n",
      "\n",
      " Train loss: 0.0027514907997101545 | Test loss: 5.3717  | Test acc: 0.6908\n",
      "\n",
      " Train loss: 0.002933251205831766 | Test loss: 4.6278  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.004512049723416567 | Test loss: 4.4930  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0011545869056135416 | Test loss: 5.8241  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.0034185966942459345 | Test loss: 6.3215  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.005397906992584467 | Test loss: 6.2925  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.006673668976873159 | Test loss: 5.8606  | Test acc: 0.6795\n",
      "\n",
      " Train loss: 0.001784637221135199 | Test loss: 4.5628  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.001355186104774475 | Test loss: 4.6895  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.004017690196633339 | Test loss: 3.0956  | Test acc: 0.7664\n",
      "\n",
      " Train loss: 0.001088609336875379 | Test loss: 3.1533  | Test acc: 0.7589\n",
      "\n",
      " Train loss: 0.0015437528491020203 | Test loss: 4.6022  | Test acc: 0.7069\n",
      "\n",
      " Train loss: 0.002123369602486491 | Test loss: 5.7936  | Test acc: 0.6759\n",
      "\n",
      " Train loss: 0.0007601984543725848 | Test loss: 6.7469  | Test acc: 0.6470\n",
      "\n",
      " Train loss: 0.005211047362536192 | Test loss: 5.0249  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.0020561746787279844 | Test loss: 3.9509  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.001720534753985703 | Test loss: 3.6975  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.001108276890590787 | Test loss: 4.2646  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0013874468859285116 | Test loss: 4.3348  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.002460920251905918 | Test loss: 5.0756  | Test acc: 0.6889\n",
      "\n",
      " Train loss: 0.0019160700030624866 | Test loss: 6.9829  | Test acc: 0.6632\n",
      "\n",
      " Train loss: 0.0021280068904161453 | Test loss: 7.7680  | Test acc: 0.6767\n",
      "\n",
      " Train loss: 0.00422440143302083 | Test loss: 6.0303  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0028214571066200733 | Test loss: 3.7379  | Test acc: 0.7516\n",
      "\n",
      " Train loss: 0.001191108487546444 | Test loss: 4.5220  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.0012875014217570424 | Test loss: 5.5924  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0019327802583575249 | Test loss: 5.7907  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0036804669070988894 | Test loss: 3.8623  | Test acc: 0.7420\n",
      "\n",
      " Train loss: 0.0028392851818352938 | Test loss: 3.7351  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.002839359687641263 | Test loss: 4.5271  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.0027200747281312943 | Test loss: 5.2638  | Test acc: 0.7091\n",
      "\n",
      " Train loss: 0.001634028390981257 | Test loss: 5.0935  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.0016796207055449486 | Test loss: 4.2088  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.0009289126610383391 | Test loss: 4.4137  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.003164638765156269 | Test loss: 4.1170  | Test acc: 0.7192\n",
      "\n",
      " Train loss: 0.0015071160160005093 | Test loss: 3.5752  | Test acc: 0.7345\n",
      "\n",
      " Train loss: 0.001240757293999195 | Test loss: 3.9897  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0034728439059108496 | Test loss: 4.0861  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.0017741649644449353 | Test loss: 3.5550  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0019450319232419133 | Test loss: 2.7759  | Test acc: 0.7527\n",
      "\n",
      " Train loss: 0.0015675653703510761 | Test loss: 2.9831  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.0009614804876036942 | Test loss: 4.1985  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.0010731035144999623 | Test loss: 4.9839  | Test acc: 0.6651\n",
      "\n",
      " Train loss: 0.0021248625125736 | Test loss: 4.4647  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.002209148835390806 | Test loss: 3.3860  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0023270207457244396 | Test loss: 3.8133  | Test acc: 0.7346\n",
      "\n",
      " Train loss: 0.0010510791325941682 | Test loss: 4.8041  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.003012146335095167 | Test loss: 4.7513  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.0029056991916149855 | Test loss: 3.9127  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0014128230977803469 | Test loss: 4.8493  | Test acc: 0.6878\n",
      "\n",
      " Train loss: 0.0023668003268539906 | Test loss: 6.8625  | Test acc: 0.6121\n",
      "\n",
      " Train loss: 0.005924963392317295 | Test loss: 5.1576  | Test acc: 0.6641\n",
      "\n",
      " Train loss: 0.0036875749938189983 | Test loss: 6.1776  | Test acc: 0.6224\n",
      "\n",
      " Train loss: 0.0023852286394685507 | Test loss: 6.3464  | Test acc: 0.6557\n",
      "\n",
      " Train loss: 0.002299404237419367 | Test loss: 6.6679  | Test acc: 0.6337\n",
      "\n",
      " Train loss: 0.002499583875760436 | Test loss: 7.7631  | Test acc: 0.6167\n",
      "\n",
      " Train loss: 0.0018775133648887277 | Test loss: 8.7966  | Test acc: 0.6236\n",
      "\n",
      " Train loss: 0.0049367486499249935 | Test loss: 7.3316  | Test acc: 0.6543\n",
      "\n",
      " Train loss: 0.004435421898961067 | Test loss: 5.1959  | Test acc: 0.6938\n",
      "\n",
      " Train loss: 0.0020197166595607996 | Test loss: 6.7685  | Test acc: 0.6785\n",
      "\n",
      " Train loss: 0.0025222711265087128 | Test loss: 9.6523  | Test acc: 0.6132\n",
      "\n",
      " Train loss: 0.008899987675249577 | Test loss: 7.8990  | Test acc: 0.6552\n",
      "\n",
      " Train loss: 0.0041642566211521626 | Test loss: 7.2912  | Test acc: 0.6414\n",
      "\n",
      " Train loss: 0.0042512561194598675 | Test loss: 5.8331  | Test acc: 0.6882\n",
      "\n",
      " Train loss: 0.0022127535194158554 | Test loss: 5.6070  | Test acc: 0.6744\n",
      "\n",
      " Train loss: 0.004082253202795982 | Test loss: 4.8291  | Test acc: 0.7009\n",
      "\n",
      " Train loss: 0.002548954915255308 | Test loss: 4.4881  | Test acc: 0.7045\n",
      "\n",
      " Train loss: 0.00151150394231081 | Test loss: 4.6827  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0031475448049604893 | Test loss: 4.6650  | Test acc: 0.7328\n",
      "\n",
      " Train loss: 0.003655094653367996 | Test loss: 4.6394  | Test acc: 0.7300\n",
      "\n",
      " Train loss: 0.0026746848598122597 | Test loss: 4.2701  | Test acc: 0.7399\n",
      "\n",
      " Train loss: 0.0006970977992750704 | Test loss: 4.1080  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.0007990315789356828 | Test loss: 3.9753  | Test acc: 0.7398\n",
      "\n",
      " Train loss: 0.0012864981545135379 | Test loss: 4.0497  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.0007335686823353171 | Test loss: 4.4181  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.0019272903446108103 | Test loss: 4.0978  | Test acc: 0.7266\n",
      "\n",
      " Train loss: 0.002788373501971364 | Test loss: 4.2442  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0030595215503126383 | Test loss: 3.3918  | Test acc: 0.7748\n",
      "\n",
      " Train loss: 0.0020236640702933073 | Test loss: 3.2316  | Test acc: 0.7796\n",
      "\n",
      " Train loss: 0.0023709323722869158 | Test loss: 3.5400  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0012228927807882428 | Test loss: 4.0013  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.002864160807803273 | Test loss: 3.7547  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.0024796933867037296 | Test loss: 3.1099  | Test acc: 0.7692\n",
      "\n",
      " Train loss: 0.0011926982551813126 | Test loss: 3.3943  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.0014389451825991273 | Test loss: 4.4136  | Test acc: 0.6952\n",
      "\n",
      " Train loss: 0.0022128617856651545 | Test loss: 3.4561  | Test acc: 0.7305\n",
      "\n",
      " Train loss: 0.0017010732553899288 | Test loss: 3.2680  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.0003252299502491951 | Test loss: 4.2962  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.001977022271603346 | Test loss: 4.2068  | Test acc: 0.7150\n",
      "\n",
      " Train loss: 0.001434394740499556 | Test loss: 3.4752  | Test acc: 0.7418\n",
      "\n",
      " Train loss: 0.0019306497415527701 | Test loss: 3.6785  | Test acc: 0.7350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0017786826938390732 | Test loss: 5.2063  | Test acc: 0.6889\n",
      "\n",
      " Train loss: 0.00403405399993062 | Test loss: 5.3979  | Test acc: 0.6690\n",
      "\n",
      " Train loss: 0.0023769421968609095 | Test loss: 4.7735  | Test acc: 0.7058\n",
      "\n",
      " Train loss: 0.0022608244325965643 | Test loss: 4.5454  | Test acc: 0.7109\n",
      "\n",
      " Train loss: 0.00438452186062932 | Test loss: 5.1195  | Test acc: 0.7167\n",
      "\n",
      " Train loss: 0.002590823220089078 | Test loss: 5.7499  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.002651065355166793 | Test loss: 5.8739  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.003743134206160903 | Test loss: 5.1732  | Test acc: 0.7122\n",
      "\n",
      " Train loss: 0.0023869615979492664 | Test loss: 3.7938  | Test acc: 0.7396\n",
      "\n",
      " Train loss: 0.0013870281400159001 | Test loss: 3.2880  | Test acc: 0.7207\n",
      "\n",
      " Train loss: 0.0013615605421364307 | Test loss: 3.0663  | Test acc: 0.7282\n",
      "\n",
      " Train loss: 0.001050868071615696 | Test loss: 3.1160  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0011504263384267688 | Test loss: 3.3665  | Test acc: 0.7180\n",
      "\n",
      " Train loss: 0.0022904572542756796 | Test loss: 3.0958  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.002508794190362096 | Test loss: 2.4439  | Test acc: 0.7771\n",
      "\n",
      " Train loss: 0.0004814313433598727 | Test loss: 2.6221  | Test acc: 0.7726\n",
      "\n",
      " Train loss: 0.00021998933516442776 | Test loss: 3.2744  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.0022309720516204834 | Test loss: 3.5554  | Test acc: 0.7237\n",
      "\n",
      " Train loss: 0.000982416677288711 | Test loss: 3.2944  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.002334228018298745 | Test loss: 3.0670  | Test acc: 0.7452\n",
      "\n",
      " Train loss: 0.0007512100855819881 | Test loss: 3.2561  | Test acc: 0.7350\n",
      "\n",
      " Train loss: 0.0011949490290135145 | Test loss: 3.6412  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.001534236827865243 | Test loss: 4.1096  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.001315346104092896 | Test loss: 3.9293  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.001884118770249188 | Test loss: 3.3722  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.0012778080999851227 | Test loss: 2.6342  | Test acc: 0.7428\n",
      "\n",
      " Train loss: 0.0012131747789680958 | Test loss: 2.4750  | Test acc: 0.7684\n",
      "\n",
      " Train loss: 0.0011814093450084329 | Test loss: 3.0270  | Test acc: 0.7345\n",
      "\n",
      " Train loss: 0.00104832265060395 | Test loss: 3.2609  | Test acc: 0.7267\n",
      "\n",
      " Train loss: 0.0019083709921687841 | Test loss: 2.7977  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.000920357124414295 | Test loss: 2.2097  | Test acc: 0.7774\n",
      "\n",
      " Train loss: 0.0009662986267358065 | Test loss: 2.3959  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.0009416058892384171 | Test loss: 2.8802  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0010531531879678369 | Test loss: 3.3296  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.000656654592603445 | Test loss: 3.6365  | Test acc: 0.6874\n",
      "\n",
      " Train loss: 0.0012757830554619431 | Test loss: 3.2298  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0020418858621269464 | Test loss: 2.7793  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.000579879037104547 | Test loss: 2.5440  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.002800449263304472 | Test loss: 2.6093  | Test acc: 0.7569\n",
      "\n",
      " Train loss: 0.001093168742954731 | Test loss: 2.9481  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.0027777862269431353 | Test loss: 2.6777  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.0005922981072217226 | Test loss: 2.6220  | Test acc: 0.7361\n",
      "\n",
      " Train loss: 0.0009080359595827758 | Test loss: 2.4890  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.0009727122378535569 | Test loss: 2.4451  | Test acc: 0.7607\n",
      "\n",
      " Train loss: 0.0009453012607991695 | Test loss: 2.4296  | Test acc: 0.7605\n",
      "\n",
      " Train loss: 0.0005799939972348511 | Test loss: 2.1778  | Test acc: 0.7840\n",
      "\n",
      " Train loss: 0.003363463096320629 | Test loss: 2.2035  | Test acc: 0.7921\n",
      "\n",
      " Train loss: 0.001337881083600223 | Test loss: 2.8306  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.0017057445365935564 | Test loss: 3.4173  | Test acc: 0.7114\n",
      "\n",
      " Train loss: 0.0008253460400737822 | Test loss: 4.2482  | Test acc: 0.6700\n",
      "\n",
      " Train loss: 0.001604934805072844 | Test loss: 2.9044  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.001330649945884943 | Test loss: 2.6608  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.0035704264882951975 | Test loss: 2.2274  | Test acc: 0.7650\n",
      "\n",
      " Train loss: 0.0012894952669739723 | Test loss: 1.9939  | Test acc: 0.7670\n",
      "\n",
      " Train loss: 0.0005053522763773799 | Test loss: 2.0085  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.00251028616912663 | Test loss: 2.4352  | Test acc: 0.7192\n",
      "\n",
      " Train loss: 0.001677176565863192 | Test loss: 2.8895  | Test acc: 0.6875\n",
      "\n",
      " Train loss: 0.0021837966050952673 | Test loss: 2.3037  | Test acc: 0.7230\n",
      "\n",
      " Train loss: 0.0017317378660663962 | Test loss: 2.0132  | Test acc: 0.7512\n",
      "\n",
      " Train loss: 0.0007608242449350655 | Test loss: 2.1893  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.002033288823440671 | Test loss: 2.3510  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.001740801497362554 | Test loss: 2.2904  | Test acc: 0.7352\n",
      "\n",
      " Train loss: 0.0014419200597330928 | Test loss: 2.1902  | Test acc: 0.7198\n",
      "\n",
      " Train loss: 0.00120673852507025 | Test loss: 2.4649  | Test acc: 0.6848\n",
      "\n",
      " Train loss: 0.0006601317436434329 | Test loss: 2.3871  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0013293930096551776 | Test loss: 2.0651  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.0007928140112198889 | Test loss: 2.5161  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.00043626767001114786 | Test loss: 3.4322  | Test acc: 0.7119\n",
      "\n",
      " Train loss: 0.0017433277098461986 | Test loss: 3.4075  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0007078319904394448 | Test loss: 2.9780  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0010259386617690325 | Test loss: 2.1868  | Test acc: 0.7710\n",
      "\n",
      " Train loss: 0.0011542349820956588 | Test loss: 2.2614  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.0014050111640244722 | Test loss: 2.2958  | Test acc: 0.7575\n",
      "\n",
      " Train loss: 0.000831871759146452 | Test loss: 2.2752  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.0012187478132545948 | Test loss: 2.1570  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0005195989506319165 | Test loss: 2.0928  | Test acc: 0.7698\n",
      "\n",
      " Train loss: 0.0004268308402970433 | Test loss: 2.0885  | Test acc: 0.7776\n",
      "\n",
      " Train loss: 0.0004646221350412816 | Test loss: 2.0031  | Test acc: 0.7933\n",
      "\n",
      " Train loss: 0.00043191324220970273 | Test loss: 2.0749  | Test acc: 0.7963\n",
      "\n",
      " Train loss: 0.0006865906179882586 | Test loss: 2.1815  | Test acc: 0.7887\n",
      "\n",
      " Train loss: 0.0008813555468805134 | Test loss: 1.9586  | Test acc: 0.7992\n",
      "\n",
      " Train loss: 0.000522790418472141 | Test loss: 2.0857  | Test acc: 0.7798\n",
      "\n",
      " Train loss: 0.00032028957502916455 | Test loss: 2.3726  | Test acc: 0.7629\n",
      "\n",
      " Train loss: 0.0018460258143022656 | Test loss: 2.0947  | Test acc: 0.7908\n",
      "\n",
      " Train loss: 0.0006799909169785678 | Test loss: 2.1675  | Test acc: 0.7915\n",
      "\n",
      " Train loss: 0.0007409147219732404 | Test loss: 2.5874  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0008688797242939472 | Test loss: 2.8470  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.0008146071922965348 | Test loss: 2.3438  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.0006623601075261831 | Test loss: 2.2362  | Test acc: 0.7769\n",
      "\n",
      " Train loss: 0.000841669156216085 | Test loss: 2.2145  | Test acc: 0.7834\n",
      "\n",
      " Train loss: 0.0031606375705450773 | Test loss: 2.1380  | Test acc: 0.7947\n",
      "\n",
      " Train loss: 0.0006398166879080236 | Test loss: 1.9923  | Test acc: 0.8035\n",
      "\n",
      " Train loss: 0.0006970178219489753 | Test loss: 1.9483  | Test acc: 0.8047\n",
      "\n",
      " Train loss: 0.0007282370352186263 | Test loss: 2.0130  | Test acc: 0.8042\n",
      "\n",
      " Train loss: 0.0013730598147958517 | Test loss: 2.2429  | Test acc: 0.7890\n",
      "\n",
      " Train loss: 0.0007544411346316338 | Test loss: 2.6460  | Test acc: 0.7414\n",
      "\n",
      " Train loss: 0.0004951595328748226 | Test loss: 2.9668  | Test acc: 0.7213\n",
      "\n",
      " Train loss: 0.0020641149021685123 | Test loss: 2.7787  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0009373787324875593 | Test loss: 2.4526  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.0018780053360387683 | Test loss: 2.2297  | Test acc: 0.7653\n",
      "\n",
      " Train loss: 0.0015196900349110365 | Test loss: 2.6703  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0008571927901357412 | Test loss: 3.2544  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0002872758486773819 | Test loss: 4.1467  | Test acc: 0.6681\n",
      "\n",
      " Train loss: 0.0012150448746979237 | Test loss: 4.7429  | Test acc: 0.6459\n",
      "\n",
      " Train loss: 0.0031520500779151917 | Test loss: 4.1170  | Test acc: 0.6707\n",
      "\n",
      " Train loss: 0.0025836487766355276 | Test loss: 2.9093  | Test acc: 0.7245\n",
      "\n",
      " Train loss: 0.002100670477375388 | Test loss: 2.3145  | Test acc: 0.7514\n",
      "\n",
      " Train loss: 0.0017846145201474428 | Test loss: 2.8352  | Test acc: 0.7294\n",
      "\n",
      " Train loss: 0.0019816795829683542 | Test loss: 3.7498  | Test acc: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.001121998648159206 | Test loss: 4.2344  | Test acc: 0.6465\n",
      "\n",
      " Train loss: 0.001393214683048427 | Test loss: 3.8255  | Test acc: 0.6615\n",
      "\n",
      " Train loss: 0.0008265302749350667 | Test loss: 2.8569  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0011297616874799132 | Test loss: 2.1643  | Test acc: 0.7392\n",
      "\n",
      " Train loss: 0.0030680380295962095 | Test loss: 1.9500  | Test acc: 0.7603\n",
      "\n",
      " Train loss: 0.0002802897070068866 | Test loss: 2.9585  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.0008819400100037456 | Test loss: 4.0269  | Test acc: 0.6807\n",
      "\n",
      " Train loss: 0.002288522431626916 | Test loss: 3.1926  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.002186349593102932 | Test loss: 2.2585  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.0012752303155139089 | Test loss: 2.5380  | Test acc: 0.7319\n",
      "\n",
      " Train loss: 0.002240988193079829 | Test loss: 2.4339  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.0011044300626963377 | Test loss: 2.2723  | Test acc: 0.7647\n",
      "\n",
      " Train loss: 0.0011714487336575985 | Test loss: 2.3859  | Test acc: 0.7631\n",
      "\n",
      " Train loss: 0.0010453701252117753 | Test loss: 2.8632  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.0010213101049885154 | Test loss: 3.4643  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0010548128047958016 | Test loss: 3.3936  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0011638959404081106 | Test loss: 2.7601  | Test acc: 0.7377\n",
      "\n",
      " Train loss: 0.003814466530457139 | Test loss: 2.3195  | Test acc: 0.7635\n",
      "\n",
      " Train loss: 0.0018755481578409672 | Test loss: 2.3142  | Test acc: 0.7415\n",
      "\n",
      " Train loss: 0.0010198689997196198 | Test loss: 2.0895  | Test acc: 0.7580\n",
      "\n",
      " Train loss: 0.0010162141406908631 | Test loss: 2.5827  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0013125607511028647 | Test loss: 2.7003  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0013807711657136679 | Test loss: 2.3532  | Test acc: 0.7542\n",
      "\n",
      " Train loss: 0.001319440663792193 | Test loss: 2.4219  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.0012688847491517663 | Test loss: 3.4110  | Test acc: 0.6870\n",
      "\n",
      " Train loss: 0.0024139562156051397 | Test loss: 3.0282  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.000977006508037448 | Test loss: 2.4337  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.0009416188695468009 | Test loss: 2.2178  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0007530152215622365 | Test loss: 2.0067  | Test acc: 0.7698\n",
      "\n",
      " Train loss: 0.0007298614364117384 | Test loss: 1.8639  | Test acc: 0.7850\n",
      "\n",
      " Train loss: 0.0006099219899624586 | Test loss: 1.8471  | Test acc: 0.7794\n",
      "\n",
      " Train loss: 0.0012397526297718287 | Test loss: 2.0960  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.001802945858798921 | Test loss: 2.1827  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.0010562120005488396 | Test loss: 2.3264  | Test acc: 0.7347\n",
      "\n",
      " Train loss: 0.000832026416901499 | Test loss: 2.3976  | Test acc: 0.7319\n",
      "\n",
      " Train loss: 0.0019991907756775618 | Test loss: 2.2975  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0008071772172115743 | Test loss: 2.3847  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.001350018079392612 | Test loss: 2.5061  | Test acc: 0.7514\n",
      "\n",
      " Train loss: 0.0008836194756440818 | Test loss: 2.7126  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.0014510101173073053 | Test loss: 2.7240  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.002253537764772773 | Test loss: 2.5480  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.0007541250670328736 | Test loss: 2.6179  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0020738188177347183 | Test loss: 2.5626  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0012596554588526487 | Test loss: 2.5594  | Test acc: 0.7235\n",
      "\n",
      " Train loss: 0.0009045726619660854 | Test loss: 2.6719  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0007647656020708382 | Test loss: 2.6253  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.001283534918911755 | Test loss: 2.9520  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0016010843683034182 | Test loss: 3.0563  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.002905266359448433 | Test loss: 2.6389  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.0007041650242172182 | Test loss: 2.3764  | Test acc: 0.7562\n",
      "\n",
      " Train loss: 0.0013957452028989792 | Test loss: 2.2745  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.0012245510006323457 | Test loss: 2.6374  | Test acc: 0.7310\n",
      "\n",
      " Train loss: 0.0030537641141563654 | Test loss: 2.6706  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.0015574991703033447 | Test loss: 2.4176  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.0020514987409114838 | Test loss: 2.5003  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0013054775772616267 | Test loss: 2.8380  | Test acc: 0.7190\n",
      "\n",
      " Train loss: 0.0010816118447110057 | Test loss: 3.1339  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0008259158348664641 | Test loss: 3.9096  | Test acc: 0.6474\n",
      "\n",
      " Train loss: 0.0020432383753359318 | Test loss: 3.4305  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.0012907931813970208 | Test loss: 3.0852  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0023578417021781206 | Test loss: 3.1268  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.0008769147098064423 | Test loss: 2.8603  | Test acc: 0.7059\n",
      "\n",
      " Train loss: 0.0018532034009695053 | Test loss: 1.9581  | Test acc: 0.7792\n",
      "\n",
      " Train loss: 0.00021470835781656206 | Test loss: 2.1807  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.0008048989111557603 | Test loss: 2.3815  | Test acc: 0.7443\n",
      "\n",
      " Train loss: 0.0012920266017317772 | Test loss: 2.4766  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.0016483819345012307 | Test loss: 2.2559  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.0019738732371479273 | Test loss: 2.1856  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0010713620577007532 | Test loss: 2.8740  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.0009811181807890534 | Test loss: 2.3528  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.0008558324771001935 | Test loss: 2.0380  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.001477835699915886 | Test loss: 1.9982  | Test acc: 0.7578\n",
      "\n",
      " Train loss: 0.0008670987444929779 | Test loss: 2.1401  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.000537184823770076 | Test loss: 2.2674  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0017416283953934908 | Test loss: 2.3215  | Test acc: 0.7569\n",
      "\n",
      " Train loss: 0.001379614695906639 | Test loss: 2.1030  | Test acc: 0.7684\n",
      "\n",
      " Train loss: 0.0009015906252898276 | Test loss: 1.8450  | Test acc: 0.7859\n",
      "\n",
      " Train loss: 0.0015927640488371253 | Test loss: 2.0237  | Test acc: 0.7671\n",
      "\n",
      " Train loss: 0.00033023732248693705 | Test loss: 2.4829  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0017855499172583222 | Test loss: 2.4271  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.001315486617386341 | Test loss: 2.2112  | Test acc: 0.7392\n",
      "\n",
      " Train loss: 0.0006158509058877826 | Test loss: 2.1536  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.001531945657916367 | Test loss: 2.1297  | Test acc: 0.7588\n",
      "\n",
      " Train loss: 0.0008671547402627766 | Test loss: 2.1543  | Test acc: 0.7548\n",
      "\n",
      " Train loss: 0.001223025843501091 | Test loss: 2.2928  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.0009380965493619442 | Test loss: 2.3151  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.00014669325901195407 | Test loss: 2.3502  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0018630471313372254 | Test loss: 2.0400  | Test acc: 0.7578\n",
      "\n",
      " Train loss: 0.0013240361586213112 | Test loss: 1.7664  | Test acc: 0.7702\n",
      "\n",
      " Train loss: 0.0007122987881302834 | Test loss: 1.6380  | Test acc: 0.7897\n",
      "\n",
      " Train loss: 0.0008141340804286301 | Test loss: 1.6695  | Test acc: 0.7891\n",
      "\n",
      " Train loss: 0.0006934715202078223 | Test loss: 1.8101  | Test acc: 0.7766\n",
      "\n",
      " Train loss: 0.00017199009016621858 | Test loss: 2.0989  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.001753151067532599 | Test loss: 2.2051  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.00016987462004180998 | Test loss: 2.5020  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.0007999678491614759 | Test loss: 2.5619  | Test acc: 0.7128\n",
      "\n",
      " Train loss: 0.0018509968649595976 | Test loss: 2.1471  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.00285951211117208 | Test loss: 2.2732  | Test acc: 0.6914\n",
      "\n",
      " Train loss: 0.000687472231220454 | Test loss: 2.8604  | Test acc: 0.6716\n",
      "\n",
      " Train loss: 0.0013561643427237868 | Test loss: 2.9758  | Test acc: 0.6560\n",
      "\n",
      " Train loss: 0.0007136244676075876 | Test loss: 2.8096  | Test acc: 0.6718\n",
      "\n",
      " Train loss: 0.001050518243573606 | Test loss: 2.5682  | Test acc: 0.7117\n",
      "\n",
      " Train loss: 0.0017919435631483793 | Test loss: 2.3063  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0010499578202143312 | Test loss: 2.3825  | Test acc: 0.7352\n",
      "\n",
      " Train loss: 0.0019690096378326416 | Test loss: 2.0716  | Test acc: 0.7458\n",
      "Looked at 12800/ 60000 samples\n",
      "\n",
      " Train loss: 0.0013950334396213293 | Test loss: 1.7955  | Test acc: 0.7646\n",
      "\n",
      " Train loss: 0.0007243736763484776 | Test loss: 2.1077  | Test acc: 0.7523\n",
      "\n",
      " Train loss: 0.0005158983985893428 | Test loss: 2.6508  | Test acc: 0.7144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0013296811375766993 | Test loss: 2.8697  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0023012724705040455 | Test loss: 2.0256  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.0018663140945136547 | Test loss: 1.6439  | Test acc: 0.7903\n",
      "\n",
      " Train loss: 0.0007300719153136015 | Test loss: 1.6436  | Test acc: 0.7929\n",
      "\n",
      " Train loss: 0.0016050089616328478 | Test loss: 1.9474  | Test acc: 0.7572\n",
      "\n",
      " Train loss: 0.00016091714496724308 | Test loss: 2.8562  | Test acc: 0.6918\n",
      "\n",
      " Train loss: 0.0017670653760433197 | Test loss: 3.1569  | Test acc: 0.6568\n",
      "\n",
      " Train loss: 0.002351505681872368 | Test loss: 2.1645  | Test acc: 0.7207\n",
      "\n",
      " Train loss: 0.0013751185033470392 | Test loss: 3.2186  | Test acc: 0.6769\n",
      "\n",
      " Train loss: 0.0017367193941026926 | Test loss: 3.7780  | Test acc: 0.6509\n",
      "\n",
      " Train loss: 0.0018175733275711536 | Test loss: 4.1834  | Test acc: 0.6165\n",
      "\n",
      " Train loss: 0.0012322207912802696 | Test loss: 3.3626  | Test acc: 0.6618\n",
      "\n",
      " Train loss: 0.001779784681275487 | Test loss: 2.5205  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0014615043764933944 | Test loss: 2.7688  | Test acc: 0.7180\n",
      "\n",
      " Train loss: 0.0013155011693015695 | Test loss: 2.7903  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.0009422838338650763 | Test loss: 2.7378  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0009392403298988938 | Test loss: 2.8475  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.0010888301767408848 | Test loss: 3.0525  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.0023383009247481823 | Test loss: 2.8623  | Test acc: 0.7225\n",
      "\n",
      " Train loss: 0.002772986888885498 | Test loss: 2.5362  | Test acc: 0.7302\n",
      "\n",
      " Train loss: 0.0005202458123676479 | Test loss: 2.3667  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.0017302625346928835 | Test loss: 2.3400  | Test acc: 0.7253\n",
      "\n",
      " Train loss: 0.001923504052683711 | Test loss: 2.7152  | Test acc: 0.6883\n",
      "\n",
      " Train loss: 0.0018642665818333626 | Test loss: 2.5888  | Test acc: 0.6917\n",
      "\n",
      " Train loss: 0.0014119683764874935 | Test loss: 2.0935  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0016475155716761947 | Test loss: 2.0852  | Test acc: 0.7594\n",
      "\n",
      " Train loss: 0.001670820522122085 | Test loss: 2.1473  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.0008314393344335258 | Test loss: 2.1737  | Test acc: 0.7353\n",
      "\n",
      " Train loss: 0.0016558971256017685 | Test loss: 1.8805  | Test acc: 0.7630\n",
      "\n",
      " Train loss: 0.0016018574824556708 | Test loss: 1.6451  | Test acc: 0.7802\n",
      "\n",
      " Train loss: 7.042756624286994e-05 | Test loss: 2.0205  | Test acc: 0.7294\n",
      "\n",
      " Train loss: 0.0019626272842288017 | Test loss: 1.9235  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0012197786709293723 | Test loss: 2.4543  | Test acc: 0.7213\n",
      "\n",
      " Train loss: 0.0020739417523145676 | Test loss: 2.8891  | Test acc: 0.6748\n",
      "\n",
      " Train loss: 0.0016702022403478622 | Test loss: 2.6620  | Test acc: 0.6777\n",
      "\n",
      " Train loss: 0.0007829715614207089 | Test loss: 2.8680  | Test acc: 0.6714\n",
      "\n",
      " Train loss: 0.0019274092046543956 | Test loss: 2.3215  | Test acc: 0.6924\n",
      "\n",
      " Train loss: 0.0006816673558205366 | Test loss: 1.9268  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0008608093485236168 | Test loss: 2.0314  | Test acc: 0.7310\n",
      "\n",
      " Train loss: 0.0004490485298447311 | Test loss: 2.2242  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0008415046031586826 | Test loss: 2.6807  | Test acc: 0.6812\n",
      "\n",
      " Train loss: 0.0011029556626453996 | Test loss: 3.1699  | Test acc: 0.6765\n",
      "\n",
      " Train loss: 0.001673370017670095 | Test loss: 2.6611  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0011558118276298046 | Test loss: 2.4617  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.0005017273942939937 | Test loss: 2.6536  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.002187189646065235 | Test loss: 3.1120  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.0016095505561679602 | Test loss: 2.8471  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.0016029038233682513 | Test loss: 2.3153  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.0024989943485707045 | Test loss: 1.8825  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.0015925021143630147 | Test loss: 1.9532  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.0013959117932245135 | Test loss: 2.0749  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0008125519962050021 | Test loss: 1.6124  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0007930701831355691 | Test loss: 2.3323  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0011688831727951765 | Test loss: 2.3159  | Test acc: 0.6901\n",
      "\n",
      " Train loss: 0.0005190225783735514 | Test loss: 2.6593  | Test acc: 0.6980\n",
      "\n",
      " Train loss: 0.0015846934402361512 | Test loss: 2.8409  | Test acc: 0.6761\n",
      "\n",
      " Train loss: 0.0014299831818789244 | Test loss: 2.4343  | Test acc: 0.6841\n",
      "\n",
      " Train loss: 0.0021179846953600645 | Test loss: 2.5134  | Test acc: 0.6892\n",
      "\n",
      " Train loss: 0.0012346681905910373 | Test loss: 3.2494  | Test acc: 0.6654\n",
      "\n",
      " Train loss: 0.0013884924119338393 | Test loss: 3.1354  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.0005948234465904534 | Test loss: 3.5402  | Test acc: 0.7091\n",
      "\n",
      " Train loss: 0.0011317955795675516 | Test loss: 3.8167  | Test acc: 0.7015\n",
      "\n",
      " Train loss: 0.002820938127115369 | Test loss: 3.5573  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.0015632732538506389 | Test loss: 2.7735  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.001165874651633203 | Test loss: 2.4421  | Test acc: 0.7335\n",
      "\n",
      " Train loss: 0.00128864252474159 | Test loss: 2.7400  | Test acc: 0.7054\n",
      "\n",
      " Train loss: 0.001832566224038601 | Test loss: 2.6418  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0014424002729356289 | Test loss: 2.8498  | Test acc: 0.7546\n",
      "\n",
      " Train loss: 0.001922216615639627 | Test loss: 3.3909  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.0006882621091790497 | Test loss: 3.7200  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.0021480759605765343 | Test loss: 5.1752  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.002783611649647355 | Test loss: 4.8466  | Test acc: 0.6865\n",
      "\n",
      " Train loss: 0.002510161604732275 | Test loss: 5.0226  | Test acc: 0.6730\n",
      "\n",
      " Train loss: 0.004084341693669558 | Test loss: 3.7928  | Test acc: 0.7036\n",
      "\n",
      " Train loss: 0.0019259866094216704 | Test loss: 3.3278  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.0025902329944074154 | Test loss: 3.2284  | Test acc: 0.6971\n",
      "\n",
      " Train loss: 0.0012019246350973845 | Test loss: 3.8495  | Test acc: 0.6627\n",
      "\n",
      " Train loss: 0.0014872135361656547 | Test loss: 4.6671  | Test acc: 0.6237\n",
      "\n",
      " Train loss: 0.003311775391921401 | Test loss: 3.9915  | Test acc: 0.6539\n",
      "\n",
      " Train loss: 0.001822780235670507 | Test loss: 3.1966  | Test acc: 0.6918\n",
      "\n",
      " Train loss: 0.002158636227250099 | Test loss: 2.7978  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.0016471969429403543 | Test loss: 2.7055  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.0011385479010641575 | Test loss: 2.9556  | Test acc: 0.6942\n",
      "\n",
      " Train loss: 0.0009247621637769043 | Test loss: 3.9563  | Test acc: 0.6492\n",
      "\n",
      " Train loss: 0.002096192678436637 | Test loss: 3.4487  | Test acc: 0.6788\n",
      "\n",
      " Train loss: 0.0034749468322843313 | Test loss: 3.9055  | Test acc: 0.6937\n",
      "\n",
      " Train loss: 0.0012474973918870091 | Test loss: 5.5074  | Test acc: 0.6771\n",
      "\n",
      " Train loss: 0.0033409693278372288 | Test loss: 5.3597  | Test acc: 0.6546\n",
      "\n",
      " Train loss: 0.002698536030948162 | Test loss: 5.8791  | Test acc: 0.6587\n",
      "\n",
      " Train loss: 0.0028277006931602955 | Test loss: 5.1629  | Test acc: 0.6589\n",
      "\n",
      " Train loss: 0.0015332046896219254 | Test loss: 3.7379  | Test acc: 0.6974\n",
      "\n",
      " Train loss: 0.0009921547025442123 | Test loss: 6.1979  | Test acc: 0.6204\n",
      "\n",
      " Train loss: 0.0025693492498248816 | Test loss: 8.1452  | Test acc: 0.5626\n",
      "\n",
      " Train loss: 0.003599514253437519 | Test loss: 5.5259  | Test acc: 0.6133\n",
      "\n",
      " Train loss: 0.002697989344596863 | Test loss: 4.2801  | Test acc: 0.6592\n",
      "\n",
      " Train loss: 0.0015608876710757613 | Test loss: 4.6379  | Test acc: 0.6766\n",
      "\n",
      " Train loss: 0.0014301266055554152 | Test loss: 4.7547  | Test acc: 0.6904\n",
      "\n",
      " Train loss: 0.0022732799407094717 | Test loss: 4.9601  | Test acc: 0.6620\n",
      "\n",
      " Train loss: 0.0018423657165840268 | Test loss: 4.6816  | Test acc: 0.6573\n",
      "\n",
      " Train loss: 0.002351851901039481 | Test loss: 4.6876  | Test acc: 0.6447\n",
      "\n",
      " Train loss: 0.0016034541185945272 | Test loss: 4.9516  | Test acc: 0.6561\n",
      "\n",
      " Train loss: 0.0031483625061810017 | Test loss: 3.8356  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0031555513851344585 | Test loss: 2.3628  | Test acc: 0.7723\n",
      "\n",
      " Train loss: 0.0009297727374359965 | Test loss: 2.3527  | Test acc: 0.7724\n",
      "\n",
      " Train loss: 0.0010161567479372025 | Test loss: 3.1713  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0010462433565407991 | Test loss: 5.0518  | Test acc: 0.6529\n",
      "\n",
      " Train loss: 0.001012688153423369 | Test loss: 6.5950  | Test acc: 0.6233\n",
      "\n",
      " Train loss: 0.0022516653407365084 | Test loss: 5.2480  | Test acc: 0.6690\n",
      "\n",
      " Train loss: 0.006766506936401129 | Test loss: 4.5345  | Test acc: 0.6696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0019357952987775207 | Test loss: 5.0104  | Test acc: 0.6858\n",
      "\n",
      " Train loss: 0.0023286163341253996 | Test loss: 6.3405  | Test acc: 0.6575\n",
      "\n",
      " Train loss: 0.00439222389832139 | Test loss: 6.5752  | Test acc: 0.6786\n",
      "\n",
      " Train loss: 0.0028032097034156322 | Test loss: 5.4367  | Test acc: 0.6911\n",
      "\n",
      " Train loss: 0.0021354281343519688 | Test loss: 4.1332  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0014164176536723971 | Test loss: 5.6241  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.004814777057617903 | Test loss: 4.8690  | Test acc: 0.7054\n",
      "\n",
      " Train loss: 0.004334916360676289 | Test loss: 3.8145  | Test acc: 0.7493\n",
      "\n",
      " Train loss: 0.002141237026080489 | Test loss: 5.4267  | Test acc: 0.7159\n",
      "\n",
      " Train loss: 0.0039261458441615105 | Test loss: 5.1593  | Test acc: 0.7101\n",
      "\n",
      " Train loss: 0.005602561868727207 | Test loss: 4.0833  | Test acc: 0.7423\n",
      "\n",
      " Train loss: 0.002551293233409524 | Test loss: 3.4409  | Test acc: 0.7723\n",
      "\n",
      " Train loss: 0.0024804570712149143 | Test loss: 4.1408  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.0018885378958657384 | Test loss: 7.6679  | Test acc: 0.6663\n",
      "\n",
      " Train loss: 0.003230024827644229 | Test loss: 7.8181  | Test acc: 0.6516\n",
      "\n",
      " Train loss: 0.006442655343562365 | Test loss: 6.5179  | Test acc: 0.6396\n",
      "\n",
      " Train loss: 0.0037264593411237 | Test loss: 4.3846  | Test acc: 0.7163\n",
      "\n",
      " Train loss: 0.0023182358127087355 | Test loss: 4.4489  | Test acc: 0.7346\n",
      "\n",
      " Train loss: 0.00216418388299644 | Test loss: 5.7904  | Test acc: 0.7210\n",
      "\n",
      " Train loss: 0.0006932277465239167 | Test loss: 7.2077  | Test acc: 0.6979\n",
      "\n",
      " Train loss: 0.0013435465516522527 | Test loss: 7.3999  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.0028745669405907393 | Test loss: 6.0594  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0030460653360933065 | Test loss: 5.0484  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0034136357717216015 | Test loss: 5.4259  | Test acc: 0.6935\n",
      "\n",
      " Train loss: 0.001604792894795537 | Test loss: 7.7801  | Test acc: 0.6375\n",
      "\n",
      " Train loss: 0.004336345009505749 | Test loss: 5.5049  | Test acc: 0.6802\n",
      "\n",
      " Train loss: 0.0013116106856614351 | Test loss: 6.4703  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.0038250654470175505 | Test loss: 8.2533  | Test acc: 0.7024\n",
      "\n",
      " Train loss: 0.001924757263623178 | Test loss: 8.6800  | Test acc: 0.7006\n",
      "\n",
      " Train loss: 0.0029673834796994925 | Test loss: 9.0478  | Test acc: 0.6498\n",
      "\n",
      " Train loss: 0.0032294956035912037 | Test loss: 6.6266  | Test acc: 0.7231\n",
      "\n",
      " Train loss: 0.003759750397875905 | Test loss: 5.6392  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0031927702948451042 | Test loss: 6.4497  | Test acc: 0.6824\n",
      "\n",
      " Train loss: 0.003742527449503541 | Test loss: 15.0072  | Test acc: 0.5065\n",
      "\n",
      " Train loss: 0.008592057041823864 | Test loss: 6.8332  | Test acc: 0.6867\n",
      "\n",
      " Train loss: 0.004225491546094418 | Test loss: 7.4096  | Test acc: 0.6428\n",
      "\n",
      " Train loss: 0.007428776938468218 | Test loss: 6.0186  | Test acc: 0.6702\n",
      "\n",
      " Train loss: 0.0030096368864178658 | Test loss: 6.0999  | Test acc: 0.6505\n",
      "\n",
      " Train loss: 0.0026141402777284384 | Test loss: 4.9693  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0010506701655685902 | Test loss: 5.8354  | Test acc: 0.6678\n",
      "\n",
      " Train loss: 0.0015378940152004361 | Test loss: 8.2114  | Test acc: 0.6311\n",
      "\n",
      " Train loss: 0.005319017451256514 | Test loss: 5.9869  | Test acc: 0.6751\n",
      "\n",
      " Train loss: 0.003298938972875476 | Test loss: 4.7320  | Test acc: 0.7252\n",
      "\n",
      " Train loss: 0.002258013002574444 | Test loss: 5.3923  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.005656857509166002 | Test loss: 5.4337  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.002573629142716527 | Test loss: 5.5861  | Test acc: 0.7253\n",
      "\n",
      " Train loss: 0.003691332647576928 | Test loss: 6.8127  | Test acc: 0.6906\n",
      "\n",
      " Train loss: 0.005420918110758066 | Test loss: 8.2865  | Test acc: 0.7161\n",
      "\n",
      " Train loss: 0.0009194980375468731 | Test loss: 9.9689  | Test acc: 0.7156\n",
      "\n",
      " Train loss: 0.0041985344141721725 | Test loss: 8.9378  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.007361177355051041 | Test loss: 5.1215  | Test acc: 0.7443\n",
      "\n",
      " Train loss: 0.0032620513811707497 | Test loss: 6.3816  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.002929341746494174 | Test loss: 6.9083  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.002433606656268239 | Test loss: 5.7676  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.001708691823296249 | Test loss: 5.0328  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0010614810744300485 | Test loss: 6.2740  | Test acc: 0.6766\n",
      "\n",
      " Train loss: 0.0015622772043570876 | Test loss: 6.7491  | Test acc: 0.6570\n",
      "\n",
      " Train loss: 0.0029399124905467033 | Test loss: 5.2762  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0031145301181823015 | Test loss: 6.5957  | Test acc: 0.6516\n",
      "\n",
      " Train loss: 0.0038929067086428404 | Test loss: 8.2178  | Test acc: 0.6176\n",
      "\n",
      " Train loss: 0.004783669952303171 | Test loss: 4.7836  | Test acc: 0.7100\n",
      "\n",
      " Train loss: 0.0018825269071385264 | Test loss: 5.4987  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.00445573078468442 | Test loss: 6.0533  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.0009326339932158589 | Test loss: 5.8591  | Test acc: 0.7359\n",
      "\n",
      " Train loss: 0.001547388848848641 | Test loss: 5.9271  | Test acc: 0.7223\n",
      "\n",
      " Train loss: 0.002627783687785268 | Test loss: 6.3700  | Test acc: 0.6944\n",
      "\n",
      " Train loss: 0.006584485527127981 | Test loss: 6.1767  | Test acc: 0.7041\n",
      "\n",
      " Train loss: 0.0017615752294659615 | Test loss: 6.1981  | Test acc: 0.6848\n",
      "\n",
      " Train loss: 0.0022230674512684345 | Test loss: 5.8126  | Test acc: 0.6718\n",
      "\n",
      " Train loss: 0.0018552665133029222 | Test loss: 5.8281  | Test acc: 0.6713\n",
      "\n",
      " Train loss: 0.003238864941522479 | Test loss: 7.8293  | Test acc: 0.6397\n",
      "\n",
      " Train loss: 0.006675968877971172 | Test loss: 7.9111  | Test acc: 0.6149\n",
      "\n",
      " Train loss: 0.00355413812212646 | Test loss: 5.1687  | Test acc: 0.6908\n",
      "\n",
      " Train loss: 0.0028347757179290056 | Test loss: 5.1727  | Test acc: 0.7223\n",
      "\n",
      " Train loss: 0.0017007730202749372 | Test loss: 5.2325  | Test acc: 0.7148\n",
      "\n",
      " Train loss: 0.0017652721144258976 | Test loss: 5.4576  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0018933286191895604 | Test loss: 5.3060  | Test acc: 0.7224\n",
      "\n",
      " Train loss: 0.0019389936933293939 | Test loss: 9.0635  | Test acc: 0.6371\n",
      "\n",
      " Train loss: 0.007092171814292669 | Test loss: 9.8948  | Test acc: 0.6263\n",
      "\n",
      " Train loss: 0.00779388751834631 | Test loss: 6.7567  | Test acc: 0.6716\n",
      "\n",
      " Train loss: 0.004571440163999796 | Test loss: 5.4889  | Test acc: 0.6835\n",
      "\n",
      " Train loss: 0.0010692509822547436 | Test loss: 6.0079  | Test acc: 0.6632\n",
      "\n",
      " Train loss: 0.0022392598912119865 | Test loss: 4.7149  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0009440068388357759 | Test loss: 4.0493  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.0013372241519391537 | Test loss: 3.7351  | Test acc: 0.7789\n",
      "\n",
      " Train loss: 0.003773010103031993 | Test loss: 3.3319  | Test acc: 0.7885\n",
      "\n",
      " Train loss: 0.002983781276270747 | Test loss: 3.7059  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0007754362304694951 | Test loss: 5.2172  | Test acc: 0.6957\n",
      "\n",
      " Train loss: 0.0034710185136646032 | Test loss: 5.8135  | Test acc: 0.6739\n",
      "\n",
      " Train loss: 0.0014154509408399463 | Test loss: 6.8331  | Test acc: 0.6162\n",
      "\n",
      " Train loss: 0.0021665464155375957 | Test loss: 6.4931  | Test acc: 0.6323\n",
      "\n",
      " Train loss: 0.0030109069775789976 | Test loss: 5.1759  | Test acc: 0.6930\n",
      "\n",
      " Train loss: 0.0017279479652643204 | Test loss: 4.1993  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.003915696870535612 | Test loss: 4.0944  | Test acc: 0.7564\n",
      "\n",
      " Train loss: 0.0011843005195260048 | Test loss: 4.4495  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.0011147059267386794 | Test loss: 5.0602  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.001198220532387495 | Test loss: 5.3637  | Test acc: 0.7055\n",
      "\n",
      " Train loss: 0.005849321372807026 | Test loss: 3.6922  | Test acc: 0.7450\n",
      "\n",
      " Train loss: 0.0012765283463522792 | Test loss: 3.9757  | Test acc: 0.6999\n",
      "\n",
      " Train loss: 0.0009668581187725067 | Test loss: 4.9876  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.003050459548830986 | Test loss: 5.6138  | Test acc: 0.6804\n",
      "\n",
      " Train loss: 0.0015368089079856873 | Test loss: 5.0365  | Test acc: 0.6719\n",
      "\n",
      " Train loss: 0.0009105478529818356 | Test loss: 4.3053  | Test acc: 0.6774\n",
      "\n",
      " Train loss: 0.001818193239159882 | Test loss: 3.4738  | Test acc: 0.7231\n",
      "\n",
      " Train loss: 0.0015947058564051986 | Test loss: 3.1501  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.0012440462596714497 | Test loss: 3.2200  | Test acc: 0.7572\n",
      "\n",
      " Train loss: 0.0022611147724092007 | Test loss: 3.4232  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.0010218111565336585 | Test loss: 3.0262  | Test acc: 0.7607\n",
      "\n",
      " Train loss: 0.0023022438399493694 | Test loss: 2.6112  | Test acc: 0.7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0004817660665139556 | Test loss: 2.8374  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0014799038181081414 | Test loss: 2.8104  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0008727741660550237 | Test loss: 2.9882  | Test acc: 0.7479\n",
      "\n",
      " Train loss: 0.000524254806805402 | Test loss: 3.2108  | Test acc: 0.7398\n",
      "\n",
      " Train loss: 0.0011962837306782603 | Test loss: 3.2460  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.002510529011487961 | Test loss: 2.4980  | Test acc: 0.8105\n",
      "\n",
      " Train loss: 0.0009864938911050558 | Test loss: 2.8282  | Test acc: 0.7883\n",
      "\n",
      " Train loss: 0.001231382368132472 | Test loss: 3.4398  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0016765511827543378 | Test loss: 3.6931  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.0024645081721246243 | Test loss: 3.5930  | Test acc: 0.7289\n",
      "\n",
      " Train loss: 0.0009737257496453822 | Test loss: 3.5846  | Test acc: 0.7233\n",
      "\n",
      " Train loss: 0.000600721628870815 | Test loss: 3.8830  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.00278487685136497 | Test loss: 3.3159  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.0017372493166476488 | Test loss: 2.9378  | Test acc: 0.7510\n",
      "\n",
      " Train loss: 0.002205271739512682 | Test loss: 3.4096  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0016536549665033817 | Test loss: 3.3975  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.0022376403212547302 | Test loss: 2.8623  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.0017109737964347005 | Test loss: 3.5633  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0011290522525087 | Test loss: 4.3665  | Test acc: 0.6635\n",
      "\n",
      " Train loss: 0.0016310977516695857 | Test loss: 4.3903  | Test acc: 0.6746\n",
      "\n",
      " Train loss: 0.0016545779071748257 | Test loss: 4.3887  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.003615602618083358 | Test loss: 3.3629  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0012899634893983603 | Test loss: 3.3596  | Test acc: 0.7335\n",
      "\n",
      " Train loss: 0.0010913603473454714 | Test loss: 5.2239  | Test acc: 0.6663\n",
      "\n",
      " Train loss: 0.0027162632904946804 | Test loss: 3.9401  | Test acc: 0.6900\n",
      "\n",
      " Train loss: 0.0017107189632952213 | Test loss: 3.2872  | Test acc: 0.7012\n",
      "\n",
      " Train loss: 0.0021914697717875242 | Test loss: 3.0782  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0017703240737318993 | Test loss: 2.9564  | Test acc: 0.7033\n",
      "\n",
      " Train loss: 0.0009931395761668682 | Test loss: 2.8908  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0008475729264318943 | Test loss: 3.8763  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.002025847090408206 | Test loss: 4.6120  | Test acc: 0.6659\n",
      "\n",
      " Train loss: 0.002818988636136055 | Test loss: 4.2859  | Test acc: 0.6973\n",
      "\n",
      " Train loss: 0.0015059936558827758 | Test loss: 3.9946  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.003007218474522233 | Test loss: 4.5622  | Test acc: 0.6875\n",
      "\n",
      " Train loss: 0.001109982025809586 | Test loss: 5.2563  | Test acc: 0.6962\n",
      "\n",
      " Train loss: 0.002609040355309844 | Test loss: 4.3139  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.0071209208108484745 | Test loss: 3.1662  | Test acc: 0.7439\n",
      "\n",
      " Train loss: 0.0016284732846543193 | Test loss: 3.8022  | Test acc: 0.6772\n",
      "\n",
      " Train loss: 0.001617763889953494 | Test loss: 3.1796  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.00362909073010087 | Test loss: 2.4893  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0011989627964794636 | Test loss: 2.6732  | Test acc: 0.7631\n",
      "\n",
      " Train loss: 0.0012181747006252408 | Test loss: 2.9316  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.0004927950794808567 | Test loss: 3.2514  | Test acc: 0.7194\n",
      "\n",
      " Train loss: 0.00035214779200032353 | Test loss: 4.0574  | Test acc: 0.6849\n",
      "\n",
      " Train loss: 0.0009916103444993496 | Test loss: 3.9254  | Test acc: 0.6906\n",
      "\n",
      " Train loss: 0.0031687081791460514 | Test loss: 2.8505  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.0011707318481057882 | Test loss: 3.2803  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.002759646624326706 | Test loss: 2.8981  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.001822052989155054 | Test loss: 4.1409  | Test acc: 0.7002\n",
      "\n",
      " Train loss: 0.0020952699705958366 | Test loss: 4.2415  | Test acc: 0.7038\n",
      "\n",
      " Train loss: 0.0032025843393057585 | Test loss: 2.5710  | Test acc: 0.7526\n",
      "\n",
      " Train loss: 0.0009448093478567898 | Test loss: 3.5594  | Test acc: 0.7146\n",
      "\n",
      " Train loss: 0.0013378317235037684 | Test loss: 3.8571  | Test acc: 0.7074\n",
      "\n",
      " Train loss: 0.0018187440000474453 | Test loss: 3.4073  | Test acc: 0.7249\n",
      "\n",
      " Train loss: 0.0011147484183311462 | Test loss: 3.0561  | Test acc: 0.7376\n",
      "\n",
      " Train loss: 0.0017132709035649896 | Test loss: 2.9211  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.0010721652070060372 | Test loss: 3.2333  | Test acc: 0.7273\n",
      "\n",
      " Train loss: 0.0008431629976257682 | Test loss: 3.4207  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0017088638851419091 | Test loss: 3.2839  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0018790363101288676 | Test loss: 2.7586  | Test acc: 0.7510\n",
      "\n",
      " Train loss: 0.0011242999462410808 | Test loss: 2.6407  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0012240882497280836 | Test loss: 2.5459  | Test acc: 0.7663\n",
      "\n",
      " Train loss: 0.00018231422291137278 | Test loss: 2.8697  | Test acc: 0.7446\n",
      "\n",
      " Train loss: 0.000867141061462462 | Test loss: 2.8510  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.0022364386823028326 | Test loss: 3.0416  | Test acc: 0.7335\n",
      "\n",
      " Train loss: 0.000942981627304107 | Test loss: 2.9957  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.0017896825447678566 | Test loss: 3.0253  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0018937507411465049 | Test loss: 2.7753  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.001765089575201273 | Test loss: 2.7047  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.000524065806530416 | Test loss: 2.9838  | Test acc: 0.7464\n",
      "\n",
      " Train loss: 0.002477422123774886 | Test loss: 2.8825  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.0019303712761029601 | Test loss: 2.5919  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0013518480118364096 | Test loss: 3.0429  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.00295649329200387 | Test loss: 3.3682  | Test acc: 0.7117\n",
      "\n",
      " Train loss: 0.00042021265835501254 | Test loss: 3.5102  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0009762981790117919 | Test loss: 3.4681  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.002246782649308443 | Test loss: 3.1931  | Test acc: 0.7270\n",
      "\n",
      " Train loss: 0.0006985285435803235 | Test loss: 2.9196  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0018677355255931616 | Test loss: 2.9149  | Test acc: 0.7100\n",
      "\n",
      " Train loss: 0.0009092490654438734 | Test loss: 2.9299  | Test acc: 0.6897\n",
      "\n",
      " Train loss: 0.000796317879576236 | Test loss: 2.7528  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.0010794776026159525 | Test loss: 2.8592  | Test acc: 0.7088\n",
      "\n",
      " Train loss: 0.0014081127010285854 | Test loss: 3.8480  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.0013464265502989292 | Test loss: 4.5142  | Test acc: 0.6985\n",
      "\n",
      " Train loss: 0.002915892982855439 | Test loss: 3.5031  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.005022816825658083 | Test loss: 2.9555  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.0016933177830651402 | Test loss: 2.8062  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.0015858490951359272 | Test loss: 2.8924  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.00031834360561333597 | Test loss: 3.2622  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0010914035374298692 | Test loss: 2.6266  | Test acc: 0.7779\n",
      "\n",
      " Train loss: 0.00038653064984828234 | Test loss: 2.3293  | Test acc: 0.7860\n",
      "\n",
      " Train loss: 0.00221928209066391 | Test loss: 2.3520  | Test acc: 0.7772\n",
      "\n",
      " Train loss: 0.0009903924074023962 | Test loss: 2.8299  | Test acc: 0.7493\n",
      "\n",
      " Train loss: 0.0024723182432353497 | Test loss: 2.9085  | Test acc: 0.7562\n",
      "\n",
      " Train loss: 0.0004543194081634283 | Test loss: 3.3167  | Test acc: 0.7416\n",
      "\n",
      " Train loss: 0.0004153615445829928 | Test loss: 3.8765  | Test acc: 0.7152\n",
      "\n",
      " Train loss: 0.002507661236450076 | Test loss: 3.4504  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.0017842644592747092 | Test loss: 2.9696  | Test acc: 0.7532\n",
      "\n",
      " Train loss: 0.0011365513782948256 | Test loss: 2.5636  | Test acc: 0.7673\n",
      "\n",
      " Train loss: 0.0023289453238248825 | Test loss: 2.0313  | Test acc: 0.7897\n",
      "\n",
      " Train loss: 0.0007020868360996246 | Test loss: 2.2657  | Test acc: 0.7684\n",
      "\n",
      " Train loss: 0.001235556905157864 | Test loss: 2.3468  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.0010129362344741821 | Test loss: 2.2453  | Test acc: 0.7541\n",
      "\n",
      " Train loss: 0.001964920898899436 | Test loss: 2.4905  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.0015684723621234298 | Test loss: 2.9463  | Test acc: 0.6961\n",
      "\n",
      " Train loss: 0.0017652538372203708 | Test loss: 2.7561  | Test acc: 0.7121\n",
      "\n",
      " Train loss: 0.003754654433578253 | Test loss: 2.5469  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.000665077066514641 | Test loss: 2.4477  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0014187326887622476 | Test loss: 2.3536  | Test acc: 0.7441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0010493389563634992 | Test loss: 2.1728  | Test acc: 0.7584\n",
      "\n",
      " Train loss: 0.0010673076612874866 | Test loss: 1.8975  | Test acc: 0.7805\n",
      "\n",
      " Train loss: 0.0006449642824009061 | Test loss: 1.9416  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0007271524518728256 | Test loss: 2.2831  | Test acc: 0.7624\n",
      "\n",
      " Train loss: 0.0019304867601022124 | Test loss: 2.4736  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.00175545085221529 | Test loss: 2.4153  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.0007844795472919941 | Test loss: 2.3275  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.00115454092156142 | Test loss: 2.1358  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0008333036676049232 | Test loss: 2.3751  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.00044240523129701614 | Test loss: 2.7327  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.000558229919988662 | Test loss: 2.9298  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0015314138727262616 | Test loss: 2.3438  | Test acc: 0.7473\n",
      "\n",
      " Train loss: 0.0014950194163247943 | Test loss: 2.0906  | Test acc: 0.7615\n",
      "\n",
      " Train loss: 0.0018709679134190083 | Test loss: 2.3649  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.00022958999034017324 | Test loss: 2.9687  | Test acc: 0.6813\n",
      "\n",
      " Train loss: 0.002516975160688162 | Test loss: 2.7833  | Test acc: 0.6935\n",
      "\n",
      " Train loss: 0.0020156344398856163 | Test loss: 2.2714  | Test acc: 0.7259\n",
      "\n",
      " Train loss: 0.0013264549197629094 | Test loss: 2.1128  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.0005040249088779092 | Test loss: 2.0780  | Test acc: 0.7493\n",
      "\n",
      " Train loss: 0.00051206408534199 | Test loss: 2.0582  | Test acc: 0.7625\n",
      "\n",
      " Train loss: 0.002273011486977339 | Test loss: 1.9580  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.000933406874537468 | Test loss: 1.8863  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.000506087439134717 | Test loss: 1.9686  | Test acc: 0.7537\n",
      "\n",
      " Train loss: 0.0009538046433590353 | Test loss: 2.4011  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0011363321682438254 | Test loss: 2.5344  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.001231993781402707 | Test loss: 2.4834  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0012483044993132353 | Test loss: 2.5703  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.001679560518823564 | Test loss: 2.2500  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.0021558264270424843 | Test loss: 2.1099  | Test acc: 0.7574\n",
      "\n",
      " Train loss: 0.0009393758955411613 | Test loss: 2.1310  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.0026178087573498487 | Test loss: 2.1632  | Test acc: 0.7477\n",
      "\n",
      " Train loss: 0.0012653263984248042 | Test loss: 2.1104  | Test acc: 0.7506\n",
      "\n",
      " Train loss: 0.0016419996973127127 | Test loss: 2.0761  | Test acc: 0.7482\n",
      "\n",
      " Train loss: 0.0005617981078103185 | Test loss: 2.2037  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0005922449054196477 | Test loss: 2.6249  | Test acc: 0.7196\n",
      "\n",
      " Train loss: 0.0018128433730453253 | Test loss: 2.5373  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.001877009985037148 | Test loss: 2.2935  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.001429527415893972 | Test loss: 1.9399  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.0001301886368310079 | Test loss: 1.7195  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0014087097952142358 | Test loss: 1.6840  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0007304716273210943 | Test loss: 1.7423  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0010138637153431773 | Test loss: 2.0046  | Test acc: 0.7114\n",
      "\n",
      " Train loss: 0.0007243413710966706 | Test loss: 1.9206  | Test acc: 0.7358\n",
      "\n",
      " Train loss: 0.00046379989362321794 | Test loss: 1.9425  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.001163351465947926 | Test loss: 1.8885  | Test acc: 0.7550\n",
      "\n",
      " Train loss: 0.0008600474684499204 | Test loss: 1.9230  | Test acc: 0.7579\n",
      "\n",
      " Train loss: 0.000436207017628476 | Test loss: 2.0060  | Test acc: 0.7549\n",
      "\n",
      " Train loss: 0.0011665356578305364 | Test loss: 2.0247  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.000495324784424156 | Test loss: 2.3117  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.001114360406063497 | Test loss: 2.4279  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0011479707900434732 | Test loss: 2.6432  | Test acc: 0.7103\n",
      "\n",
      " Train loss: 0.0011538768885657191 | Test loss: 2.4125  | Test acc: 0.7347\n",
      "\n",
      " Train loss: 0.001404391834512353 | Test loss: 2.1304  | Test acc: 0.7589\n",
      "\n",
      " Train loss: 0.0010453808354213834 | Test loss: 2.1202  | Test acc: 0.7497\n",
      "\n",
      " Train loss: 0.0008346070535480976 | Test loss: 2.2878  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0006137678283266723 | Test loss: 2.4851  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.002637036144733429 | Test loss: 2.0304  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0010965323308482766 | Test loss: 2.2268  | Test acc: 0.7090\n",
      "\n",
      " Train loss: 0.0011197782587260008 | Test loss: 2.2793  | Test acc: 0.7063\n",
      "\n",
      " Train loss: 0.0008881629328243434 | Test loss: 2.0699  | Test acc: 0.7245\n",
      "\n",
      " Train loss: 0.0007790090749040246 | Test loss: 1.9154  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.0009582568309269845 | Test loss: 1.8709  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0016235187649726868 | Test loss: 1.8849  | Test acc: 0.7679\n",
      "\n",
      " Train loss: 0.0011308294488117099 | Test loss: 2.4039  | Test acc: 0.7071\n",
      "\n",
      " Train loss: 0.0002648956433404237 | Test loss: 3.1240  | Test acc: 0.6576\n",
      "\n",
      " Train loss: 0.0015160717302933335 | Test loss: 2.9152  | Test acc: 0.6784\n",
      "\n",
      " Train loss: 0.0031818151473999023 | Test loss: 2.0816  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.0008008501026779413 | Test loss: 2.2019  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0008340599597431719 | Test loss: 2.1433  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.0018512897659093142 | Test loss: 1.7203  | Test acc: 0.7696\n",
      "Looked at 25600/ 60000 samples\n",
      "\n",
      " Train loss: 0.0012800509575754404 | Test loss: 1.7610  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0010057291947305202 | Test loss: 2.0369  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0014068135060369968 | Test loss: 2.2021  | Test acc: 0.7446\n",
      "\n",
      " Train loss: 0.0015305443666875362 | Test loss: 2.1917  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0009897922864183784 | Test loss: 2.2047  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0011711212573572993 | Test loss: 2.1321  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.0010238339891657233 | Test loss: 1.8191  | Test acc: 0.7441\n",
      "\n",
      " Train loss: 0.0005872140754945576 | Test loss: 2.0778  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.0007064981618896127 | Test loss: 2.2513  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0009496014099568129 | Test loss: 2.3116  | Test acc: 0.7287\n",
      "\n",
      " Train loss: 0.0005898158997297287 | Test loss: 2.1096  | Test acc: 0.7468\n",
      "\n",
      " Train loss: 0.0011205311166122556 | Test loss: 1.8696  | Test acc: 0.7732\n",
      "\n",
      " Train loss: 0.0007523950771428645 | Test loss: 2.1055  | Test acc: 0.7617\n",
      "\n",
      " Train loss: 0.0012478556018322706 | Test loss: 2.3615  | Test acc: 0.7421\n",
      "\n",
      " Train loss: 0.001993251033127308 | Test loss: 2.2908  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.0011240129824727774 | Test loss: 2.2610  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0006774369394406676 | Test loss: 2.1127  | Test acc: 0.7429\n",
      "\n",
      " Train loss: 0.0010090006981045008 | Test loss: 2.1007  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0004793426487594843 | Test loss: 2.7935  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0013896293239668012 | Test loss: 3.3430  | Test acc: 0.6810\n",
      "\n",
      " Train loss: 0.002380744321271777 | Test loss: 2.9323  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.002363004954531789 | Test loss: 2.9359  | Test acc: 0.7154\n",
      "\n",
      " Train loss: 0.0015563997440040112 | Test loss: 4.0389  | Test acc: 0.6710\n",
      "\n",
      " Train loss: 0.0019915420562028885 | Test loss: 3.1906  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.0012275375192984939 | Test loss: 2.8102  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0006826662574894726 | Test loss: 2.9205  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0017809526761993766 | Test loss: 3.2213  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.002025959314778447 | Test loss: 3.3200  | Test acc: 0.6979\n",
      "\n",
      " Train loss: 0.0015809100586920977 | Test loss: 3.3597  | Test acc: 0.6913\n",
      "\n",
      " Train loss: 0.001946796546690166 | Test loss: 2.9091  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.0012163476785644889 | Test loss: 2.2980  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0011239066952839494 | Test loss: 2.3528  | Test acc: 0.7233\n",
      "\n",
      " Train loss: 0.0015144908102229238 | Test loss: 2.4365  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0003945740172639489 | Test loss: 2.4776  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.0020431624725461006 | Test loss: 2.4291  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.000926321605220437 | Test loss: 2.2789  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.0005130042554810643 | Test loss: 2.1745  | Test acc: 0.7541\n",
      "\n",
      " Train loss: 0.0008806304540485144 | Test loss: 1.9956  | Test acc: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.001003432204015553 | Test loss: 1.7879  | Test acc: 0.7789\n",
      "\n",
      " Train loss: 0.00046911975368857384 | Test loss: 1.8051  | Test acc: 0.7806\n",
      "\n",
      " Train loss: 0.0006217212066985667 | Test loss: 1.8493  | Test acc: 0.7800\n",
      "\n",
      " Train loss: 0.001208089990541339 | Test loss: 1.9669  | Test acc: 0.7668\n",
      "\n",
      " Train loss: 0.0006857097614556551 | Test loss: 2.1770  | Test acc: 0.7428\n",
      "\n",
      " Train loss: 0.0009288160363212228 | Test loss: 2.1907  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.000568229123018682 | Test loss: 2.1095  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.0006337776430882514 | Test loss: 1.8802  | Test acc: 0.7702\n",
      "\n",
      " Train loss: 0.0004701261059381068 | Test loss: 1.9362  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.0005386988050304353 | Test loss: 2.1451  | Test acc: 0.7569\n",
      "\n",
      " Train loss: 0.0011619110591709614 | Test loss: 2.2152  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.00011858626385219395 | Test loss: 2.4304  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0002742299984674901 | Test loss: 2.7986  | Test acc: 0.7228\n",
      "\n",
      " Train loss: 0.001289837178774178 | Test loss: 3.3693  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0018836857052519917 | Test loss: 2.5473  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0015899178106337786 | Test loss: 1.9067  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.000983546837233007 | Test loss: 2.1265  | Test acc: 0.7360\n",
      "\n",
      " Train loss: 0.0004976348136551678 | Test loss: 2.9422  | Test acc: 0.6896\n",
      "\n",
      " Train loss: 0.0016390486853197217 | Test loss: 2.8195  | Test acc: 0.7128\n",
      "\n",
      " Train loss: 0.0021024292800575495 | Test loss: 2.1698  | Test acc: 0.7539\n",
      "\n",
      " Train loss: 0.0011301947524771094 | Test loss: 1.8519  | Test acc: 0.7856\n",
      "\n",
      " Train loss: 0.000885663612280041 | Test loss: 1.8333  | Test acc: 0.7827\n",
      "\n",
      " Train loss: 0.0005392110324464738 | Test loss: 1.8357  | Test acc: 0.7817\n",
      "\n",
      " Train loss: 0.00042363748070783913 | Test loss: 1.9031  | Test acc: 0.7699\n",
      "\n",
      " Train loss: 0.0008336983155459166 | Test loss: 2.1662  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.0015774733619764447 | Test loss: 2.1261  | Test acc: 0.7353\n",
      "\n",
      " Train loss: 0.0013262442080304027 | Test loss: 2.1443  | Test acc: 0.7459\n",
      "\n",
      " Train loss: 0.001189347472973168 | Test loss: 2.3275  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.00048036070074886084 | Test loss: 2.6337  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.0013837270671501756 | Test loss: 1.9874  | Test acc: 0.7543\n",
      "\n",
      " Train loss: 0.0006803947617299855 | Test loss: 2.0567  | Test acc: 0.7753\n",
      "\n",
      " Train loss: 0.000687021529302001 | Test loss: 2.7670  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.002031423384323716 | Test loss: 2.3491  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0007153693586587906 | Test loss: 2.3353  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.001953303115442395 | Test loss: 2.3858  | Test acc: 0.7506\n",
      "\n",
      " Train loss: 0.0009499688749201596 | Test loss: 2.3956  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.0009382672142237425 | Test loss: 2.3143  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0012483360478654504 | Test loss: 2.0401  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0009797151433303952 | Test loss: 1.9084  | Test acc: 0.7812\n",
      "\n",
      " Train loss: 0.000818918168079108 | Test loss: 1.9122  | Test acc: 0.7808\n",
      "\n",
      " Train loss: 0.0005368654383346438 | Test loss: 2.0076  | Test acc: 0.7694\n",
      "\n",
      " Train loss: 0.0008903213310986757 | Test loss: 2.1532  | Test acc: 0.7510\n",
      "\n",
      " Train loss: 0.0007724692695774138 | Test loss: 2.1239  | Test acc: 0.7702\n",
      "\n",
      " Train loss: 0.0015789661556482315 | Test loss: 2.1940  | Test acc: 0.7748\n",
      "\n",
      " Train loss: 0.0014493478229269385 | Test loss: 2.4708  | Test acc: 0.7708\n",
      "\n",
      " Train loss: 0.0008370251744054258 | Test loss: 2.6770  | Test acc: 0.7605\n",
      "\n",
      " Train loss: 0.0007915819296613336 | Test loss: 3.1868  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0010624490678310394 | Test loss: 3.1907  | Test acc: 0.7120\n",
      "\n",
      " Train loss: 0.0016457949532195926 | Test loss: 2.5601  | Test acc: 0.7518\n",
      "\n",
      " Train loss: 0.0008821153896860778 | Test loss: 2.3899  | Test acc: 0.7543\n",
      "\n",
      " Train loss: 0.0006388301844708622 | Test loss: 2.6773  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.00048064609291031957 | Test loss: 4.6640  | Test acc: 0.6414\n",
      "\n",
      " Train loss: 0.0014455593191087246 | Test loss: 5.7704  | Test acc: 0.6213\n",
      "\n",
      " Train loss: 0.0031156810000538826 | Test loss: 3.4688  | Test acc: 0.7165\n",
      "\n",
      " Train loss: 0.0029640081338584423 | Test loss: 2.5481  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.000866006943397224 | Test loss: 3.0067  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.002524422714486718 | Test loss: 3.0871  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0015530724776908755 | Test loss: 2.7632  | Test acc: 0.7651\n",
      "\n",
      " Train loss: 0.0015908661298453808 | Test loss: 3.5936  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.001145074376836419 | Test loss: 4.4923  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.001410544733516872 | Test loss: 4.4138  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.003317950526252389 | Test loss: 2.9414  | Test acc: 0.7457\n",
      "\n",
      " Train loss: 0.0014451786410063505 | Test loss: 4.1514  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0031964259687811136 | Test loss: 5.4937  | Test acc: 0.7013\n",
      "\n",
      " Train loss: 0.002756275935098529 | Test loss: 5.6682  | Test acc: 0.6968\n",
      "\n",
      " Train loss: 0.0021494608372449875 | Test loss: 5.0398  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.001964505994692445 | Test loss: 5.1541  | Test acc: 0.6667\n",
      "\n",
      " Train loss: 0.003705622861161828 | Test loss: 4.1042  | Test acc: 0.6729\n",
      "\n",
      " Train loss: 0.003154207020998001 | Test loss: 2.7747  | Test acc: 0.6948\n",
      "\n",
      " Train loss: 0.0026548609603196383 | Test loss: 2.7683  | Test acc: 0.7067\n",
      "\n",
      " Train loss: 0.0028845597989857197 | Test loss: 2.9650  | Test acc: 0.7039\n",
      "\n",
      " Train loss: 0.0013847049558535218 | Test loss: 2.2345  | Test acc: 0.7579\n",
      "\n",
      " Train loss: 0.002390447538346052 | Test loss: 2.1395  | Test acc: 0.7698\n",
      "\n",
      " Train loss: 0.0012401111889630556 | Test loss: 2.4794  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.0006900930311530828 | Test loss: 2.8159  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.001116956234909594 | Test loss: 2.2031  | Test acc: 0.7632\n",
      "\n",
      " Train loss: 0.0003623350348789245 | Test loss: 1.9106  | Test acc: 0.7850\n",
      "\n",
      " Train loss: 0.0016398060834035277 | Test loss: 1.9075  | Test acc: 0.7774\n",
      "\n",
      " Train loss: 0.0008804957033134997 | Test loss: 2.0618  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.0013568022986873984 | Test loss: 2.0202  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0006112575647421181 | Test loss: 1.8585  | Test acc: 0.7616\n",
      "\n",
      " Train loss: 0.001063716015778482 | Test loss: 2.1943  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0014130271738395095 | Test loss: 2.7768  | Test acc: 0.7131\n",
      "\n",
      " Train loss: 0.003075740300118923 | Test loss: 2.2609  | Test acc: 0.7497\n",
      "\n",
      " Train loss: 0.0025722491554915905 | Test loss: 1.9044  | Test acc: 0.7785\n",
      "\n",
      " Train loss: 0.0010853904532268643 | Test loss: 2.0429  | Test acc: 0.7632\n",
      "\n",
      " Train loss: 0.0013496727915480733 | Test loss: 2.1672  | Test acc: 0.7482\n",
      "\n",
      " Train loss: 0.001172790420241654 | Test loss: 2.2567  | Test acc: 0.7396\n",
      "\n",
      " Train loss: 0.0018047698540613055 | Test loss: 2.3503  | Test acc: 0.7325\n",
      "\n",
      " Train loss: 0.0007650246261619031 | Test loss: 2.2042  | Test acc: 0.7424\n",
      "\n",
      " Train loss: 0.0014179563149809837 | Test loss: 2.0950  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0009811094496399164 | Test loss: 1.7809  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0006109164096415043 | Test loss: 1.7871  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.0005235281423665583 | Test loss: 2.1296  | Test acc: 0.7282\n",
      "\n",
      " Train loss: 0.0006401598220691085 | Test loss: 2.5065  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0026208546478301287 | Test loss: 2.4030  | Test acc: 0.7176\n",
      "\n",
      " Train loss: 0.001320666866376996 | Test loss: 2.7420  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.001184379099868238 | Test loss: 2.2141  | Test acc: 0.7559\n",
      "\n",
      " Train loss: 0.0012610990088433027 | Test loss: 2.5710  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0009808159666135907 | Test loss: 3.0492  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0012588885147124529 | Test loss: 2.8022  | Test acc: 0.7353\n",
      "\n",
      " Train loss: 0.0014837362105026841 | Test loss: 2.3302  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.0004542209208011627 | Test loss: 2.4295  | Test acc: 0.7489\n",
      "\n",
      " Train loss: 0.0008392497547902167 | Test loss: 2.5250  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0004927597474306822 | Test loss: 2.7266  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.0016410212265327573 | Test loss: 2.9544  | Test acc: 0.7213\n",
      "\n",
      " Train loss: 0.001758430153131485 | Test loss: 2.9208  | Test acc: 0.7161\n",
      "\n",
      " Train loss: 0.0012135386932641268 | Test loss: 2.8469  | Test acc: 0.7204\n",
      "\n",
      " Train loss: 0.001773330383002758 | Test loss: 2.7710  | Test acc: 0.7259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0018340650713071227 | Test loss: 2.4825  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.001105982344597578 | Test loss: 2.5584  | Test acc: 0.7517\n",
      "\n",
      " Train loss: 0.0021137897856533527 | Test loss: 2.3987  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0010225169826298952 | Test loss: 2.3011  | Test acc: 0.7767\n",
      "\n",
      " Train loss: 0.0006941335159353912 | Test loss: 2.3510  | Test acc: 0.7708\n",
      "\n",
      " Train loss: 0.002216866472736001 | Test loss: 2.6695  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.001853125519119203 | Test loss: 2.7056  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0009420271962881088 | Test loss: 2.5773  | Test acc: 0.7297\n",
      "\n",
      " Train loss: 0.0004619103856384754 | Test loss: 2.9968  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.000758933019824326 | Test loss: 3.8266  | Test acc: 0.6713\n",
      "\n",
      " Train loss: 0.0015958512667566538 | Test loss: 2.6156  | Test acc: 0.7463\n",
      "\n",
      " Train loss: 0.0013499788474291563 | Test loss: 2.2768  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.000691014516633004 | Test loss: 2.0425  | Test acc: 0.7635\n",
      "\n",
      " Train loss: 0.0006970923277549446 | Test loss: 1.9649  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.0006035704864189029 | Test loss: 2.2279  | Test acc: 0.7254\n",
      "\n",
      " Train loss: 0.0003899885050486773 | Test loss: 2.8712  | Test acc: 0.6779\n",
      "\n",
      " Train loss: 0.0007063275552354753 | Test loss: 2.9214  | Test acc: 0.6896\n",
      "\n",
      " Train loss: 0.0023314531426876783 | Test loss: 2.6483  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0011715246364474297 | Test loss: 2.5278  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.0027545802295207977 | Test loss: 3.6943  | Test acc: 0.6860\n",
      "\n",
      " Train loss: 0.004295773338526487 | Test loss: 3.4941  | Test acc: 0.6898\n",
      "\n",
      " Train loss: 0.0013076643226668239 | Test loss: 3.0364  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.0029368021059781313 | Test loss: 2.4711  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.0011626286432147026 | Test loss: 2.5254  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0008017606451176107 | Test loss: 2.2147  | Test acc: 0.7450\n",
      "\n",
      " Train loss: 0.0005251492839306593 | Test loss: 2.1011  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0007000984041951597 | Test loss: 2.2259  | Test acc: 0.7594\n",
      "\n",
      " Train loss: 0.0010055735474452376 | Test loss: 2.5897  | Test acc: 0.7209\n",
      "\n",
      " Train loss: 0.0006624396773986518 | Test loss: 3.8740  | Test acc: 0.6671\n",
      "\n",
      " Train loss: 0.0026363094802945852 | Test loss: 2.6173  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.00025454408023506403 | Test loss: 2.1450  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.0023976447992026806 | Test loss: 2.8622  | Test acc: 0.7262\n",
      "\n",
      " Train loss: 0.0033018523827195168 | Test loss: 2.7477  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.0011074375361204147 | Test loss: 3.8255  | Test acc: 0.7174\n",
      "\n",
      " Train loss: 0.003274568123742938 | Test loss: 3.6822  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0020080620888620615 | Test loss: 2.9075  | Test acc: 0.7478\n",
      "\n",
      " Train loss: 0.0011661913013085723 | Test loss: 2.6949  | Test acc: 0.7500\n",
      "\n",
      " Train loss: 0.00279097817838192 | Test loss: 3.1177  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0013177110813558102 | Test loss: 2.7143  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.0014009402366355062 | Test loss: 4.2583  | Test acc: 0.6239\n",
      "\n",
      " Train loss: 0.0010074155870825052 | Test loss: 5.7603  | Test acc: 0.5938\n",
      "\n",
      " Train loss: 0.0032409061677753925 | Test loss: 4.4851  | Test acc: 0.6595\n",
      "\n",
      " Train loss: 0.002806035801768303 | Test loss: 3.8348  | Test acc: 0.6851\n",
      "\n",
      " Train loss: 0.003801817772909999 | Test loss: 3.3189  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0014688331866636872 | Test loss: 4.3753  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0028099624905735254 | Test loss: 4.8237  | Test acc: 0.7074\n",
      "\n",
      " Train loss: 0.002235078951343894 | Test loss: 3.8725  | Test acc: 0.7162\n",
      "\n",
      " Train loss: 0.003913223743438721 | Test loss: 2.7906  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.001892086467705667 | Test loss: 3.2982  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0020211830269545317 | Test loss: 3.6730  | Test acc: 0.7158\n",
      "\n",
      " Train loss: 0.002380470745265484 | Test loss: 3.7429  | Test acc: 0.6992\n",
      "\n",
      " Train loss: 0.0028146354015916586 | Test loss: 2.4575  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.001270256587304175 | Test loss: 3.4678  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.0012290755985304713 | Test loss: 5.6786  | Test acc: 0.6048\n",
      "\n",
      " Train loss: 0.004233493935316801 | Test loss: 3.7263  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.0015255343168973923 | Test loss: 2.6704  | Test acc: 0.7549\n",
      "\n",
      " Train loss: 0.0009434529347345233 | Test loss: 2.6904  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.0011459667002782226 | Test loss: 2.6559  | Test acc: 0.7472\n",
      "\n",
      " Train loss: 0.0012089418014511466 | Test loss: 2.5652  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0008125418098643422 | Test loss: 2.9097  | Test acc: 0.7374\n",
      "\n",
      " Train loss: 0.002459784271195531 | Test loss: 2.8620  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0004921640502288938 | Test loss: 3.0520  | Test acc: 0.7196\n",
      "\n",
      " Train loss: 0.0026053283363580704 | Test loss: 2.8146  | Test acc: 0.7492\n",
      "\n",
      " Train loss: 0.0015877155819907784 | Test loss: 3.2429  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.0024739678483456373 | Test loss: 2.6561  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0007398806046694517 | Test loss: 2.3419  | Test acc: 0.7649\n",
      "\n",
      " Train loss: 0.0009347276645712554 | Test loss: 2.2832  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0019268217729404569 | Test loss: 2.5162  | Test acc: 0.7254\n",
      "\n",
      " Train loss: 0.0006786921876482666 | Test loss: 2.6114  | Test acc: 0.7325\n",
      "\n",
      " Train loss: 0.0034835331607609987 | Test loss: 3.1564  | Test acc: 0.7120\n",
      "\n",
      " Train loss: 0.0017869469011202455 | Test loss: 2.4707  | Test acc: 0.7426\n",
      "\n",
      " Train loss: 0.000657693250104785 | Test loss: 2.8905  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.0012191502610221505 | Test loss: 3.5006  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.001688405405730009 | Test loss: 2.7730  | Test acc: 0.7460\n",
      "\n",
      " Train loss: 0.0012423868756741285 | Test loss: 2.6439  | Test acc: 0.7554\n",
      "\n",
      " Train loss: 0.0007681745337322354 | Test loss: 2.0181  | Test acc: 0.7911\n",
      "\n",
      " Train loss: 0.0016507760155946016 | Test loss: 2.2275  | Test acc: 0.7623\n",
      "\n",
      " Train loss: 0.0015000521671026945 | Test loss: 2.9495  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.001680007902905345 | Test loss: 2.1594  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.002086317865177989 | Test loss: 2.2835  | Test acc: 0.7681\n",
      "\n",
      " Train loss: 0.0005990152130834758 | Test loss: 2.4491  | Test acc: 0.7638\n",
      "\n",
      " Train loss: 0.00046846046461723745 | Test loss: 2.4205  | Test acc: 0.7670\n",
      "\n",
      " Train loss: 0.002071738475933671 | Test loss: 2.5564  | Test acc: 0.7486\n",
      "\n",
      " Train loss: 0.001938311499543488 | Test loss: 3.1893  | Test acc: 0.7112\n",
      "\n",
      " Train loss: 0.00036249574623070657 | Test loss: 3.4135  | Test acc: 0.7011\n",
      "\n",
      " Train loss: 0.0005813496536575258 | Test loss: 3.5206  | Test acc: 0.7002\n",
      "\n",
      " Train loss: 0.000946127693168819 | Test loss: 3.2004  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.001457500853575766 | Test loss: 2.7244  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0013245681766420603 | Test loss: 2.5973  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.001433721510693431 | Test loss: 3.4717  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.00136083853431046 | Test loss: 3.4172  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0016191861359402537 | Test loss: 2.9877  | Test acc: 0.7362\n",
      "\n",
      " Train loss: 0.0007708381745032966 | Test loss: 2.9256  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.001830611377954483 | Test loss: 3.2520  | Test acc: 0.7338\n",
      "\n",
      " Train loss: 0.0029101574327796698 | Test loss: 3.4284  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.000989701715297997 | Test loss: 2.9237  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.0006489639054052532 | Test loss: 2.8403  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.0011849006405100226 | Test loss: 2.8137  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.00144956074655056 | Test loss: 2.3762  | Test acc: 0.7338\n",
      "\n",
      " Train loss: 0.0012103836052119732 | Test loss: 2.4105  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.0007987837889231741 | Test loss: 2.5291  | Test acc: 0.7663\n",
      "\n",
      " Train loss: 0.0014452795730903745 | Test loss: 2.4212  | Test acc: 0.7688\n",
      "\n",
      " Train loss: 0.0004082527884747833 | Test loss: 2.3350  | Test acc: 0.7686\n",
      "\n",
      " Train loss: 0.002906985580921173 | Test loss: 2.0201  | Test acc: 0.7792\n",
      "\n",
      " Train loss: 0.0006240639486350119 | Test loss: 1.9388  | Test acc: 0.7716\n",
      "\n",
      " Train loss: 0.0008299083565361798 | Test loss: 1.9830  | Test acc: 0.7666\n",
      "\n",
      " Train loss: 0.0010003444040194154 | Test loss: 2.0672  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0008734933217056096 | Test loss: 2.0760  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.0016629924066364765 | Test loss: 2.1345  | Test acc: 0.7269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0007870002882555127 | Test loss: 2.1542  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0017819568747654557 | Test loss: 2.1025  | Test acc: 0.7054\n",
      "\n",
      " Train loss: 0.0007606815197505057 | Test loss: 1.9587  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0013517428888007998 | Test loss: 1.7822  | Test acc: 0.7222\n",
      "\n",
      " Train loss: 0.000994740636087954 | Test loss: 1.7066  | Test acc: 0.7365\n",
      "\n",
      " Train loss: 0.0009432740043848753 | Test loss: 1.7460  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0007733081583864987 | Test loss: 1.7859  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.0007622126722708344 | Test loss: 1.8198  | Test acc: 0.7516\n",
      "\n",
      " Train loss: 0.0014669990632683039 | Test loss: 1.5825  | Test acc: 0.7666\n",
      "\n",
      " Train loss: 0.0007758632418699563 | Test loss: 1.8194  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0010836730943992734 | Test loss: 2.5337  | Test acc: 0.6728\n",
      "\n",
      " Train loss: 0.000528989068698138 | Test loss: 2.2196  | Test acc: 0.7159\n",
      "\n",
      " Train loss: 0.00124250422231853 | Test loss: 1.9085  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.0013946410035714507 | Test loss: 1.6894  | Test acc: 0.7780\n",
      "\n",
      " Train loss: 0.0015695331385359168 | Test loss: 1.6755  | Test acc: 0.7869\n",
      "\n",
      " Train loss: 0.0006814388325437903 | Test loss: 2.1848  | Test acc: 0.7410\n",
      "\n",
      " Train loss: 0.001321254065260291 | Test loss: 2.4692  | Test acc: 0.7287\n",
      "\n",
      " Train loss: 0.001955826301127672 | Test loss: 1.9060  | Test acc: 0.7745\n",
      "\n",
      " Train loss: 0.0014420277439057827 | Test loss: 1.6730  | Test acc: 0.7897\n",
      "\n",
      " Train loss: 0.000511077290866524 | Test loss: 2.0527  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.00080861960304901 | Test loss: 2.6014  | Test acc: 0.7247\n",
      "\n",
      " Train loss: 0.003231396898627281 | Test loss: 2.9371  | Test acc: 0.6793\n",
      "\n",
      " Train loss: 0.001667859498411417 | Test loss: 2.9823  | Test acc: 0.6710\n",
      "\n",
      " Train loss: 0.001787453657016158 | Test loss: 2.2691  | Test acc: 0.7002\n",
      "\n",
      " Train loss: 0.0006672872113995254 | Test loss: 1.9221  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0017981933197006583 | Test loss: 1.7162  | Test acc: 0.7528\n",
      "\n",
      " Train loss: 0.0003984449722338468 | Test loss: 1.9344  | Test acc: 0.7282\n",
      "\n",
      " Train loss: 0.0010100161889567971 | Test loss: 2.1108  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.0010727302869781852 | Test loss: 2.5182  | Test acc: 0.6742\n",
      "\n",
      " Train loss: 0.0022015098948031664 | Test loss: 2.4853  | Test acc: 0.6805\n",
      "\n",
      " Train loss: 0.0008912576013244689 | Test loss: 1.9288  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.002289555035531521 | Test loss: 1.6640  | Test acc: 0.7601\n",
      "\n",
      " Train loss: 0.0009242225205525756 | Test loss: 2.7562  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.0008418168290518224 | Test loss: 3.1759  | Test acc: 0.6899\n",
      "\n",
      " Train loss: 0.0011512498604133725 | Test loss: 2.0706  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.0018046792829409242 | Test loss: 1.4994  | Test acc: 0.7801\n",
      "\n",
      " Train loss: 0.00045137834968045354 | Test loss: 1.8601  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.0004065481189172715 | Test loss: 2.2674  | Test acc: 0.7065\n",
      "\n",
      " Train loss: 0.0010717394761741161 | Test loss: 2.3133  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0008257143199443817 | Test loss: 3.1519  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.0008103529689833522 | Test loss: 3.4747  | Test acc: 0.7037\n",
      "\n",
      " Train loss: 0.0015648978296667337 | Test loss: 3.1424  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.0022288498003035784 | Test loss: 2.0626  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0009019423159770668 | Test loss: 1.6749  | Test acc: 0.7795\n",
      "\n",
      " Train loss: 0.0004448808904271573 | Test loss: 2.4750  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0010607686126604676 | Test loss: 2.6532  | Test acc: 0.7149\n",
      "\n",
      " Train loss: 0.0013407476944848895 | Test loss: 2.4637  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.0014827607665210962 | Test loss: 2.1361  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0011288805399090052 | Test loss: 2.0429  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.000388369953725487 | Test loss: 2.2299  | Test acc: 0.7428\n",
      "\n",
      " Train loss: 0.00012757159129250795 | Test loss: 2.4745  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0007420260808430612 | Test loss: 2.8906  | Test acc: 0.6972\n",
      "\n",
      " Train loss: 0.0012921160086989403 | Test loss: 2.7732  | Test acc: 0.7064\n",
      "\n",
      " Train loss: 0.002361756283789873 | Test loss: 2.5165  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.001021207426674664 | Test loss: 2.3609  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.0013011114206165075 | Test loss: 2.8062  | Test acc: 0.7003\n",
      "\n",
      " Train loss: 0.0008665708592161536 | Test loss: 3.3641  | Test acc: 0.6706\n",
      "\n",
      " Train loss: 0.0016440891195088625 | Test loss: 3.1679  | Test acc: 0.6961\n",
      "\n",
      " Train loss: 0.0028124942909926176 | Test loss: 2.9070  | Test acc: 0.7115\n",
      "\n",
      " Train loss: 0.0018058082787320018 | Test loss: 3.3480  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0014497701777145267 | Test loss: 3.5963  | Test acc: 0.6810\n",
      "\n",
      " Train loss: 0.0018086223863065243 | Test loss: 2.4821  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0014458552468568087 | Test loss: 2.3487  | Test acc: 0.7307\n",
      "\n",
      " Train loss: 0.0020104609429836273 | Test loss: 2.9202  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0020710297394543886 | Test loss: 2.8541  | Test acc: 0.7050\n",
      "\n",
      " Train loss: 0.0006889221840538085 | Test loss: 3.7921  | Test acc: 0.6528\n",
      "\n",
      " Train loss: 0.002241302514448762 | Test loss: 2.8488  | Test acc: 0.7006\n",
      "\n",
      " Train loss: 0.0012437039986252785 | Test loss: 2.1972  | Test acc: 0.7468\n",
      "\n",
      " Train loss: 0.001269282540306449 | Test loss: 2.3092  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.000874559860676527 | Test loss: 2.0845  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0014760198537260294 | Test loss: 2.1557  | Test acc: 0.7635\n",
      "\n",
      " Train loss: 0.0010503570083528757 | Test loss: 2.5855  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.0011841367231681943 | Test loss: 3.0455  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.0021138680167496204 | Test loss: 3.0991  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.0013234212528914213 | Test loss: 2.8123  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0026746804360300303 | Test loss: 2.4880  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0021516126580536366 | Test loss: 2.1854  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0007433278951793909 | Test loss: 2.5320  | Test acc: 0.7017\n",
      "\n",
      " Train loss: 0.0017364583909511566 | Test loss: 2.6446  | Test acc: 0.6899\n",
      "\n",
      " Train loss: 0.0009519280283711851 | Test loss: 2.6473  | Test acc: 0.6982\n",
      "\n",
      " Train loss: 0.0004598784144036472 | Test loss: 2.7575  | Test acc: 0.7016\n",
      "\n",
      " Train loss: 0.0006477859569713473 | Test loss: 3.3365  | Test acc: 0.6618\n",
      "\n",
      " Train loss: 0.0019815510604530573 | Test loss: 2.8016  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.001122937654145062 | Test loss: 2.1511  | Test acc: 0.7483\n",
      "\n",
      " Train loss: 0.00046676339115947485 | Test loss: 2.6385  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0021618972532451153 | Test loss: 2.8200  | Test acc: 0.7198\n",
      "\n",
      " Train loss: 0.0016855366993695498 | Test loss: 2.6817  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0006567903910763562 | Test loss: 2.5297  | Test acc: 0.7326\n",
      "\n",
      " Train loss: 0.0006234731408767402 | Test loss: 2.4614  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0006226358818821609 | Test loss: 2.5256  | Test acc: 0.7676\n",
      "\n",
      " Train loss: 0.0015035996912047267 | Test loss: 2.4676  | Test acc: 0.7802\n",
      "\n",
      " Train loss: 0.0016848094528540969 | Test loss: 2.3667  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0007789402734488249 | Test loss: 2.2580  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0013254126533865929 | Test loss: 2.0847  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.001259754179045558 | Test loss: 2.6790  | Test acc: 0.7009\n",
      "\n",
      " Train loss: 0.0011996724642813206 | Test loss: 3.0501  | Test acc: 0.6939\n",
      "\n",
      " Train loss: 0.0019269553013145924 | Test loss: 2.8572  | Test acc: 0.6960\n",
      "\n",
      " Train loss: 0.0013150942977517843 | Test loss: 2.6152  | Test acc: 0.7128\n",
      "\n",
      " Train loss: 0.002798252273350954 | Test loss: 2.4295  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.0008257461013272405 | Test loss: 3.1867  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.002874956000596285 | Test loss: 2.7422  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.0011980291455984116 | Test loss: 3.0579  | Test acc: 0.6856\n",
      "\n",
      " Train loss: 0.002854685764759779 | Test loss: 2.7310  | Test acc: 0.6948\n",
      "\n",
      " Train loss: 0.0006392834475263953 | Test loss: 2.3451  | Test acc: 0.7249\n",
      "\n",
      " Train loss: 0.0013023861683905125 | Test loss: 1.8239  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0005046233418397605 | Test loss: 2.0037  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0005841170204803348 | Test loss: 2.1977  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0013344635954126716 | Test loss: 2.1379  | Test acc: 0.7167\n",
      "\n",
      " Train loss: 0.0013812450924888253 | Test loss: 2.0600  | Test acc: 0.7149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.000807659700512886 | Test loss: 2.3292  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.0006577497697435319 | Test loss: 2.7019  | Test acc: 0.6853\n",
      "\n",
      " Train loss: 0.0030154758132994175 | Test loss: 1.8892  | Test acc: 0.7452\n",
      "\n",
      " Train loss: 0.0004970492445863783 | Test loss: 1.7221  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.0017120798584073782 | Test loss: 1.8933  | Test acc: 0.7435\n",
      "\n",
      " Train loss: 0.0005500513361766934 | Test loss: 2.2062  | Test acc: 0.7311\n",
      "\n",
      " Train loss: 0.002455485984683037 | Test loss: 2.1960  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.001257863244973123 | Test loss: 2.0700  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0014964878791943192 | Test loss: 1.9144  | Test acc: 0.7472\n",
      "\n",
      " Train loss: 0.0006299025844782591 | Test loss: 2.1750  | Test acc: 0.7217\n",
      "\n",
      " Train loss: 0.001157652004621923 | Test loss: 1.9843  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0019100812496617436 | Test loss: 1.9179  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.0005069639883004129 | Test loss: 1.8822  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.0007289939094334841 | Test loss: 1.8750  | Test acc: 0.7311\n",
      "\n",
      " Train loss: 0.0008710657712072134 | Test loss: 2.0133  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0012416518293321133 | Test loss: 2.0912  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0012800168478861451 | Test loss: 1.9267  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.00094928580801934 | Test loss: 1.6465  | Test acc: 0.7239\n",
      "\n",
      " Train loss: 0.0006628713454119861 | Test loss: 1.5398  | Test acc: 0.7549\n",
      "\n",
      " Train loss: 0.0004235848318785429 | Test loss: 1.8393  | Test acc: 0.7223\n",
      "\n",
      " Train loss: 0.0008378939237445593 | Test loss: 2.0204  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0006129792891442776 | Test loss: 1.9654  | Test acc: 0.7343\n",
      "\n",
      " Train loss: 0.0003690820303745568 | Test loss: 2.0081  | Test acc: 0.7410\n",
      "\n",
      " Train loss: 0.0012426008470356464 | Test loss: 1.8803  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.0008842322276905179 | Test loss: 1.8942  | Test acc: 0.7203\n",
      "\n",
      " Train loss: 0.0003784103610087186 | Test loss: 2.2354  | Test acc: 0.6952\n",
      "\n",
      " Train loss: 0.0007665242883376777 | Test loss: 2.4353  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0014627183554694057 | Test loss: 2.2320  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0011563622392714024 | Test loss: 2.0714  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0012232697336003184 | Test loss: 1.8085  | Test acc: 0.7572\n",
      "\n",
      " Train loss: 0.0013443491188809276 | Test loss: 1.6305  | Test acc: 0.7737\n",
      "\n",
      " Train loss: 0.0006558897439390421 | Test loss: 1.5758  | Test acc: 0.7817\n",
      "\n",
      " Train loss: 0.0005763955996371806 | Test loss: 1.4763  | Test acc: 0.7928\n",
      "\n",
      " Train loss: 0.0010072981240227818 | Test loss: 1.4831  | Test acc: 0.7909\n",
      "\n",
      " Train loss: 0.00044471630826592445 | Test loss: 1.7715  | Test acc: 0.7556\n",
      "Looked at 38400/ 60000 samples\n",
      "\n",
      " Train loss: 0.0005162748857401311 | Test loss: 2.3065  | Test acc: 0.7120\n",
      "\n",
      " Train loss: 0.0008414176409132779 | Test loss: 2.1013  | Test acc: 0.7348\n",
      "\n",
      " Train loss: 0.001400316134095192 | Test loss: 1.9927  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0006825101445429027 | Test loss: 2.0591  | Test acc: 0.7601\n",
      "\n",
      " Train loss: 0.0008398646605201066 | Test loss: 2.4215  | Test acc: 0.7421\n",
      "\n",
      " Train loss: 0.002028187969699502 | Test loss: 3.0326  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.002351931296288967 | Test loss: 2.7444  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.0009584907675161958 | Test loss: 2.1893  | Test acc: 0.7345\n",
      "\n",
      " Train loss: 0.0007968359277583659 | Test loss: 2.7611  | Test acc: 0.7006\n",
      "\n",
      " Train loss: 0.0011361073702573776 | Test loss: 3.0490  | Test acc: 0.6955\n",
      "\n",
      " Train loss: 0.002281680703163147 | Test loss: 2.6793  | Test acc: 0.6837\n",
      "\n",
      " Train loss: 0.0021545360796153545 | Test loss: 2.9318  | Test acc: 0.6872\n",
      "\n",
      " Train loss: 0.002687703352421522 | Test loss: 2.5121  | Test acc: 0.6937\n",
      "\n",
      " Train loss: 0.0025237000081688166 | Test loss: 2.2818  | Test acc: 0.7059\n",
      "\n",
      " Train loss: 0.0011326313251629472 | Test loss: 2.2249  | Test acc: 0.7062\n",
      "\n",
      " Train loss: 0.0009928252547979355 | Test loss: 2.6681  | Test acc: 0.6672\n",
      "\n",
      " Train loss: 0.001241890131495893 | Test loss: 2.8881  | Test acc: 0.6694\n",
      "\n",
      " Train loss: 0.0012551244581118226 | Test loss: 2.4128  | Test acc: 0.6887\n",
      "\n",
      " Train loss: 0.0015887265326455235 | Test loss: 2.3624  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0010169988963752985 | Test loss: 3.1849  | Test acc: 0.6541\n",
      "\n",
      " Train loss: 0.0016922480426728725 | Test loss: 2.1885  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.000937574717681855 | Test loss: 1.7244  | Test acc: 0.7685\n",
      "\n",
      " Train loss: 0.0008454862982034683 | Test loss: 1.9086  | Test acc: 0.7720\n",
      "\n",
      " Train loss: 0.00010463424405315891 | Test loss: 2.7567  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0011161533184349537 | Test loss: 3.1813  | Test acc: 0.7247\n",
      "\n",
      " Train loss: 0.0023779915645718575 | Test loss: 2.8966  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.0010238575050607324 | Test loss: 2.8701  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.0010313699021935463 | Test loss: 2.4621  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.0013611336471512914 | Test loss: 2.2701  | Test acc: 0.7554\n",
      "\n",
      " Train loss: 0.0008636970305815339 | Test loss: 2.4573  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.000425913865910843 | Test loss: 2.6744  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.0008555959793739021 | Test loss: 2.7731  | Test acc: 0.7234\n",
      "\n",
      " Train loss: 0.0012787714367732406 | Test loss: 2.8572  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.0021729490254074335 | Test loss: 2.3696  | Test acc: 0.7506\n",
      "\n",
      " Train loss: 0.0011442364193499088 | Test loss: 2.2933  | Test acc: 0.7512\n",
      "\n",
      " Train loss: 0.0005382856470532715 | Test loss: 2.8110  | Test acc: 0.7376\n",
      "\n",
      " Train loss: 0.001111511024646461 | Test loss: 2.5485  | Test acc: 0.7399\n",
      "\n",
      " Train loss: 0.0014896391658112407 | Test loss: 2.1715  | Test acc: 0.7691\n",
      "\n",
      " Train loss: 0.0012845025630667806 | Test loss: 3.1640  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.0026678629219532013 | Test loss: 3.7851  | Test acc: 0.6609\n",
      "\n",
      " Train loss: 0.0015175013104453683 | Test loss: 4.1408  | Test acc: 0.6494\n",
      "\n",
      " Train loss: 0.0019490926060825586 | Test loss: 3.5747  | Test acc: 0.6682\n",
      "\n",
      " Train loss: 0.0015078171854838729 | Test loss: 2.4906  | Test acc: 0.6932\n",
      "\n",
      " Train loss: 0.000992292887531221 | Test loss: 2.3277  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0007170782773755491 | Test loss: 2.4050  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0004848612588830292 | Test loss: 2.2554  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.0021327012218534946 | Test loss: 2.0550  | Test acc: 0.7557\n",
      "\n",
      " Train loss: 0.001986726652830839 | Test loss: 2.1423  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.0014833630993962288 | Test loss: 2.5314  | Test acc: 0.7023\n",
      "\n",
      " Train loss: 0.0008916078368201852 | Test loss: 2.6449  | Test acc: 0.7130\n",
      "\n",
      " Train loss: 0.001928290817886591 | Test loss: 2.5197  | Test acc: 0.7045\n",
      "\n",
      " Train loss: 0.0015843409346416593 | Test loss: 2.0591  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.00121962686534971 | Test loss: 2.3213  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0003845000173896551 | Test loss: 2.7114  | Test acc: 0.7150\n",
      "\n",
      " Train loss: 0.0015171387931331992 | Test loss: 2.9155  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0006578646716661751 | Test loss: 2.5951  | Test acc: 0.7273\n",
      "\n",
      " Train loss: 0.001043331460095942 | Test loss: 2.1459  | Test acc: 0.7666\n",
      "\n",
      " Train loss: 0.0005081848939880729 | Test loss: 2.3192  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.0002734687877818942 | Test loss: 2.7144  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.002992653287947178 | Test loss: 2.2731  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0007102545350790024 | Test loss: 2.0681  | Test acc: 0.7834\n",
      "\n",
      " Train loss: 0.0011350886197760701 | Test loss: 2.2239  | Test acc: 0.7664\n",
      "\n",
      " Train loss: 0.0011590375797823071 | Test loss: 2.7787  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0012697343481704593 | Test loss: 3.0152  | Test acc: 0.7013\n",
      "\n",
      " Train loss: 0.0015005385503172874 | Test loss: 2.9289  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0009700536611489952 | Test loss: 2.5306  | Test acc: 0.7384\n",
      "\n",
      " Train loss: 0.0013346178457140923 | Test loss: 2.2004  | Test acc: 0.7876\n",
      "\n",
      " Train loss: 0.0013929583365097642 | Test loss: 2.9696  | Test acc: 0.7667\n",
      "\n",
      " Train loss: 0.0027746660634875298 | Test loss: 2.9151  | Test acc: 0.7757\n",
      "\n",
      " Train loss: 0.00045839796075597405 | Test loss: 3.1067  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.001430754316970706 | Test loss: 3.3736  | Test acc: 0.7407\n",
      "\n",
      " Train loss: 0.00233805482275784 | Test loss: 2.9220  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.0018708507996052504 | Test loss: 2.4663  | Test acc: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0012741979444399476 | Test loss: 2.6230  | Test acc: 0.7167\n",
      "\n",
      " Train loss: 0.001877077273093164 | Test loss: 2.7324  | Test acc: 0.6962\n",
      "\n",
      " Train loss: 0.0009839435806497931 | Test loss: 2.9510  | Test acc: 0.6720\n",
      "\n",
      " Train loss: 0.002479705261066556 | Test loss: 2.6674  | Test acc: 0.6957\n",
      "\n",
      " Train loss: 0.0017308432143181562 | Test loss: 2.6683  | Test acc: 0.6985\n",
      "\n",
      " Train loss: 0.0005723732756450772 | Test loss: 2.3997  | Test acc: 0.7225\n",
      "\n",
      " Train loss: 0.00039285392267629504 | Test loss: 2.6388  | Test acc: 0.6851\n",
      "\n",
      " Train loss: 0.0014141405699774623 | Test loss: 2.4339  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0012698972132056952 | Test loss: 2.3117  | Test acc: 0.7111\n",
      "\n",
      " Train loss: 0.0007859501638449728 | Test loss: 2.0856  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.000979611068032682 | Test loss: 2.3287  | Test acc: 0.7262\n",
      "\n",
      " Train loss: 0.0006078959559090436 | Test loss: 3.0437  | Test acc: 0.6990\n",
      "\n",
      " Train loss: 0.0014449849259108305 | Test loss: 2.5408  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.00224314839579165 | Test loss: 2.5464  | Test acc: 0.7278\n",
      "\n",
      " Train loss: 0.000992307672277093 | Test loss: 2.3644  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0006998320459388196 | Test loss: 2.3039  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.0009101532632485032 | Test loss: 2.2356  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0010408031521365047 | Test loss: 2.1830  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.001136426697485149 | Test loss: 2.0710  | Test acc: 0.7590\n",
      "\n",
      " Train loss: 0.00024913009838201106 | Test loss: 1.9668  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.00010991864110110328 | Test loss: 2.0650  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0008250930695794523 | Test loss: 1.9358  | Test acc: 0.7699\n",
      "\n",
      " Train loss: 0.0010542824165895581 | Test loss: 1.8993  | Test acc: 0.7774\n",
      "\n",
      " Train loss: 0.00025042498600669205 | Test loss: 1.9935  | Test acc: 0.7708\n",
      "\n",
      " Train loss: 0.00082307995762676 | Test loss: 1.9258  | Test acc: 0.7738\n",
      "\n",
      " Train loss: 0.0009668340208008885 | Test loss: 1.8746  | Test acc: 0.7759\n",
      "\n",
      " Train loss: 0.0005873137852177024 | Test loss: 2.1703  | Test acc: 0.7451\n",
      "\n",
      " Train loss: 0.0009225543471984565 | Test loss: 2.2898  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0010012199636548758 | Test loss: 2.1223  | Test acc: 0.7434\n",
      "\n",
      " Train loss: 0.0008152498048730195 | Test loss: 2.1876  | Test acc: 0.7517\n",
      "\n",
      " Train loss: 0.0006594727747142315 | Test loss: 2.9064  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0011819247156381607 | Test loss: 2.8779  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.0007948543643578887 | Test loss: 2.3043  | Test acc: 0.7418\n",
      "\n",
      " Train loss: 0.0007194608333520591 | Test loss: 1.8516  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.0003811660862993449 | Test loss: 2.0192  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.0010777033166959882 | Test loss: 2.3019  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.00039447713061235845 | Test loss: 2.2880  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0009474997059442103 | Test loss: 1.9715  | Test acc: 0.7359\n",
      "\n",
      " Train loss: 0.0009552064002491534 | Test loss: 2.0665  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0010544975521042943 | Test loss: 2.4823  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0009633691515773535 | Test loss: 2.7873  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.0010773757239803672 | Test loss: 2.3841  | Test acc: 0.7358\n",
      "\n",
      " Train loss: 0.0011981666320934892 | Test loss: 1.7784  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0007421745685860515 | Test loss: 1.7975  | Test acc: 0.7648\n",
      "\n",
      " Train loss: 0.0007673062500543892 | Test loss: 1.8040  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.0013010762631893158 | Test loss: 1.7912  | Test acc: 0.7768\n",
      "\n",
      " Train loss: 0.00038878608029335737 | Test loss: 2.0716  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.000313925149384886 | Test loss: 2.7488  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0013739983551204205 | Test loss: 2.4157  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.001945398049429059 | Test loss: 2.2373  | Test acc: 0.7701\n",
      "\n",
      " Train loss: 0.0017967498861253262 | Test loss: 2.3417  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0014189076609909534 | Test loss: 2.1474  | Test acc: 0.7632\n",
      "\n",
      " Train loss: 0.00043912255205214024 | Test loss: 1.9956  | Test acc: 0.7651\n",
      "\n",
      " Train loss: 0.0004707010230049491 | Test loss: 2.0581  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.0016394004924222827 | Test loss: 2.0163  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0003459009458310902 | Test loss: 2.0517  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.0011097604874521494 | Test loss: 2.1101  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0007189157768152654 | Test loss: 2.2429  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.0003560636832844466 | Test loss: 2.4234  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.0002466576115693897 | Test loss: 2.6235  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.002309206873178482 | Test loss: 2.1618  | Test acc: 0.7519\n",
      "\n",
      " Train loss: 0.0010418437886983156 | Test loss: 2.0289  | Test acc: 0.7679\n",
      "\n",
      " Train loss: 0.00021638038742821664 | Test loss: 2.2951  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0012330971658229828 | Test loss: 2.6890  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0009493736433796585 | Test loss: 2.7837  | Test acc: 0.7051\n",
      "\n",
      " Train loss: 0.0014877842040732503 | Test loss: 2.5734  | Test acc: 0.7098\n",
      "\n",
      " Train loss: 0.0008741994388401508 | Test loss: 2.5621  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.002177971415221691 | Test loss: 2.9495  | Test acc: 0.6620\n",
      "\n",
      " Train loss: 0.0021482103038579226 | Test loss: 2.2563  | Test acc: 0.7170\n",
      "\n",
      " Train loss: 0.0013367891078814864 | Test loss: 1.4760  | Test acc: 0.7828\n",
      "\n",
      " Train loss: 0.0007539114449173212 | Test loss: 1.9252  | Test acc: 0.7514\n",
      "\n",
      " Train loss: 0.000878726365044713 | Test loss: 2.1116  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.0021218189503997564 | Test loss: 2.1088  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.0011668134247884154 | Test loss: 2.1173  | Test acc: 0.7091\n",
      "\n",
      " Train loss: 0.0010689134942367673 | Test loss: 1.7865  | Test acc: 0.7515\n",
      "\n",
      " Train loss: 0.0008538836264051497 | Test loss: 1.9363  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.0009432531078346074 | Test loss: 2.2138  | Test acc: 0.6994\n",
      "\n",
      " Train loss: 0.0010759909637272358 | Test loss: 2.6231  | Test acc: 0.6625\n",
      "\n",
      " Train loss: 0.0004980915109626949 | Test loss: 2.7953  | Test acc: 0.6459\n",
      "\n",
      " Train loss: 0.00047224044101312757 | Test loss: 1.9924  | Test acc: 0.7144\n",
      "\n",
      " Train loss: 0.0017040930688381195 | Test loss: 2.1591  | Test acc: 0.7115\n",
      "\n",
      " Train loss: 0.0008292266866192222 | Test loss: 3.3224  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.0017345231026411057 | Test loss: 4.0637  | Test acc: 0.6921\n",
      "\n",
      " Train loss: 0.001792068942449987 | Test loss: 4.3044  | Test acc: 0.6611\n",
      "\n",
      " Train loss: 0.003243087325245142 | Test loss: 3.4130  | Test acc: 0.6479\n",
      "\n",
      " Train loss: 0.003484058193862438 | Test loss: 2.0799  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.001375113264657557 | Test loss: 2.5535  | Test acc: 0.6806\n",
      "\n",
      " Train loss: 0.0016607488505542278 | Test loss: 2.2947  | Test acc: 0.6969\n",
      "\n",
      " Train loss: 0.0008782761287875473 | Test loss: 2.8631  | Test acc: 0.6679\n",
      "\n",
      " Train loss: 0.0007238456164486706 | Test loss: 3.5483  | Test acc: 0.6543\n",
      "\n",
      " Train loss: 0.0024154018610715866 | Test loss: 3.0371  | Test acc: 0.6966\n",
      "\n",
      " Train loss: 0.0015437420224770904 | Test loss: 2.2267  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.0009273456525988877 | Test loss: 3.2355  | Test acc: 0.7074\n",
      "\n",
      " Train loss: 0.0015127534279599786 | Test loss: 4.7002  | Test acc: 0.6778\n",
      "\n",
      " Train loss: 0.0025589263532310724 | Test loss: 4.9847  | Test acc: 0.6727\n",
      "\n",
      " Train loss: 0.0026945124845951796 | Test loss: 3.7361  | Test acc: 0.6943\n",
      "\n",
      " Train loss: 0.0024161727633327246 | Test loss: 3.2791  | Test acc: 0.7068\n",
      "\n",
      " Train loss: 0.00169746286701411 | Test loss: 2.9533  | Test acc: 0.7272\n",
      "\n",
      " Train loss: 0.0016721012070775032 | Test loss: 2.4519  | Test acc: 0.7521\n",
      "\n",
      " Train loss: 0.0014261649921536446 | Test loss: 2.3742  | Test acc: 0.7484\n",
      "\n",
      " Train loss: 0.0017091481713578105 | Test loss: 2.8488  | Test acc: 0.7235\n",
      "\n",
      " Train loss: 0.0003415924438741058 | Test loss: 3.2630  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.0007795155397616327 | Test loss: 3.2493  | Test acc: 0.7024\n",
      "\n",
      " Train loss: 0.002253997139632702 | Test loss: 2.7152  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0013443583156913519 | Test loss: 2.6683  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.001786794513463974 | Test loss: 2.8394  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0014388487907126546 | Test loss: 3.1243  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0011128652840852737 | Test loss: 3.2542  | Test acc: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0008430156158283353 | Test loss: 3.1413  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0013695561792701483 | Test loss: 3.1540  | Test acc: 0.7348\n",
      "\n",
      " Train loss: 0.0012934213737025857 | Test loss: 3.6217  | Test acc: 0.6989\n",
      "\n",
      " Train loss: 0.0018797334050759673 | Test loss: 3.1401  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.002453478053212166 | Test loss: 2.3405  | Test acc: 0.7654\n",
      "\n",
      " Train loss: 0.0010731038637459278 | Test loss: 1.9929  | Test acc: 0.7829\n",
      "\n",
      " Train loss: 0.0003203705418854952 | Test loss: 2.0999  | Test acc: 0.7758\n",
      "\n",
      " Train loss: 0.0014904725831001997 | Test loss: 3.1934  | Test acc: 0.7192\n",
      "\n",
      " Train loss: 0.0003955495194531977 | Test loss: 4.9291  | Test acc: 0.6666\n",
      "\n",
      " Train loss: 0.0015589249087497592 | Test loss: 5.1100  | Test acc: 0.6846\n",
      "\n",
      " Train loss: 0.0021845586597919464 | Test loss: 3.2249  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.0024566343054175377 | Test loss: 3.5400  | Test acc: 0.6811\n",
      "\n",
      " Train loss: 0.0013639847747981548 | Test loss: 3.6642  | Test acc: 0.6746\n",
      "\n",
      " Train loss: 0.0015506789786741138 | Test loss: 3.0875  | Test acc: 0.6960\n",
      "\n",
      " Train loss: 0.0011276513105258346 | Test loss: 4.2146  | Test acc: 0.6665\n",
      "\n",
      " Train loss: 0.0016042323550209403 | Test loss: 4.6403  | Test acc: 0.6642\n",
      "\n",
      " Train loss: 0.002173005137592554 | Test loss: 4.1765  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.0036086735781282187 | Test loss: 3.9972  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.004155098460614681 | Test loss: 3.3691  | Test acc: 0.7058\n",
      "\n",
      " Train loss: 0.0015344986459240317 | Test loss: 2.2939  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.0002216310822404921 | Test loss: 3.7299  | Test acc: 0.7156\n",
      "\n",
      " Train loss: 0.0022121153306216 | Test loss: 4.1633  | Test acc: 0.7190\n",
      "\n",
      " Train loss: 0.0009790639160200953 | Test loss: 4.7996  | Test acc: 0.6832\n",
      "\n",
      " Train loss: 0.0023400136269629 | Test loss: 4.7065  | Test acc: 0.6277\n",
      "\n",
      " Train loss: 0.0018580491887405515 | Test loss: 2.9734  | Test acc: 0.6926\n",
      "\n",
      " Train loss: 0.0016550718573853374 | Test loss: 2.6414  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0015304925618693233 | Test loss: 3.9223  | Test acc: 0.6376\n",
      "\n",
      " Train loss: 0.0023615132085978985 | Test loss: 2.9548  | Test acc: 0.7014\n",
      "\n",
      " Train loss: 0.0014886369463056326 | Test loss: 2.3926  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.0008278488530777395 | Test loss: 2.9820  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.001775696873664856 | Test loss: 2.5358  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0011839274084195495 | Test loss: 2.6749  | Test acc: 0.7483\n",
      "\n",
      " Train loss: 0.0008032139739952981 | Test loss: 3.0534  | Test acc: 0.7196\n",
      "\n",
      " Train loss: 0.0014981887070462108 | Test loss: 2.4925  | Test acc: 0.7504\n",
      "\n",
      " Train loss: 0.0013790883822366595 | Test loss: 3.7825  | Test acc: 0.6816\n",
      "\n",
      " Train loss: 0.001587673556059599 | Test loss: 2.9633  | Test acc: 0.7294\n",
      "\n",
      " Train loss: 0.001052013598382473 | Test loss: 2.3599  | Test acc: 0.7813\n",
      "\n",
      " Train loss: 0.001263410784304142 | Test loss: 2.4836  | Test acc: 0.7836\n",
      "\n",
      " Train loss: 0.0021108880173414946 | Test loss: 2.5575  | Test acc: 0.7849\n",
      "\n",
      " Train loss: 0.0005462001427076757 | Test loss: 2.8568  | Test acc: 0.7683\n",
      "\n",
      " Train loss: 0.0035136085934937 | Test loss: 2.6438  | Test acc: 0.7719\n",
      "\n",
      " Train loss: 0.0011343950172886252 | Test loss: 2.5103  | Test acc: 0.7758\n",
      "\n",
      " Train loss: 0.0019383233739063144 | Test loss: 2.3956  | Test acc: 0.7771\n",
      "\n",
      " Train loss: 0.0008885040879249573 | Test loss: 2.4427  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.001998871099203825 | Test loss: 2.5815  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.003538826946169138 | Test loss: 2.9659  | Test acc: 0.7255\n",
      "\n",
      " Train loss: 0.002492267405614257 | Test loss: 3.0205  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0029424389358609915 | Test loss: 2.3956  | Test acc: 0.7588\n",
      "\n",
      " Train loss: 0.001050997874699533 | Test loss: 2.6277  | Test acc: 0.7638\n",
      "\n",
      " Train loss: 0.0009159485343843699 | Test loss: 2.9135  | Test acc: 0.7501\n",
      "\n",
      " Train loss: 0.001414791913703084 | Test loss: 2.9391  | Test acc: 0.7318\n",
      "\n",
      " Train loss: 0.0016303792363032699 | Test loss: 2.7474  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0011236860882490873 | Test loss: 2.5389  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.0008025904535315931 | Test loss: 2.2243  | Test acc: 0.7307\n",
      "\n",
      " Train loss: 0.00042691529961302876 | Test loss: 1.8459  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0006248073186725378 | Test loss: 1.7945  | Test acc: 0.7869\n",
      "\n",
      " Train loss: 0.0009788954630494118 | Test loss: 2.2687  | Test acc: 0.7726\n",
      "\n",
      " Train loss: 0.0016200493555516005 | Test loss: 2.5759  | Test acc: 0.7629\n",
      "\n",
      " Train loss: 0.0012449627975001931 | Test loss: 2.8292  | Test acc: 0.7528\n",
      "\n",
      " Train loss: 0.001243210630491376 | Test loss: 2.9412  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.0005393294850364327 | Test loss: 2.8204  | Test acc: 0.7163\n",
      "\n",
      " Train loss: 0.001254185102880001 | Test loss: 2.5553  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0010347660863772035 | Test loss: 2.6667  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0016125119291245937 | Test loss: 3.5173  | Test acc: 0.6807\n",
      "\n",
      " Train loss: 0.001872590626589954 | Test loss: 2.9833  | Test acc: 0.7250\n",
      "\n",
      " Train loss: 0.001751632196828723 | Test loss: 2.7569  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.0008331199642270803 | Test loss: 2.4873  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.0009981341427192092 | Test loss: 2.3461  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.0036830606404691935 | Test loss: 2.3514  | Test acc: 0.7352\n",
      "\n",
      " Train loss: 0.0010096270125359297 | Test loss: 3.2994  | Test acc: 0.6694\n",
      "\n",
      " Train loss: 0.0023472271859645844 | Test loss: 4.5208  | Test acc: 0.6079\n",
      "\n",
      " Train loss: 0.002460487186908722 | Test loss: 3.9536  | Test acc: 0.6361\n",
      "\n",
      " Train loss: 0.001324174110777676 | Test loss: 3.3727  | Test acc: 0.6798\n",
      "\n",
      " Train loss: 0.0008647228241898119 | Test loss: 3.4432  | Test acc: 0.6790\n",
      "\n",
      " Train loss: 0.002334705786779523 | Test loss: 2.6780  | Test acc: 0.7088\n",
      "\n",
      " Train loss: 0.0011095026275143027 | Test loss: 2.8468  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.001888134516775608 | Test loss: 3.0636  | Test acc: 0.7033\n",
      "\n",
      " Train loss: 0.0012778888922184706 | Test loss: 3.9485  | Test acc: 0.7075\n",
      "\n",
      " Train loss: 0.0035910506267100573 | Test loss: 4.2743  | Test acc: 0.7135\n",
      "\n",
      " Train loss: 0.0032150051556527615 | Test loss: 4.7359  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.00265201972797513 | Test loss: 3.8547  | Test acc: 0.6853\n",
      "\n",
      " Train loss: 0.002551866928115487 | Test loss: 3.1472  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.001963180024176836 | Test loss: 3.8723  | Test acc: 0.7285\n",
      "\n",
      " Train loss: 0.0019284423906356096 | Test loss: 3.4527  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0014496705261990428 | Test loss: 3.2818  | Test acc: 0.7623\n",
      "\n",
      " Train loss: 0.0013985877158120275 | Test loss: 3.0710  | Test acc: 0.7561\n",
      "\n",
      " Train loss: 0.002726313890889287 | Test loss: 2.5606  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.000631127564702183 | Test loss: 2.7302  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.0023719926830381155 | Test loss: 3.1500  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.0015043682651594281 | Test loss: 2.9707  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.0009270488517358899 | Test loss: 3.2099  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.001230658614076674 | Test loss: 3.7185  | Test acc: 0.7209\n",
      "\n",
      " Train loss: 0.0019582149107009172 | Test loss: 3.6352  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.002654023002833128 | Test loss: 2.5492  | Test acc: 0.7633\n",
      "\n",
      " Train loss: 0.0005068644532002509 | Test loss: 2.3134  | Test acc: 0.7580\n",
      "\n",
      " Train loss: 0.0010554998880252242 | Test loss: 2.4719  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0010830037062987685 | Test loss: 3.0351  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0012469352222979069 | Test loss: 3.4303  | Test acc: 0.6901\n",
      "\n",
      " Train loss: 0.0023307804949581623 | Test loss: 2.6874  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.0012469751527532935 | Test loss: 2.0569  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.0007053922163322568 | Test loss: 2.2494  | Test acc: 0.7531\n",
      "\n",
      " Train loss: 0.003014086978510022 | Test loss: 2.4379  | Test acc: 0.7363\n",
      "\n",
      " Train loss: 0.0009114760323427618 | Test loss: 2.0517  | Test acc: 0.7694\n",
      "\n",
      " Train loss: 0.0004291707300581038 | Test loss: 2.2549  | Test acc: 0.7563\n",
      "\n",
      " Train loss: 0.001110080978833139 | Test loss: 2.3634  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.0011427568970248103 | Test loss: 3.1627  | Test acc: 0.6742\n",
      "\n",
      " Train loss: 0.0016411797842010856 | Test loss: 3.1094  | Test acc: 0.6651\n",
      "\n",
      " Train loss: 0.0010043628280982375 | Test loss: 2.5181  | Test acc: 0.7017\n",
      "\n",
      " Train loss: 0.002394517185166478 | Test loss: 2.3707  | Test acc: 0.7341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0005786540568806231 | Test loss: 2.6170  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.0017131480854004622 | Test loss: 2.6745  | Test acc: 0.6984\n",
      "\n",
      " Train loss: 0.0008375710458494723 | Test loss: 3.5183  | Test acc: 0.6643\n",
      "\n",
      " Train loss: 0.0005508155445568264 | Test loss: 4.1254  | Test acc: 0.6567\n",
      "\n",
      " Train loss: 0.00395340658724308 | Test loss: 3.0208  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.0014845089754089713 | Test loss: 4.1223  | Test acc: 0.6732\n",
      "\n",
      " Train loss: 0.002348880283534527 | Test loss: 4.7631  | Test acc: 0.6408\n",
      "\n",
      " Train loss: 0.003606653306633234 | Test loss: 2.7105  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.0015426528407260776 | Test loss: 4.0645  | Test acc: 0.6660\n",
      "\n",
      " Train loss: 0.0017607372719794512 | Test loss: 5.0927  | Test acc: 0.6741\n",
      "\n",
      " Train loss: 0.0009158749016933143 | Test loss: 9.3918  | Test acc: 0.5705\n",
      "\n",
      " Train loss: 0.0029345436487346888 | Test loss: 9.1584  | Test acc: 0.6018\n",
      "\n",
      " Train loss: 0.005569829139858484 | Test loss: 3.9226  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.0024322255048900843 | Test loss: 2.4612  | Test acc: 0.7567\n",
      "\n",
      " Train loss: 0.0007699748384766281 | Test loss: 4.9703  | Test acc: 0.6786\n",
      "\n",
      " Train loss: 0.0024982208851724863 | Test loss: 6.2515  | Test acc: 0.6426\n",
      "\n",
      " Train loss: 0.002172788605093956 | Test loss: 4.5258  | Test acc: 0.6936\n",
      "\n",
      " Train loss: 0.0022957664914429188 | Test loss: 3.1404  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.001790122245438397 | Test loss: 3.2072  | Test acc: 0.6908\n",
      "\n",
      " Train loss: 0.0018429907504469156 | Test loss: 4.4612  | Test acc: 0.6181\n",
      "\n",
      " Train loss: 0.0023701998870819807 | Test loss: 4.7630  | Test acc: 0.6195\n",
      "\n",
      " Train loss: 0.0024586906656622887 | Test loss: 4.0154  | Test acc: 0.6701\n",
      "\n",
      " Train loss: 0.0017276143189519644 | Test loss: 3.4383  | Test acc: 0.7194\n",
      "\n",
      " Train loss: 0.0008481954573653638 | Test loss: 3.3121  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0017976517556235194 | Test loss: 3.6984  | Test acc: 0.7213\n",
      "\n",
      " Train loss: 0.0037499391473829746 | Test loss: 4.0626  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0025013380218297243 | Test loss: 4.1696  | Test acc: 0.6704\n",
      "\n",
      " Train loss: 0.00338148046284914 | Test loss: 3.6064  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.00156686722766608 | Test loss: 3.3411  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.0016239741817116737 | Test loss: 5.3334  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.0015613698633387685 | Test loss: 6.2704  | Test acc: 0.6744\n",
      "\n",
      " Train loss: 0.00555687490850687 | Test loss: 4.3711  | Test acc: 0.7260\n",
      "\n",
      " Train loss: 0.002295184414833784 | Test loss: 2.9069  | Test acc: 0.7618\n",
      "\n",
      " Train loss: 0.0021869849879294634 | Test loss: 2.5571  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0021376253571361303 | Test loss: 2.6520  | Test acc: 0.7585\n",
      "\n",
      " Train loss: 0.0022781617008149624 | Test loss: 2.8647  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.001061576302163303 | Test loss: 2.7738  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0006772205815650523 | Test loss: 2.8101  | Test acc: 0.7464\n",
      "\n",
      " Train loss: 0.0013472355203703046 | Test loss: 2.9637  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.0007878976175561547 | Test loss: 3.4719  | Test acc: 0.7304\n",
      "\n",
      " Train loss: 0.0019800574518740177 | Test loss: 4.2103  | Test acc: 0.6746\n",
      "\n",
      " Train loss: 0.002474322682246566 | Test loss: 3.1747  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.0023217294365167618 | Test loss: 2.9208  | Test acc: 0.7174\n",
      "\n",
      " Train loss: 0.0005399083020165563 | Test loss: 3.3138  | Test acc: 0.6866\n",
      "\n",
      " Train loss: 0.001019967719912529 | Test loss: 3.7289  | Test acc: 0.6683\n",
      "\n",
      " Train loss: 0.0013867159141227603 | Test loss: 3.8224  | Test acc: 0.6849\n",
      "\n",
      " Train loss: 0.0006737610092386603 | Test loss: 4.2915  | Test acc: 0.6872\n",
      "\n",
      " Train loss: 0.0019867285154759884 | Test loss: 3.4132  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.0014457663055509329 | Test loss: 2.6802  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0008144894381985068 | Test loss: 3.7467  | Test acc: 0.6871\n",
      "\n",
      " Train loss: 0.003288072533905506 | Test loss: 3.3966  | Test acc: 0.7067\n",
      "\n",
      " Train loss: 0.002324651926755905 | Test loss: 2.6571  | Test acc: 0.7614\n",
      "\n",
      " Train loss: 0.001662096823565662 | Test loss: 2.8690  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0005910343024879694 | Test loss: 3.1074  | Test acc: 0.7564\n",
      "\n",
      " Train loss: 0.0009928065119311213 | Test loss: 2.8636  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0004555539635475725 | Test loss: 2.7010  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.001594178145751357 | Test loss: 2.4468  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0015723721589893103 | Test loss: 2.5653  | Test acc: 0.7399\n",
      "\n",
      " Train loss: 0.0013839318417012691 | Test loss: 2.4857  | Test acc: 0.7465\n",
      "\n",
      " Train loss: 0.0013961667427793145 | Test loss: 2.6500  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0005511220078915358 | Test loss: 2.7994  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.0017959148390218616 | Test loss: 2.9264  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0008229712839238346 | Test loss: 2.8116  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.0023286687210202217 | Test loss: 2.6143  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.0010072010336443782 | Test loss: 3.1664  | Test acc: 0.7114\n",
      "\n",
      " Train loss: 0.0016156373312696815 | Test loss: 4.3832  | Test acc: 0.6649\n",
      "\n",
      " Train loss: 0.0021699562203139067 | Test loss: 4.6889  | Test acc: 0.6501\n",
      "\n",
      " Train loss: 0.003612647531554103 | Test loss: 2.7120  | Test acc: 0.7289\n",
      "\n",
      " Train loss: 0.0004950470174662769 | Test loss: 2.6894  | Test acc: 0.7473\n",
      "\n",
      " Train loss: 0.0016198975499719381 | Test loss: 3.5904  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0015907924389466643 | Test loss: 3.1201  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0005888675223104656 | Test loss: 2.7157  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.001308673294261098 | Test loss: 2.3724  | Test acc: 0.7574\n",
      "\n",
      " Train loss: 0.0007654732908122241 | Test loss: 2.2969  | Test acc: 0.7566\n",
      "\n",
      " Train loss: 0.0008130688220262527 | Test loss: 2.3767  | Test acc: 0.7515\n",
      "\n",
      " Train loss: 0.0015037916600704193 | Test loss: 2.4923  | Test acc: 0.7493\n",
      "\n",
      " Train loss: 0.00011071412882301956 | Test loss: 2.7520  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.0020018552895635366 | Test loss: 3.0258  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.001003264100290835 | Test loss: 3.5988  | Test acc: 0.6873\n",
      "\n",
      " Train loss: 0.0006826259195804596 | Test loss: 4.1426  | Test acc: 0.6769\n",
      "\n",
      " Train loss: 0.003296793205663562 | Test loss: 3.3902  | Test acc: 0.6999\n",
      "\n",
      " Train loss: 0.001279507647268474 | Test loss: 2.7934  | Test acc: 0.7230\n",
      "\n",
      " Train loss: 0.0010908051626756787 | Test loss: 2.7459  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0008796167094260454 | Test loss: 3.2725  | Test acc: 0.7002\n",
      "\n",
      " Train loss: 0.0007140806410461664 | Test loss: 3.2595  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.0016818268923088908 | Test loss: 2.6181  | Test acc: 0.7442\n",
      "\n",
      " Train loss: 0.0009900466538965702 | Test loss: 2.6676  | Test acc: 0.7418\n",
      "\n",
      " Train loss: 0.0016963413218036294 | Test loss: 2.5320  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.0018754579359665513 | Test loss: 2.4075  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.002352176234126091 | Test loss: 2.2834  | Test acc: 0.7734\n",
      "\n",
      " Train loss: 0.0011233261320739985 | Test loss: 2.3738  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.0005182686727494001 | Test loss: 2.2912  | Test acc: 0.7694\n",
      "\n",
      " Train loss: 0.0006805745651945472 | Test loss: 2.2241  | Test acc: 0.7687\n",
      "\n",
      " Train loss: 0.0018229956040158868 | Test loss: 2.3287  | Test acc: 0.7518\n",
      "\n",
      " Train loss: 0.001111865509301424 | Test loss: 2.3884  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.00110732764005661 | Test loss: 2.2783  | Test acc: 0.7441\n",
      "\n",
      " Train loss: 0.0015419755363836884 | Test loss: 1.9450  | Test acc: 0.7835\n",
      "\n",
      " Train loss: 0.0005275607691146433 | Test loss: 1.8900  | Test acc: 0.7879\n",
      "\n",
      " Train loss: 0.0004892109427601099 | Test loss: 2.0060  | Test acc: 0.7662\n",
      "\n",
      " Train loss: 0.0005034218193031847 | Test loss: 3.0543  | Test acc: 0.6918\n",
      "\n",
      " Train loss: 0.0018770270980894566 | Test loss: 2.6566  | Test acc: 0.7090\n",
      "\n",
      " Train loss: 0.001554112765006721 | Test loss: 2.5140  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.0016765299951657653 | Test loss: 2.3857  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0004231393104419112 | Test loss: 2.1908  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.000245363189605996 | Test loss: 2.1793  | Test acc: 0.7521\n",
      "\n",
      " Train loss: 0.001234338036738336 | Test loss: 2.4604  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.0009767101146280766 | Test loss: 2.7229  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0008012412581592798 | Test loss: 3.2851  | Test acc: 0.6993\n",
      "\n",
      " Train loss: 0.0022465474903583527 | Test loss: 3.7161  | Test acc: 0.6671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0018199387704953551 | Test loss: 4.0638  | Test acc: 0.6439\n",
      "Looked at 51200/ 60000 samples\n",
      "\n",
      " Train loss: 0.002463491400703788 | Test loss: 3.4075  | Test acc: 0.6708\n",
      "\n",
      " Train loss: 0.0024855260271579027 | Test loss: 2.5404  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.0010622283443808556 | Test loss: 2.8312  | Test acc: 0.6989\n",
      "\n",
      " Train loss: 0.0027565881609916687 | Test loss: 2.6843  | Test acc: 0.6871\n",
      "\n",
      " Train loss: 0.0022126531694084406 | Test loss: 2.1416  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0016646282747387886 | Test loss: 2.4621  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0020046918652951717 | Test loss: 2.4464  | Test acc: 0.7375\n",
      "\n",
      " Train loss: 0.0012473142705857754 | Test loss: 2.2868  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.001035683206282556 | Test loss: 2.9037  | Test acc: 0.7111\n",
      "\n",
      " Train loss: 0.0002758375776465982 | Test loss: 4.1505  | Test acc: 0.6415\n",
      "\n",
      " Train loss: 0.0016888565151020885 | Test loss: 5.7533  | Test acc: 0.6100\n",
      "\n",
      " Train loss: 0.0034462043549865484 | Test loss: 3.7428  | Test acc: 0.6886\n",
      "\n",
      " Train loss: 0.00033517711563035846 | Test loss: 4.2888  | Test acc: 0.6984\n",
      "\n",
      " Train loss: 0.0024215029552578926 | Test loss: 5.5942  | Test acc: 0.6530\n",
      "\n",
      " Train loss: 0.0030558498110622168 | Test loss: 4.2176  | Test acc: 0.6614\n",
      "\n",
      " Train loss: 0.0013594389893114567 | Test loss: 3.1910  | Test acc: 0.6841\n",
      "\n",
      " Train loss: 0.0020724611822515726 | Test loss: 2.8888  | Test acc: 0.7075\n",
      "\n",
      " Train loss: 0.0015600017504766583 | Test loss: 2.6283  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.001097991829738021 | Test loss: 2.4035  | Test acc: 0.7567\n",
      "\n",
      " Train loss: 0.001308602630160749 | Test loss: 2.4926  | Test acc: 0.7504\n",
      "\n",
      " Train loss: 0.000575457641389221 | Test loss: 2.4769  | Test acc: 0.7594\n",
      "\n",
      " Train loss: 0.0009553217678330839 | Test loss: 2.6494  | Test acc: 0.7503\n",
      "\n",
      " Train loss: 0.0014588248450309038 | Test loss: 2.2295  | Test acc: 0.7696\n",
      "\n",
      " Train loss: 0.001193702919408679 | Test loss: 2.1198  | Test acc: 0.7715\n",
      "\n",
      " Train loss: 0.0006038678111508489 | Test loss: 2.5191  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0011371982982382178 | Test loss: 2.3764  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0007719270652160048 | Test loss: 2.5639  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.0017258613370358944 | Test loss: 2.6120  | Test acc: 0.7616\n",
      "\n",
      " Train loss: 0.0011525561567395926 | Test loss: 2.6861  | Test acc: 0.7575\n",
      "\n",
      " Train loss: 0.0005030840984545648 | Test loss: 2.8354  | Test acc: 0.7504\n",
      "\n",
      " Train loss: 0.0019049015827476978 | Test loss: 2.9264  | Test acc: 0.7307\n",
      "\n",
      " Train loss: 0.0006934231496416032 | Test loss: 2.8764  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0008108310867100954 | Test loss: 2.5753  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.0008721702033653855 | Test loss: 2.2969  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0007484956295229495 | Test loss: 2.0454  | Test acc: 0.7601\n",
      "\n",
      " Train loss: 0.0008878725930117071 | Test loss: 1.9109  | Test acc: 0.7693\n",
      "\n",
      " Train loss: 0.001195955672301352 | Test loss: 2.2977  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0010963042732328176 | Test loss: 3.2785  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0035733659751713276 | Test loss: 3.1193  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.001583425677381456 | Test loss: 2.7310  | Test acc: 0.7169\n",
      "\n",
      " Train loss: 0.0019629746675491333 | Test loss: 2.9352  | Test acc: 0.6831\n",
      "\n",
      " Train loss: 0.0016726949252188206 | Test loss: 2.7571  | Test acc: 0.6938\n",
      "\n",
      " Train loss: 0.0015982703771442175 | Test loss: 2.6468  | Test acc: 0.6898\n",
      "\n",
      " Train loss: 0.001975196646526456 | Test loss: 2.0814  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0007666127639822662 | Test loss: 1.7707  | Test acc: 0.7400\n",
      "\n",
      " Train loss: 0.0006260217051021755 | Test loss: 1.7466  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.001558044576086104 | Test loss: 1.7263  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.0005045771831646562 | Test loss: 2.3244  | Test acc: 0.6798\n",
      "\n",
      " Train loss: 0.0008693995187059045 | Test loss: 3.2815  | Test acc: 0.6157\n",
      "\n",
      " Train loss: 0.0025771509390324354 | Test loss: 1.6712  | Test acc: 0.7624\n",
      "\n",
      " Train loss: 0.0001781298778951168 | Test loss: 2.0386  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.0019618591759353876 | Test loss: 2.3295  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0010108496062457561 | Test loss: 2.2838  | Test acc: 0.7108\n",
      "\n",
      " Train loss: 0.0016266433522105217 | Test loss: 2.3144  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.0007046355749480426 | Test loss: 2.3004  | Test acc: 0.7044\n",
      "\n",
      " Train loss: 0.001178019680082798 | Test loss: 2.0717  | Test acc: 0.7240\n",
      "\n",
      " Train loss: 0.0011521456763148308 | Test loss: 1.7311  | Test acc: 0.7732\n",
      "\n",
      " Train loss: 0.0007260160055011511 | Test loss: 1.6923  | Test acc: 0.7846\n",
      "\n",
      " Train loss: 0.00012095704005332664 | Test loss: 1.8904  | Test acc: 0.7693\n",
      "\n",
      " Train loss: 0.0019241340924054384 | Test loss: 1.7739  | Test acc: 0.7770\n",
      "\n",
      " Train loss: 0.0009051290689967573 | Test loss: 1.7873  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0010533519089221954 | Test loss: 2.0402  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0005963546573184431 | Test loss: 2.4463  | Test acc: 0.6902\n",
      "\n",
      " Train loss: 0.0039581796154379845 | Test loss: 2.2837  | Test acc: 0.6933\n",
      "\n",
      " Train loss: 0.0005800397484563291 | Test loss: 2.3337  | Test acc: 0.6905\n",
      "\n",
      " Train loss: 0.001912715146318078 | Test loss: 2.0756  | Test acc: 0.7047\n",
      "\n",
      " Train loss: 0.0019656792283058167 | Test loss: 2.1247  | Test acc: 0.6974\n",
      "\n",
      " Train loss: 0.0014992090873420238 | Test loss: 1.9638  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0011165826581418514 | Test loss: 1.6973  | Test acc: 0.7528\n",
      "\n",
      " Train loss: 0.001541921985335648 | Test loss: 1.5864  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.0006820623530074954 | Test loss: 1.7805  | Test acc: 0.7435\n",
      "\n",
      " Train loss: 0.0008020980749279261 | Test loss: 2.1030  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0009195085149258375 | Test loss: 2.0554  | Test acc: 0.7016\n",
      "\n",
      " Train loss: 0.0009583333740010858 | Test loss: 2.2469  | Test acc: 0.6822\n",
      "\n",
      " Train loss: 0.0010623931884765625 | Test loss: 1.9039  | Test acc: 0.7204\n",
      "\n",
      " Train loss: 0.0019721360877156258 | Test loss: 2.3828  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.0006255414336919785 | Test loss: 2.5400  | Test acc: 0.6776\n",
      "\n",
      " Train loss: 0.0008148510241881013 | Test loss: 2.6119  | Test acc: 0.6809\n",
      "\n",
      " Train loss: 0.0006738354568369687 | Test loss: 2.6136  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.0015012819785624743 | Test loss: 2.2291  | Test acc: 0.7230\n",
      "\n",
      " Train loss: 0.0016170308226719499 | Test loss: 1.9278  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0004629174363799393 | Test loss: 2.3282  | Test acc: 0.6756\n",
      "\n",
      " Train loss: 0.0012185771483927965 | Test loss: 1.8790  | Test acc: 0.7158\n",
      "\n",
      " Train loss: 0.0013740743743255734 | Test loss: 2.0817  | Test acc: 0.7203\n",
      "\n",
      " Train loss: 0.0008795993053354323 | Test loss: 2.3381  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0007680518901906908 | Test loss: 2.0064  | Test acc: 0.7690\n",
      "\n",
      " Train loss: 0.0011748449178412557 | Test loss: 1.8538  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.0017493353225290775 | Test loss: 1.7514  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.001220122561790049 | Test loss: 1.7213  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.0018860765267163515 | Test loss: 2.2125  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.001781309605576098 | Test loss: 2.6223  | Test acc: 0.6785\n",
      "\n",
      " Train loss: 0.0013756552943959832 | Test loss: 2.5470  | Test acc: 0.6789\n",
      "\n",
      " Train loss: 0.001545678824186325 | Test loss: 1.8823  | Test acc: 0.7171\n",
      "\n",
      " Train loss: 0.0007218488026410341 | Test loss: 1.8337  | Test acc: 0.7510\n",
      "\n",
      " Train loss: 0.0008609065553173423 | Test loss: 2.1936  | Test acc: 0.7341\n",
      "\n",
      " Train loss: 0.0008499617106281221 | Test loss: 2.2477  | Test acc: 0.7235\n",
      "\n",
      " Train loss: 0.0006928786169737577 | Test loss: 2.1305  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.0011480055982246995 | Test loss: 2.4502  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.0005576361436396837 | Test loss: 2.6061  | Test acc: 0.6768\n",
      "\n",
      " Train loss: 0.002624999964609742 | Test loss: 1.9865  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0013753791572526097 | Test loss: 1.9945  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.0011053081834688783 | Test loss: 2.5901  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.0019673474598675966 | Test loss: 2.8367  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0018533699912950397 | Test loss: 2.1260  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.0016349746147170663 | Test loss: 2.0016  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.00120435596909374 | Test loss: 2.0092  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.0008255771826952696 | Test loss: 2.0405  | Test acc: 0.7516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0011328620603308082 | Test loss: 1.8473  | Test acc: 0.7686\n",
      "\n",
      " Train loss: 0.00030620890902355313 | Test loss: 2.0403  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.0007835989235900342 | Test loss: 2.4324  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0005428008153103292 | Test loss: 2.2774  | Test acc: 0.7514\n",
      "\n",
      " Train loss: 0.001199132762849331 | Test loss: 2.0940  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0011511121410876513 | Test loss: 2.0996  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0004272174555808306 | Test loss: 2.0845  | Test acc: 0.7469\n",
      "\n",
      " Train loss: 0.0017612922238186002 | Test loss: 2.1183  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.0015672940062358975 | Test loss: 2.6807  | Test acc: 0.6940\n",
      "\n",
      " Train loss: 0.001281381817534566 | Test loss: 2.8792  | Test acc: 0.6812\n",
      "\n",
      " Train loss: 0.0023708625230938196 | Test loss: 1.9440  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0007876028539612889 | Test loss: 1.9339  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.00033057431573979557 | Test loss: 2.6672  | Test acc: 0.6724\n",
      "\n",
      " Train loss: 0.0006843143492005765 | Test loss: 2.5501  | Test acc: 0.6838\n",
      "\n",
      " Train loss: 0.0017567587783560157 | Test loss: 2.0241  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.00044977664947509766 | Test loss: 1.9543  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.000660474004689604 | Test loss: 1.8777  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0011260039173066616 | Test loss: 1.8179  | Test acc: 0.7461\n",
      "\n",
      " Train loss: 0.0007807278307154775 | Test loss: 1.9974  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.0006571006961166859 | Test loss: 2.1211  | Test acc: 0.7231\n",
      "\n",
      " Train loss: 0.0017112105851992965 | Test loss: 1.7825  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.0005046874866820872 | Test loss: 1.7060  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.000544339360203594 | Test loss: 1.8245  | Test acc: 0.7653\n",
      "\n",
      " Train loss: 0.0002895314246416092 | Test loss: 2.1097  | Test acc: 0.7495\n",
      "\n",
      " Train loss: 0.0009463909082114697 | Test loss: 2.1959  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.00037049248930998147 | Test loss: 2.1930  | Test acc: 0.7584\n",
      "\n",
      " Train loss: 0.0008740390767343342 | Test loss: 2.0442  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.0010227293241769075 | Test loss: 1.6361  | Test acc: 0.7854\n",
      "\n",
      " Train loss: 0.0006732469191774726 | Test loss: 1.4963  | Test acc: 0.7887\n",
      "\n",
      " Train loss: 0.0007975043845362961 | Test loss: 1.8018  | Test acc: 0.7649\n",
      "\n",
      " Train loss: 0.0002910473267547786 | Test loss: 2.7068  | Test acc: 0.7059\n",
      "\n",
      " Train loss: 0.0018787827575579286 | Test loss: 2.8883  | Test acc: 0.6843\n",
      "\n",
      " Train loss: 0.0018848937470465899 | Test loss: 2.2251  | Test acc: 0.7179\n",
      "\n",
      " Train loss: 0.0011113042710348964 | Test loss: 1.6581  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.0006650011637248099 | Test loss: 1.6698  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.0009083825862035155 | Test loss: 1.7237  | Test acc: 0.7533\n",
      "\n",
      " Train loss: 0.0001229132612934336 | Test loss: 1.9049  | Test acc: 0.7426\n",
      "\n",
      " Train loss: 0.0009020526777021587 | Test loss: 2.0101  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.00016069602861534804 | Test loss: 2.2073  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.0014699549647048116 | Test loss: 1.9856  | Test acc: 0.7629\n",
      "\n",
      " Train loss: 0.0008080133702605963 | Test loss: 1.7183  | Test acc: 0.7720\n",
      "\n",
      " Train loss: 0.0005691627156920731 | Test loss: 1.5227  | Test acc: 0.7850\n",
      "\n",
      " Train loss: 0.0007411290425807238 | Test loss: 1.6438  | Test acc: 0.7736\n",
      "\n",
      " Train loss: 0.001665332936681807 | Test loss: 2.0593  | Test acc: 0.7423\n",
      "\n",
      " Train loss: 0.001393879996612668 | Test loss: 2.2776  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.0009034405811689794 | Test loss: 2.2470  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.0007444732473231852 | Test loss: 2.0120  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.000753609579987824 | Test loss: 2.8130  | Test acc: 0.7047\n",
      "\n",
      " Train loss: 0.002046417212113738 | Test loss: 2.2740  | Test acc: 0.7532\n",
      "\n",
      " Train loss: 0.000965978077147156 | Test loss: 1.9393  | Test acc: 0.7615\n",
      "\n",
      " Train loss: 0.000853894161991775 | Test loss: 1.9528  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0022805763874202967 | Test loss: 1.6894  | Test acc: 0.7760\n",
      "\n",
      " Train loss: 0.00025217232177965343 | Test loss: 2.0771  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.002272179815918207 | Test loss: 2.1705  | Test acc: 0.7159\n",
      "\n",
      " Train loss: 0.0009639565832912922 | Test loss: 2.4301  | Test acc: 0.7081\n",
      "\n",
      " Train loss: 0.0006911753444001079 | Test loss: 2.6057  | Test acc: 0.7015\n",
      "\n",
      " Train loss: 0.002207270823419094 | Test loss: 2.2889  | Test acc: 0.6915\n",
      "\n",
      " Train loss: 0.0009598445030860603 | Test loss: 2.6938  | Test acc: 0.6632\n",
      "\n",
      " Train loss: 0.0019107229309156537 | Test loss: 3.5784  | Test acc: 0.5799\n",
      "\n",
      " Train loss: 0.002008641604334116 | Test loss: 3.0389  | Test acc: 0.6264\n",
      "\n",
      " Train loss: 0.0019334855023771524 | Test loss: 2.3552  | Test acc: 0.6671\n",
      "\n",
      " Train loss: 0.0015118889277800918 | Test loss: 1.6120  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.0004271620709914714 | Test loss: 2.0379  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.0007374779670499265 | Test loss: 2.8743  | Test acc: 0.6800\n",
      "\n",
      " Train loss: 0.001443766406737268 | Test loss: 3.1982  | Test acc: 0.6546\n",
      "\n",
      " Train loss: 0.0013640079414471984 | Test loss: 3.2129  | Test acc: 0.6651\n",
      "\n",
      " Train loss: 0.0010869887191802263 | Test loss: 3.2436  | Test acc: 0.6744\n",
      "\n",
      " Train loss: 0.001149265794083476 | Test loss: 2.6274  | Test acc: 0.6886\n",
      "\n",
      " Train loss: 0.0020459643565118313 | Test loss: 2.1755  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.001214764080941677 | Test loss: 2.2357  | Test acc: 0.7526\n",
      "\n",
      " Train loss: 0.0005968338809907436 | Test loss: 2.3231  | Test acc: 0.7491\n",
      "\n",
      " Train loss: 0.0011139664566144347 | Test loss: 2.8431  | Test acc: 0.6975\n",
      "\n",
      " Train loss: 0.0019823710899800062 | Test loss: 2.9685  | Test acc: 0.7089\n",
      "\n",
      " Train loss: 0.001263543264940381 | Test loss: 2.2393  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0013419188326224685 | Test loss: 2.5073  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0024020224809646606 | Test loss: 2.7070  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0012650866992771626 | Test loss: 2.3922  | Test acc: 0.7205\n",
      "\n",
      " Train loss: 0.0008644115296192467 | Test loss: 2.6890  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0011513677891343832 | Test loss: 2.9361  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0028883200138807297 | Test loss: 2.9314  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.003231670940294862 | Test loss: 2.6017  | Test acc: 0.7577\n",
      "\n",
      " Train loss: 0.0019607204012572765 | Test loss: 2.0809  | Test acc: 0.7736\n",
      "\n",
      " Train loss: 0.0006905209156684577 | Test loss: 1.9635  | Test acc: 0.7724\n",
      "\n",
      " Train loss: 0.0015572126721963286 | Test loss: 2.2447  | Test acc: 0.7493\n",
      "\n",
      " Train loss: 0.001888597966171801 | Test loss: 2.2555  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.0005648203077726066 | Test loss: 2.3981  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.0009112032712437212 | Test loss: 2.6035  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0017959846882149577 | Test loss: 2.5256  | Test acc: 0.7361\n",
      "\n",
      " Train loss: 0.0008668961236253381 | Test loss: 2.2692  | Test acc: 0.7583\n",
      "\n",
      " Train loss: 0.0021346567664295435 | Test loss: 2.1034  | Test acc: 0.7614\n",
      "\n",
      " Train loss: 0.0011135980021208525 | Test loss: 2.3238  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0012090119998902082 | Test loss: 2.1577  | Test acc: 0.7422\n",
      "\n",
      " Train loss: 0.0012389327166602015 | Test loss: 2.0824  | Test acc: 0.7146\n",
      "\n",
      " Train loss: 0.0011339964112266898 | Test loss: 1.8426  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.000478622067021206 | Test loss: 2.0424  | Test acc: 0.7361\n",
      "\n",
      " Train loss: 0.0007908258703537285 | Test loss: 2.1211  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0013755867257714272 | Test loss: 1.5900  | Test acc: 0.7821\n",
      "\n",
      " Train loss: 0.0007505645044147968 | Test loss: 1.5568  | Test acc: 0.7763\n",
      "\n",
      " Train loss: 0.00023794009757693857 | Test loss: 1.7437  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.0007331150118261576 | Test loss: 2.0230  | Test acc: 0.7316\n",
      "\n",
      " Train loss: 0.0007763651083223522 | Test loss: 2.3214  | Test acc: 0.7045\n",
      "\n",
      " Train loss: 0.00067261973163113 | Test loss: 2.3642  | Test acc: 0.7072\n",
      "\n",
      " Train loss: 0.001583685982041061 | Test loss: 1.9077  | Test acc: 0.7418\n",
      "\n",
      " Train loss: 0.0015177713939920068 | Test loss: 1.5956  | Test acc: 0.7723\n",
      "\n",
      " Train loss: 0.001354273990727961 | Test loss: 1.6273  | Test acc: 0.7648\n",
      "\n",
      " Train loss: 0.000525232229847461 | Test loss: 1.8002  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0006244881660677493 | Test loss: 2.0280  | Test acc: 0.7332\n",
      "\n",
      " Train loss: 0.0006227697595022619 | Test loss: 2.0089  | Test acc: 0.7319\n",
      "\n",
      " Train loss: 0.0009154948056675494 | Test loss: 1.9276  | Test acc: 0.7365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0016705316957086325 | Test loss: 1.7742  | Test acc: 0.7471\n",
      "\n",
      " Train loss: 0.000910211238078773 | Test loss: 2.3715  | Test acc: 0.7090\n",
      "\n",
      " Train loss: 0.002339498372748494 | Test loss: 2.9017  | Test acc: 0.6734\n",
      "\n",
      " Train loss: 0.0009783207206055522 | Test loss: 2.9648  | Test acc: 0.6656\n",
      "\n",
      " Train loss: 0.0016897814348340034 | Test loss: 2.3692  | Test acc: 0.7156\n",
      "\n",
      " Train loss: 0.0021181530319154263 | Test loss: 1.6886  | Test acc: 0.7577\n",
      "\n",
      " Train loss: 0.0003650732687674463 | Test loss: 2.0464  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0008590476354584098 | Test loss: 2.4630  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.0014307487290352583 | Test loss: 2.4180  | Test acc: 0.7103\n",
      "\n",
      " Train loss: 0.0011483064154163003 | Test loss: 2.5419  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.000874723365996033 | Test loss: 2.3394  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.0018481547012925148 | Test loss: 2.1725  | Test acc: 0.7429\n",
      "\n",
      " Train loss: 0.00041161992703564465 | Test loss: 2.0378  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.0005401818198151886 | Test loss: 2.2925  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.0014245398342609406 | Test loss: 2.3054  | Test acc: 0.6958\n",
      "\n",
      " Train loss: 0.0005508806789293885 | Test loss: 2.3425  | Test acc: 0.6853\n",
      "\n",
      " Train loss: 0.000888305134139955 | Test loss: 2.2231  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0009744788985699415 | Test loss: 1.6994  | Test acc: 0.7789\n",
      "\n",
      " Train loss: 0.0015596537850797176 | Test loss: 2.0367  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0007240423583425581 | Test loss: 2.3771  | Test acc: 0.7406\n",
      "\n",
      " Train loss: 0.0019431234104558825 | Test loss: 2.2817  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.001194008975289762 | Test loss: 2.6620  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.000950413232203573 | Test loss: 2.6933  | Test acc: 0.7344\n",
      "\n",
      " Train loss: 0.0010987712303176522 | Test loss: 2.3934  | Test acc: 0.7578\n",
      "\n",
      " Train loss: 6.20761638856493e-05 | Test loss: 2.2372  | Test acc: 0.7737\n",
      "\n",
      " Train loss: 0.0016222451813519 | Test loss: 2.1896  | Test acc: 0.7696\n",
      "\n",
      " Train loss: 0.0008181793964467943 | Test loss: 2.1736  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0013407202204689384 | Test loss: 2.0509  | Test acc: 0.7719\n",
      "\n",
      " Train loss: 0.0017617522971704602 | Test loss: 1.9664  | Test acc: 0.7796\n",
      "\n",
      " Train loss: 0.0005830336012877524 | Test loss: 2.0145  | Test acc: 0.7747\n",
      "\n",
      " Train loss: 0.0014178453711792827 | Test loss: 2.1677  | Test acc: 0.7559\n",
      "\n",
      " Train loss: 0.0008475142531096935 | Test loss: 2.1922  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.0005050105974078178 | Test loss: 2.1989  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.001283908379264176 | Test loss: 1.9722  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.001236559939570725 | Test loss: 1.9033  | Test acc: 0.7490\n",
      "\n",
      " Train loss: 0.0005234607378952205 | Test loss: 2.0381  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.0006371318595483899 | Test loss: 1.6625  | Test acc: 0.7625\n",
      "\n",
      " Train loss: 0.0002633203403092921 | Test loss: 1.7929  | Test acc: 0.7448\n",
      "\n",
      " Train loss: 0.000455061555840075 | Test loss: 2.0123  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.00038919455255381763 | Test loss: 2.2109  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0007166313589550555 | Test loss: 2.0988  | Test acc: 0.7477\n",
      "\n",
      " Train loss: 0.0011235945858061314 | Test loss: 1.9787  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0011903876438736916 | Test loss: 1.6593  | Test acc: 0.7857\n",
      "\n",
      " Train loss: 0.0005667094956152141 | Test loss: 1.6220  | Test acc: 0.7960\n",
      "\n",
      " Train loss: 0.00046144574298523366 | Test loss: 1.9653  | Test acc: 0.7727\n",
      "\n",
      " Train loss: 0.0014447306748479605 | Test loss: 2.1578  | Test acc: 0.7611\n",
      "\n",
      " Train loss: 0.001365905860438943 | Test loss: 2.0036  | Test acc: 0.7669\n",
      "\n",
      " Train loss: 0.0012750820023939013 | Test loss: 1.8652  | Test acc: 0.7695\n",
      "\n",
      " Train loss: 0.0010217353701591492 | Test loss: 1.8064  | Test acc: 0.7724\n",
      "\n",
      " Train loss: 0.0010767999337986112 | Test loss: 1.6764  | Test acc: 0.7881\n",
      "\n",
      " Train loss: 0.002237984212115407 | Test loss: 1.5746  | Test acc: 0.7970\n",
      "\n",
      " Train loss: 0.001289517036639154 | Test loss: 1.9277  | Test acc: 0.7670\n",
      "\n",
      " Train loss: 0.0010686207097023726 | Test loss: 1.7595  | Test acc: 0.7793\n",
      "\n",
      " Train loss: 0.0006882299785502255 | Test loss: 1.8278  | Test acc: 0.7663\n",
      "\n",
      " Train loss: 0.0005901370896026492 | Test loss: 2.4130  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0012935431441292167 | Test loss: 1.7390  | Test acc: 0.7711\n",
      "\n",
      " Train loss: 0.0007533268653787673 | Test loss: 1.6379  | Test acc: 0.7793\n",
      "\n",
      " Train loss: 0.0017035474302247167 | Test loss: 1.6484  | Test acc: 0.7761\n",
      "\n",
      " Train loss: 0.0015850620111450553 | Test loss: 1.7454  | Test acc: 0.7617\n",
      "Epoch 2\n",
      "------\n",
      "Looked at 0/ 60000 samples\n",
      "\n",
      " Train loss: 0.001011682441458106 | Test loss: 1.8873  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.0005041523836553097 | Test loss: 2.0810  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0017109708860516548 | Test loss: 2.0660  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.00148051290307194 | Test loss: 1.6580  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0008870758465491235 | Test loss: 1.7399  | Test acc: 0.7532\n",
      "\n",
      " Train loss: 0.001402244670316577 | Test loss: 1.8210  | Test acc: 0.7490\n",
      "\n",
      " Train loss: 0.0009248185087926686 | Test loss: 1.8057  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.00019764913304243237 | Test loss: 1.9347  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0015305849956348538 | Test loss: 1.7839  | Test acc: 0.7180\n",
      "\n",
      " Train loss: 0.0006810117047280073 | Test loss: 1.6837  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.000137942231958732 | Test loss: 1.7321  | Test acc: 0.7176\n",
      "\n",
      " Train loss: 0.0014458405785262585 | Test loss: 1.5406  | Test acc: 0.7314\n",
      "\n",
      " Train loss: 0.0007920606876723468 | Test loss: 1.2822  | Test acc: 0.7626\n",
      "\n",
      " Train loss: 0.0005637078429572284 | Test loss: 1.3430  | Test acc: 0.7657\n",
      "\n",
      " Train loss: 0.0005775905447080731 | Test loss: 1.5456  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.000680347322486341 | Test loss: 1.6936  | Test acc: 0.7233\n",
      "\n",
      " Train loss: 0.0012189139379188418 | Test loss: 1.7559  | Test acc: 0.7109\n",
      "\n",
      " Train loss: 0.0006044941837899387 | Test loss: 1.4322  | Test acc: 0.7619\n",
      "\n",
      " Train loss: 0.0013078156625851989 | Test loss: 1.4355  | Test acc: 0.7650\n",
      "\n",
      " Train loss: 0.0008249129168689251 | Test loss: 1.9372  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.0003976485750172287 | Test loss: 2.2533  | Test acc: 0.7023\n",
      "\n",
      " Train loss: 0.0005037541850470006 | Test loss: 2.5051  | Test acc: 0.6817\n",
      "\n",
      " Train loss: 0.000412550667533651 | Test loss: 2.4115  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.0011854451149702072 | Test loss: 2.1319  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.0004176934889983386 | Test loss: 2.1585  | Test acc: 0.7045\n",
      "\n",
      " Train loss: 0.0008414133917540312 | Test loss: 1.9971  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.0007003069622442126 | Test loss: 1.8690  | Test acc: 0.7121\n",
      "\n",
      " Train loss: 0.0018194434233009815 | Test loss: 1.7335  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0006910835509188473 | Test loss: 1.8846  | Test acc: 0.7124\n",
      "\n",
      " Train loss: 0.0009478534338995814 | Test loss: 1.9034  | Test acc: 0.7198\n",
      "\n",
      " Train loss: 0.001141318934969604 | Test loss: 1.9254  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0009696650085970759 | Test loss: 1.9716  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.001182075240649283 | Test loss: 1.7208  | Test acc: 0.7455\n",
      "\n",
      " Train loss: 0.0008551544742658734 | Test loss: 1.5967  | Test acc: 0.7469\n",
      "\n",
      " Train loss: 0.0012328815646469593 | Test loss: 1.6417  | Test acc: 0.7507\n",
      "\n",
      " Train loss: 0.0009500543237663805 | Test loss: 1.8388  | Test acc: 0.7415\n",
      "\n",
      " Train loss: 0.0013475932646542788 | Test loss: 1.7188  | Test acc: 0.7567\n",
      "\n",
      " Train loss: 0.0006726540741510689 | Test loss: 1.8958  | Test acc: 0.7455\n",
      "\n",
      " Train loss: 0.0006198398768901825 | Test loss: 1.8143  | Test acc: 0.7546\n",
      "\n",
      " Train loss: 0.0011617044219747186 | Test loss: 1.5665  | Test acc: 0.7834\n",
      "\n",
      " Train loss: 0.001390555058605969 | Test loss: 1.6904  | Test acc: 0.7881\n",
      "\n",
      " Train loss: 0.0004452609282452613 | Test loss: 2.1691  | Test acc: 0.7625\n",
      "\n",
      " Train loss: 0.0006774531793780625 | Test loss: 2.4170  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.001205253298394382 | Test loss: 1.8135  | Test acc: 0.7858\n",
      "\n",
      " Train loss: 0.00043698286754079163 | Test loss: 1.6192  | Test acc: 0.7867\n",
      "\n",
      " Train loss: 0.0006942705949768424 | Test loss: 1.6900  | Test acc: 0.7726\n",
      "\n",
      " Train loss: 0.0004637296951841563 | Test loss: 1.7696  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0005856528878211975 | Test loss: 2.1118  | Test acc: 0.7375\n",
      "\n",
      " Train loss: 0.0007461289060302079 | Test loss: 2.2375  | Test acc: 0.7223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0010232242057099938 | Test loss: 1.9034  | Test acc: 0.7589\n",
      "\n",
      " Train loss: 0.0021953086834400892 | Test loss: 1.7441  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0003487529174890369 | Test loss: 1.9485  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.0017920240061357617 | Test loss: 2.1931  | Test acc: 0.7258\n",
      "\n",
      " Train loss: 0.0009274613694287837 | Test loss: 2.2587  | Test acc: 0.7178\n",
      "\n",
      " Train loss: 0.0009912813547998667 | Test loss: 2.0593  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.0009851842187345028 | Test loss: 2.2491  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.0004908361006528139 | Test loss: 2.6956  | Test acc: 0.6869\n",
      "\n",
      " Train loss: 0.00022760620049666613 | Test loss: 3.3297  | Test acc: 0.6596\n",
      "\n",
      " Train loss: 0.0017285548383370042 | Test loss: 2.1457  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.0008133676601573825 | Test loss: 2.1818  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.0005509344046004117 | Test loss: 2.8902  | Test acc: 0.6934\n",
      "\n",
      " Train loss: 0.0024737354833632708 | Test loss: 2.4070  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.0012133067939430475 | Test loss: 1.7254  | Test acc: 0.7483\n",
      "\n",
      " Train loss: 0.00038001398206688464 | Test loss: 2.2975  | Test acc: 0.7161\n",
      "\n",
      " Train loss: 0.0004043264198116958 | Test loss: 2.9503  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.0016356233973056078 | Test loss: 2.7441  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0011818964267149568 | Test loss: 2.0631  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.0006177673349156976 | Test loss: 2.5816  | Test acc: 0.6830\n",
      "\n",
      " Train loss: 0.0009699352667666972 | Test loss: 3.2153  | Test acc: 0.6798\n",
      "\n",
      " Train loss: 0.0015040577854961157 | Test loss: 2.7553  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.0005014564958401024 | Test loss: 2.5981  | Test acc: 0.7098\n",
      "\n",
      " Train loss: 0.0009740343084558845 | Test loss: 1.8848  | Test acc: 0.7646\n",
      "\n",
      " Train loss: 0.0006397421238943934 | Test loss: 2.5483  | Test acc: 0.7139\n",
      "\n",
      " Train loss: 0.002419493393972516 | Test loss: 2.9831  | Test acc: 0.6852\n",
      "\n",
      " Train loss: 0.0008292596321552992 | Test loss: 3.3287  | Test acc: 0.6783\n",
      "\n",
      " Train loss: 0.0020139957778155804 | Test loss: 2.6197  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0006503468612208962 | Test loss: 2.6472  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0018861222779378295 | Test loss: 2.2389  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.000876535486895591 | Test loss: 3.3797  | Test acc: 0.6507\n",
      "\n",
      " Train loss: 0.0011890213936567307 | Test loss: 4.3628  | Test acc: 0.6169\n",
      "\n",
      " Train loss: 0.0019920042250305414 | Test loss: 3.6313  | Test acc: 0.6663\n",
      "\n",
      " Train loss: 0.0023552854545414448 | Test loss: 4.4351  | Test acc: 0.6639\n",
      "\n",
      " Train loss: 0.0005085808224976063 | Test loss: 4.6871  | Test acc: 0.6692\n",
      "\n",
      " Train loss: 0.0020476579666137695 | Test loss: 3.1442  | Test acc: 0.7145\n",
      "\n",
      " Train loss: 0.0015808725729584694 | Test loss: 2.8645  | Test acc: 0.7259\n",
      "\n",
      " Train loss: 0.00228103157132864 | Test loss: 2.7541  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.0009371753549203277 | Test loss: 4.3583  | Test acc: 0.6591\n",
      "\n",
      " Train loss: 0.0019571944139897823 | Test loss: 4.8709  | Test acc: 0.6610\n",
      "\n",
      " Train loss: 0.0020446761045604944 | Test loss: 4.8132  | Test acc: 0.6434\n",
      "\n",
      " Train loss: 0.0012126935180276632 | Test loss: 3.9878  | Test acc: 0.6794\n",
      "\n",
      " Train loss: 0.0017983820289373398 | Test loss: 3.6931  | Test acc: 0.6981\n",
      "\n",
      " Train loss: 0.001356090884655714 | Test loss: 3.7607  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.0030508730560541153 | Test loss: 5.0530  | Test acc: 0.6519\n",
      "\n",
      " Train loss: 0.002275246661156416 | Test loss: 7.1245  | Test acc: 0.6253\n",
      "\n",
      " Train loss: 0.003568728920072317 | Test loss: 6.3491  | Test acc: 0.6484\n",
      "\n",
      " Train loss: 0.003585126716643572 | Test loss: 3.5676  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.001920246402733028 | Test loss: 5.0387  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.0037346240133047104 | Test loss: 6.1469  | Test acc: 0.6884\n",
      "\n",
      " Train loss: 0.0036962751764804125 | Test loss: 6.0689  | Test acc: 0.6885\n",
      "\n",
      " Train loss: 0.001316120964474976 | Test loss: 5.2758  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.00410334300249815 | Test loss: 3.5255  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.0008077226812019944 | Test loss: 5.4558  | Test acc: 0.6736\n",
      "\n",
      " Train loss: 0.004527918994426727 | Test loss: 4.7788  | Test acc: 0.6955\n",
      "\n",
      " Train loss: 0.0019135797629132867 | Test loss: 4.4987  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.0015587800880894065 | Test loss: 4.8838  | Test acc: 0.6951\n",
      "\n",
      " Train loss: 0.0026330004911869764 | Test loss: 5.4849  | Test acc: 0.6596\n",
      "\n",
      " Train loss: 0.0010770836379379034 | Test loss: 5.1802  | Test acc: 0.6684\n",
      "\n",
      " Train loss: 0.002619141712784767 | Test loss: 5.1865  | Test acc: 0.6472\n",
      "\n",
      " Train loss: 0.0016333878738805652 | Test loss: 5.9749  | Test acc: 0.6669\n",
      "\n",
      " Train loss: 0.0023960890248417854 | Test loss: 6.1699  | Test acc: 0.6782\n",
      "\n",
      " Train loss: 0.004727337975054979 | Test loss: 6.2237  | Test acc: 0.6637\n",
      "\n",
      " Train loss: 0.0030797526706010103 | Test loss: 5.1093  | Test acc: 0.7075\n",
      "\n",
      " Train loss: 0.002300143474712968 | Test loss: 5.8420  | Test acc: 0.6958\n",
      "\n",
      " Train loss: 0.0015368792228400707 | Test loss: 6.5280  | Test acc: 0.6972\n",
      "\n",
      " Train loss: 0.0019338402198627591 | Test loss: 6.1459  | Test acc: 0.6942\n",
      "\n",
      " Train loss: 0.0037114513106644154 | Test loss: 4.5537  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0034164325334131718 | Test loss: 6.6770  | Test acc: 0.6370\n",
      "\n",
      " Train loss: 0.004455868620425463 | Test loss: 6.5671  | Test acc: 0.6758\n",
      "\n",
      " Train loss: 0.0015838247491046786 | Test loss: 8.4544  | Test acc: 0.6376\n",
      "\n",
      " Train loss: 0.005071905441582203 | Test loss: 9.4213  | Test acc: 0.5863\n",
      "\n",
      " Train loss: 0.004471109714359045 | Test loss: 6.2149  | Test acc: 0.6850\n",
      "\n",
      " Train loss: 0.004633527714759111 | Test loss: 4.3730  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.000591526972129941 | Test loss: 5.4457  | Test acc: 0.6838\n",
      "\n",
      " Train loss: 0.002695398172363639 | Test loss: 5.8008  | Test acc: 0.6707\n",
      "\n",
      " Train loss: 0.0010084185050800443 | Test loss: 4.7193  | Test acc: 0.7036\n",
      "\n",
      " Train loss: 0.002100270241498947 | Test loss: 4.1939  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0009654362802393734 | Test loss: 4.0160  | Test acc: 0.7386\n",
      "\n",
      " Train loss: 0.0025590111035853624 | Test loss: 5.3973  | Test acc: 0.6925\n",
      "\n",
      " Train loss: 0.002565714530646801 | Test loss: 6.8250  | Test acc: 0.6723\n",
      "\n",
      " Train loss: 0.004335729870945215 | Test loss: 5.2679  | Test acc: 0.6776\n",
      "\n",
      " Train loss: 0.0020952275954186916 | Test loss: 5.7779  | Test acc: 0.6925\n",
      "\n",
      " Train loss: 0.002832041122019291 | Test loss: 6.7777  | Test acc: 0.6919\n",
      "\n",
      " Train loss: 0.0016930137062445283 | Test loss: 8.8430  | Test acc: 0.6584\n",
      "\n",
      " Train loss: 0.0058976043947041035 | Test loss: 6.6519  | Test acc: 0.6662\n",
      "\n",
      " Train loss: 0.003499434096738696 | Test loss: 4.5954  | Test acc: 0.7184\n",
      "\n",
      " Train loss: 0.0012538826558738947 | Test loss: 7.5580  | Test acc: 0.6733\n",
      "\n",
      " Train loss: 0.005311157554388046 | Test loss: 7.1263  | Test acc: 0.6904\n",
      "\n",
      " Train loss: 0.004934362135827541 | Test loss: 5.4616  | Test acc: 0.7235\n",
      "\n",
      " Train loss: 0.003472792450338602 | Test loss: 4.9593  | Test acc: 0.7523\n",
      "\n",
      " Train loss: 0.0023903094697743654 | Test loss: 5.5594  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.0027002678252756596 | Test loss: 4.8059  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.0023227694910019636 | Test loss: 5.6134  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.002861820161342621 | Test loss: 6.2722  | Test acc: 0.7203\n",
      "\n",
      " Train loss: 0.002911907620728016 | Test loss: 5.6188  | Test acc: 0.7194\n",
      "\n",
      " Train loss: 0.0004208396712783724 | Test loss: 5.3753  | Test acc: 0.7196\n",
      "\n",
      " Train loss: 0.006721667945384979 | Test loss: 4.5014  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.0014728972455486655 | Test loss: 4.8858  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0019640407990664244 | Test loss: 4.8148  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.0016599170630797744 | Test loss: 4.4125  | Test acc: 0.7565\n",
      "\n",
      " Train loss: 0.0024467925541102886 | Test loss: 4.1178  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.0019608179572969675 | Test loss: 4.4603  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.00079427968012169 | Test loss: 5.7764  | Test acc: 0.7173\n",
      "\n",
      " Train loss: 0.0030499810818582773 | Test loss: 7.5588  | Test acc: 0.6639\n",
      "\n",
      " Train loss: 0.0033755956683307886 | Test loss: 7.9209  | Test acc: 0.6299\n",
      "\n",
      " Train loss: 0.004483840893954039 | Test loss: 4.0635  | Test acc: 0.7265\n",
      "\n",
      " Train loss: 0.0009851923678070307 | Test loss: 4.6520  | Test acc: 0.6970\n",
      "\n",
      " Train loss: 0.002729301806539297 | Test loss: 4.6828  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.0007597085204906762 | Test loss: 5.1337  | Test acc: 0.7056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.002182458760216832 | Test loss: 6.5409  | Test acc: 0.6590\n",
      "\n",
      " Train loss: 0.0018071518279612064 | Test loss: 7.9119  | Test acc: 0.6269\n",
      "\n",
      " Train loss: 0.0016926380340009928 | Test loss: 7.5271  | Test acc: 0.6611\n",
      "\n",
      " Train loss: 0.0020800791680812836 | Test loss: 6.8458  | Test acc: 0.6745\n",
      "\n",
      " Train loss: 0.0012768367305397987 | Test loss: 6.2287  | Test acc: 0.6495\n",
      "\n",
      " Train loss: 0.002823522547259927 | Test loss: 4.8899  | Test acc: 0.6883\n",
      "\n",
      " Train loss: 0.000535902101546526 | Test loss: 5.7197  | Test acc: 0.6742\n",
      "\n",
      " Train loss: 0.005824132356792688 | Test loss: 5.5633  | Test acc: 0.6915\n",
      "\n",
      " Train loss: 0.0024619498290121555 | Test loss: 6.1165  | Test acc: 0.6721\n",
      "\n",
      " Train loss: 0.0013228543102741241 | Test loss: 10.3246  | Test acc: 0.6038\n",
      "\n",
      " Train loss: 0.0054779876954853535 | Test loss: 6.6799  | Test acc: 0.6702\n",
      "\n",
      " Train loss: 0.0034449396189302206 | Test loss: 4.0567  | Test acc: 0.7519\n",
      "\n",
      " Train loss: 0.0024208305403590202 | Test loss: 4.8682  | Test acc: 0.7446\n",
      "\n",
      " Train loss: 0.002362386789172888 | Test loss: 5.0826  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.0018519433215260506 | Test loss: 4.8570  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0036014390643686056 | Test loss: 8.8532  | Test acc: 0.6046\n",
      "\n",
      " Train loss: 0.0063579208217561245 | Test loss: 6.0502  | Test acc: 0.6633\n",
      "\n",
      " Train loss: 0.004447558894753456 | Test loss: 5.3903  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.0017364758532494307 | Test loss: 5.4933  | Test acc: 0.7037\n",
      "\n",
      " Train loss: 0.004279637709259987 | Test loss: 6.5207  | Test acc: 0.6594\n",
      "\n",
      " Train loss: 0.001593803521245718 | Test loss: 6.6832  | Test acc: 0.6472\n",
      "\n",
      " Train loss: 0.0059436010196805 | Test loss: 4.9680  | Test acc: 0.6701\n",
      "\n",
      " Train loss: 0.002628326416015625 | Test loss: 8.5774  | Test acc: 0.6198\n",
      "\n",
      " Train loss: 0.004272935912013054 | Test loss: 7.3331  | Test acc: 0.6750\n",
      "\n",
      " Train loss: 0.004021135158836842 | Test loss: 6.2787  | Test acc: 0.6882\n",
      "\n",
      " Train loss: 0.0022255557123571634 | Test loss: 4.8554  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.003025069134309888 | Test loss: 5.1132  | Test acc: 0.6907\n",
      "\n",
      " Train loss: 0.0030127193313091993 | Test loss: 4.2669  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.0011539789848029613 | Test loss: 4.3826  | Test acc: 0.7302\n",
      "\n",
      " Train loss: 0.0027247148100286722 | Test loss: 5.8463  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.0027032941579818726 | Test loss: 5.4639  | Test acc: 0.7097\n",
      "\n",
      " Train loss: 0.002369014546275139 | Test loss: 6.9747  | Test acc: 0.6479\n",
      "\n",
      " Train loss: 0.001269688829779625 | Test loss: 7.7804  | Test acc: 0.6295\n",
      "\n",
      " Train loss: 0.004777822177857161 | Test loss: 5.3602  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.002655193442478776 | Test loss: 6.4563  | Test acc: 0.6939\n",
      "\n",
      " Train loss: 0.0010240513365715742 | Test loss: 6.6600  | Test acc: 0.6929\n",
      "\n",
      " Train loss: 0.004263356328010559 | Test loss: 6.4668  | Test acc: 0.6925\n",
      "\n",
      " Train loss: 0.0040528434328734875 | Test loss: 6.9517  | Test acc: 0.6806\n",
      "\n",
      " Train loss: 0.005403089337050915 | Test loss: 4.8423  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0026633874513208866 | Test loss: 4.5522  | Test acc: 0.7603\n",
      "\n",
      " Train loss: 0.003591865533962846 | Test loss: 5.2161  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.0028394435066729784 | Test loss: 5.2439  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.0005000868113711476 | Test loss: 6.1032  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.001950885052792728 | Test loss: 5.5299  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0032331091351807117 | Test loss: 4.5139  | Test acc: 0.7720\n",
      "\n",
      " Train loss: 0.0011691972613334656 | Test loss: 5.2486  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0007927839760668576 | Test loss: 6.7687  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.00465333042666316 | Test loss: 8.4429  | Test acc: 0.6595\n",
      "\n",
      " Train loss: 0.00406239228323102 | Test loss: 11.5515  | Test acc: 0.5833\n",
      "\n",
      " Train loss: 0.004817155655473471 | Test loss: 11.9305  | Test acc: 0.5780\n",
      "\n",
      " Train loss: 0.0032426221296191216 | Test loss: 8.0454  | Test acc: 0.6456\n",
      "\n",
      " Train loss: 0.007752251345664263 | Test loss: 5.4018  | Test acc: 0.6957\n",
      "\n",
      " Train loss: 0.001853249385021627 | Test loss: 5.2366  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0020859770011156797 | Test loss: 7.1231  | Test acc: 0.6849\n",
      "\n",
      " Train loss: 0.0044389995746314526 | Test loss: 5.6670  | Test acc: 0.7135\n",
      "\n",
      " Train loss: 0.0032862743828445673 | Test loss: 5.4413  | Test acc: 0.7267\n",
      "\n",
      " Train loss: 0.0005138648557476699 | Test loss: 6.4999  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.0037714142818003893 | Test loss: 6.4400  | Test acc: 0.7207\n",
      "\n",
      " Train loss: 0.003358794841915369 | Test loss: 5.9887  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.004602463450282812 | Test loss: 6.2474  | Test acc: 0.6912\n",
      "\n",
      " Train loss: 0.004033099394291639 | Test loss: 5.3074  | Test acc: 0.6925\n",
      "\n",
      " Train loss: 0.001613541622646153 | Test loss: 5.6272  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.003552123671397567 | Test loss: 5.7282  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0019985605031251907 | Test loss: 5.4571  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0033998191356658936 | Test loss: 4.6761  | Test acc: 0.7179\n",
      "\n",
      " Train loss: 0.001658329856581986 | Test loss: 6.0557  | Test acc: 0.6841\n",
      "\n",
      " Train loss: 0.002402004087343812 | Test loss: 7.1039  | Test acc: 0.6575\n",
      "\n",
      " Train loss: 0.000758838898036629 | Test loss: 6.6525  | Test acc: 0.7008\n",
      "\n",
      " Train loss: 0.0017791562713682652 | Test loss: 6.3897  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.004582278896123171 | Test loss: 5.3160  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.004039715975522995 | Test loss: 6.6331  | Test acc: 0.6505\n",
      "\n",
      " Train loss: 0.0026490858290344477 | Test loss: 8.6679  | Test acc: 0.6221\n",
      "\n",
      " Train loss: 0.007501137442886829 | Test loss: 5.7318  | Test acc: 0.6877\n",
      "\n",
      " Train loss: 0.004377669654786587 | Test loss: 5.1146  | Test acc: 0.7236\n",
      "\n",
      " Train loss: 0.0025030954275280237 | Test loss: 6.9762  | Test acc: 0.6709\n",
      "\n",
      " Train loss: 0.0049676597118377686 | Test loss: 7.5386  | Test acc: 0.6651\n",
      "\n",
      " Train loss: 0.004900804255157709 | Test loss: 6.3977  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0024969179648905993 | Test loss: 5.1879  | Test acc: 0.7350\n",
      "\n",
      " Train loss: 0.001838849624618888 | Test loss: 4.9218  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.0007061206270009279 | Test loss: 7.4048  | Test acc: 0.6474\n",
      "\n",
      " Train loss: 0.0028003877960145473 | Test loss: 9.3936  | Test acc: 0.6076\n",
      "\n",
      " Train loss: 0.0032596068922430277 | Test loss: 8.5678  | Test acc: 0.6003\n",
      "\n",
      " Train loss: 0.0038408965338021517 | Test loss: 5.8095  | Test acc: 0.6926\n",
      "\n",
      " Train loss: 0.0022021678742021322 | Test loss: 4.5417  | Test acc: 0.7539\n",
      "\n",
      " Train loss: 0.002223270945250988 | Test loss: 5.2739  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.0013959408970549703 | Test loss: 6.2179  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0011805754620581865 | Test loss: 6.5310  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.002198964124545455 | Test loss: 6.7923  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.00215283059515059 | Test loss: 6.3550  | Test acc: 0.7307\n",
      "\n",
      " Train loss: 0.0033273836597800255 | Test loss: 5.7415  | Test acc: 0.7328\n",
      "\n",
      " Train loss: 0.0013996884226799011 | Test loss: 5.2649  | Test acc: 0.7439\n",
      "\n",
      " Train loss: 0.0034058471210300922 | Test loss: 4.6403  | Test acc: 0.7689\n",
      "\n",
      " Train loss: 0.0016177501529455185 | Test loss: 4.0436  | Test acc: 0.7878\n",
      "\n",
      " Train loss: 0.004099614918231964 | Test loss: 4.3111  | Test acc: 0.7555\n",
      "\n",
      " Train loss: 0.002252901205793023 | Test loss: 5.7520  | Test acc: 0.7072\n",
      "\n",
      " Train loss: 0.005860582459717989 | Test loss: 5.6657  | Test acc: 0.7256\n",
      "\n",
      " Train loss: 0.0023074832279235125 | Test loss: 6.1025  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.006712463218718767 | Test loss: 5.2240  | Test acc: 0.7606\n",
      "\n",
      " Train loss: 0.0020982548594474792 | Test loss: 5.0844  | Test acc: 0.7628\n",
      "\n",
      " Train loss: 0.002533088903874159 | Test loss: 5.5103  | Test acc: 0.7426\n",
      "\n",
      " Train loss: 0.0027146197389811277 | Test loss: 5.4596  | Test acc: 0.7407\n",
      "\n",
      " Train loss: 0.00235484866425395 | Test loss: 4.6328  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0017134480876848102 | Test loss: 4.4594  | Test acc: 0.7787\n",
      "\n",
      " Train loss: 0.0026703577022999525 | Test loss: 5.3421  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.0025790613144636154 | Test loss: 6.0060  | Test acc: 0.7143\n",
      "\n",
      " Train loss: 0.004957079887390137 | Test loss: 4.8064  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.0032604746520519257 | Test loss: 5.6374  | Test acc: 0.7154\n",
      "\n",
      " Train loss: 0.001828898093663156 | Test loss: 6.1145  | Test acc: 0.6886\n",
      "\n",
      " Train loss: 0.0012956628343090415 | Test loss: 5.4409  | Test acc: 0.7271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0027321744710206985 | Test loss: 6.9004  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.002991050248965621 | Test loss: 7.0372  | Test acc: 0.7133\n",
      "\n",
      " Train loss: 0.002152282977476716 | Test loss: 5.3800  | Test acc: 0.7345\n",
      "\n",
      " Train loss: 0.0011979169212281704 | Test loss: 4.2411  | Test acc: 0.7605\n",
      "\n",
      " Train loss: 0.0023675241973251104 | Test loss: 4.4875  | Test acc: 0.7617\n",
      "\n",
      " Train loss: 0.0023015555925667286 | Test loss: 5.2436  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.004387121181935072 | Test loss: 5.3615  | Test acc: 0.7227\n",
      "\n",
      " Train loss: 0.0015353590715676546 | Test loss: 4.6608  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.001636770204640925 | Test loss: 3.8895  | Test acc: 0.7668\n",
      "\n",
      " Train loss: 0.0022124722599983215 | Test loss: 3.7092  | Test acc: 0.7745\n",
      "\n",
      " Train loss: 0.0013710998464375734 | Test loss: 4.3185  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0005391782615333796 | Test loss: 6.3641  | Test acc: 0.6747\n",
      "\n",
      " Train loss: 0.004153801593929529 | Test loss: 5.7121  | Test acc: 0.6846\n",
      "\n",
      " Train loss: 0.001161828520707786 | Test loss: 4.5611  | Test acc: 0.7060\n",
      "\n",
      " Train loss: 0.0032573342323303223 | Test loss: 4.9354  | Test acc: 0.6877\n",
      "\n",
      " Train loss: 0.002953381510451436 | Test loss: 3.8360  | Test acc: 0.7146\n",
      "\n",
      " Train loss: 0.002555479994043708 | Test loss: 3.2487  | Test acc: 0.7553\n",
      "\n",
      " Train loss: 0.001375047373585403 | Test loss: 3.3332  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.0017454042099416256 | Test loss: 3.7647  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0012085704365745187 | Test loss: 4.3407  | Test acc: 0.7399\n",
      "\n",
      " Train loss: 0.004716438241302967 | Test loss: 5.0135  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0028483879286795855 | Test loss: 6.1433  | Test acc: 0.6681\n",
      "\n",
      " Train loss: 0.003365922486409545 | Test loss: 5.8947  | Test acc: 0.6881\n",
      "\n",
      " Train loss: 0.003923974931240082 | Test loss: 5.2557  | Test acc: 0.6796\n",
      "\n",
      " Train loss: 0.004391920752823353 | Test loss: 3.5273  | Test acc: 0.7251\n",
      "\n",
      " Train loss: 0.0012555837165564299 | Test loss: 3.8145  | Test acc: 0.7170\n",
      "\n",
      " Train loss: 0.001698995940387249 | Test loss: 4.3258  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.0029073269106447697 | Test loss: 3.4555  | Test acc: 0.7422\n",
      "\n",
      " Train loss: 0.0010883256327360868 | Test loss: 3.8420  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.0017578501719981432 | Test loss: 4.6461  | Test acc: 0.6877\n",
      "\n",
      " Train loss: 0.004955506417900324 | Test loss: 3.2125  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0014619206776842475 | Test loss: 3.0007  | Test acc: 0.7694\n",
      "\n",
      " Train loss: 0.0012279278598725796 | Test loss: 3.1916  | Test acc: 0.7586\n",
      "\n",
      " Train loss: 0.0016206316649913788 | Test loss: 3.1188  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0017252720426768064 | Test loss: 3.1382  | Test acc: 0.7451\n",
      "\n",
      " Train loss: 0.0021888467017561197 | Test loss: 3.4503  | Test acc: 0.7218\n",
      "\n",
      " Train loss: 0.002458913717418909 | Test loss: 3.0100  | Test acc: 0.7504\n",
      "\n",
      " Train loss: 0.001678464817814529 | Test loss: 2.8271  | Test acc: 0.7637\n",
      "\n",
      " Train loss: 0.002542497357353568 | Test loss: 2.4192  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0014183453749865294 | Test loss: 2.4384  | Test acc: 0.7676\n",
      "\n",
      " Train loss: 0.00342599512077868 | Test loss: 2.6764  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0011134517844766378 | Test loss: 3.2471  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0015958546428009868 | Test loss: 3.5268  | Test acc: 0.6935\n",
      "\n",
      " Train loss: 0.001572911744005978 | Test loss: 2.9294  | Test acc: 0.7304\n",
      "\n",
      " Train loss: 0.0002787304110825062 | Test loss: 3.0609  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.000927583547309041 | Test loss: 2.8593  | Test acc: 0.7435\n",
      "\n",
      " Train loss: 0.0008851198945194483 | Test loss: 2.5012  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.0009235116303898394 | Test loss: 2.7224  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.001555979368276894 | Test loss: 3.2039  | Test acc: 0.7474\n",
      "\n",
      " Train loss: 0.00040031500975601375 | Test loss: 4.1616  | Test acc: 0.7180\n",
      "\n",
      " Train loss: 0.0024422970600426197 | Test loss: 4.6614  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.0012247678823769093 | Test loss: 4.4657  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0008418408106081188 | Test loss: 3.8834  | Test acc: 0.7468\n",
      "\n",
      " Train loss: 0.002515185857191682 | Test loss: 3.9469  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.003126456867903471 | Test loss: 3.6765  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0022924344521015882 | Test loss: 3.5269  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.0016642630798742175 | Test loss: 4.1142  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0009670249419286847 | Test loss: 4.8993  | Test acc: 0.6620\n",
      "\n",
      " Train loss: 0.002469060244038701 | Test loss: 4.7692  | Test acc: 0.6458\n",
      "\n",
      " Train loss: 0.002210685284808278 | Test loss: 4.8058  | Test acc: 0.6443\n",
      "\n",
      " Train loss: 0.0018732394091784954 | Test loss: 3.6875  | Test acc: 0.7019\n",
      "\n",
      " Train loss: 0.002659554360434413 | Test loss: 3.1227  | Test acc: 0.7500\n",
      "\n",
      " Train loss: 0.000742887903470546 | Test loss: 3.2734  | Test acc: 0.7564\n",
      "\n",
      " Train loss: 0.0026534523349255323 | Test loss: 3.5864  | Test acc: 0.7424\n",
      "\n",
      " Train loss: 0.0016859974712133408 | Test loss: 3.3086  | Test acc: 0.7521\n",
      "\n",
      " Train loss: 0.0014577786205336452 | Test loss: 3.6648  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.0004781836469192058 | Test loss: 4.2967  | Test acc: 0.7063\n",
      "\n",
      " Train loss: 0.0008873086771927774 | Test loss: 3.8029  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0005229483358561993 | Test loss: 3.9581  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.001028544851578772 | Test loss: 3.8746  | Test acc: 0.7205\n",
      "\n",
      " Train loss: 0.0008027830626815557 | Test loss: 4.3366  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0030455668456852436 | Test loss: 5.2569  | Test acc: 0.6251\n",
      "\n",
      " Train loss: 0.0031491629779338837 | Test loss: 4.7726  | Test acc: 0.6393\n",
      "\n",
      " Train loss: 0.0017589678755030036 | Test loss: 4.7436  | Test acc: 0.6522\n",
      "\n",
      " Train loss: 0.0021179779432713985 | Test loss: 4.6536  | Test acc: 0.6698\n",
      "\n",
      " Train loss: 0.0013982750242576003 | Test loss: 5.0236  | Test acc: 0.6836\n",
      "\n",
      " Train loss: 0.0026262907776981592 | Test loss: 4.0379  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.002109804190695286 | Test loss: 3.9288  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.0011346678948029876 | Test loss: 4.5005  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0035710446536540985 | Test loss: 4.9334  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.0025658144149929285 | Test loss: 5.1668  | Test acc: 0.7353\n",
      "\n",
      " Train loss: 0.003015094203874469 | Test loss: 4.6545  | Test acc: 0.7405\n",
      "\n",
      " Train loss: 0.0025039375759661198 | Test loss: 4.7538  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.0022600158117711544 | Test loss: 4.3767  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.003011399880051613 | Test loss: 4.9546  | Test acc: 0.6695\n",
      "\n",
      " Train loss: 0.002527476754039526 | Test loss: 5.8090  | Test acc: 0.6674\n",
      "\n",
      " Train loss: 0.0030165472999215126 | Test loss: 7.7505  | Test acc: 0.6114\n",
      "\n",
      " Train loss: 0.00370386871509254 | Test loss: 6.4989  | Test acc: 0.6593\n",
      "\n",
      " Train loss: 0.00422811321914196 | Test loss: 7.0702  | Test acc: 0.6867\n",
      "\n",
      " Train loss: 0.00386953167617321 | Test loss: 6.1403  | Test acc: 0.6870\n",
      "\n",
      " Train loss: 0.0025821952149271965 | Test loss: 5.1057  | Test acc: 0.6895\n",
      "\n",
      " Train loss: 0.0007656811503693461 | Test loss: 5.3117  | Test acc: 0.6980\n",
      "\n",
      " Train loss: 0.0012304560514166951 | Test loss: 6.2109  | Test acc: 0.6676\n",
      "\n",
      " Train loss: 0.004305014852434397 | Test loss: 4.4352  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0010526040568947792 | Test loss: 5.8017  | Test acc: 0.6801\n",
      "\n",
      " Train loss: 0.0011457675136625767 | Test loss: 6.8985  | Test acc: 0.6290\n",
      "\n",
      " Train loss: 0.003236829536035657 | Test loss: 6.0721  | Test acc: 0.6508\n",
      "\n",
      " Train loss: 0.002019453328102827 | Test loss: 5.4835  | Test acc: 0.6702\n",
      "\n",
      " Train loss: 0.006155472248792648 | Test loss: 4.4771  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.001228675595484674 | Test loss: 4.9706  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0037152052391320467 | Test loss: 5.6243  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.0028062390629202127 | Test loss: 5.5994  | Test acc: 0.7079\n",
      "\n",
      " Train loss: 0.0017163049196824431 | Test loss: 4.2528  | Test acc: 0.7517\n",
      "\n",
      " Train loss: 0.0021758463699370623 | Test loss: 3.7690  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0015356006333604455 | Test loss: 4.1089  | Test acc: 0.7223\n",
      "\n",
      " Train loss: 0.002545525087043643 | Test loss: 4.3316  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0017790296114981174 | Test loss: 4.7549  | Test acc: 0.7273\n",
      "\n",
      " Train loss: 0.0024101126473397017 | Test loss: 5.4662  | Test acc: 0.7200\n",
      "\n",
      " Train loss: 0.0027944203466176987 | Test loss: 5.3136  | Test acc: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0028577549383044243 | Test loss: 4.1470  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.002556934952735901 | Test loss: 4.3452  | Test acc: 0.7469\n",
      "\n",
      " Train loss: 0.002600793493911624 | Test loss: 5.4897  | Test acc: 0.7064\n",
      "\n",
      " Train loss: 0.002188511425629258 | Test loss: 5.0194  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.0019402682082727551 | Test loss: 4.3433  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0010660203406587243 | Test loss: 6.2556  | Test acc: 0.6958\n",
      "\n",
      " Train loss: 0.004625079687684774 | Test loss: 5.6660  | Test acc: 0.7109\n",
      "\n",
      " Train loss: 0.002389880595728755 | Test loss: 4.6234  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0018646996468305588 | Test loss: 3.7811  | Test acc: 0.7542\n",
      "\n",
      " Train loss: 0.0013278310652822256 | Test loss: 4.8815  | Test acc: 0.7135\n",
      "\n",
      " Train loss: 0.002680135192349553 | Test loss: 6.6644  | Test acc: 0.6726\n",
      "\n",
      " Train loss: 0.002120023360475898 | Test loss: 6.5956  | Test acc: 0.6619\n",
      "\n",
      " Train loss: 0.0018701734952628613 | Test loss: 4.4759  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.002577780047431588 | Test loss: 4.3139  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.0014270083047449589 | Test loss: 4.9314  | Test acc: 0.7302\n",
      "\n",
      " Train loss: 0.003288937034085393 | Test loss: 3.8759  | Test acc: 0.7656\n",
      "\n",
      " Train loss: 0.00218227063305676 | Test loss: 4.3922  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0036024965811520815 | Test loss: 4.8683  | Test acc: 0.7093\n",
      "\n",
      " Train loss: 0.0012519161682575941 | Test loss: 4.4633  | Test acc: 0.7123\n",
      "\n",
      " Train loss: 0.0018096781568601727 | Test loss: 3.7615  | Test acc: 0.7383\n",
      "\n",
      " Train loss: 0.0006402935250662267 | Test loss: 3.4005  | Test acc: 0.7633\n",
      "\n",
      " Train loss: 0.0005385471158660948 | Test loss: 4.1514  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0015024541644379497 | Test loss: 4.5164  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.003939962945878506 | Test loss: 4.2372  | Test acc: 0.7427\n",
      "Looked at 12800/ 60000 samples\n",
      "\n",
      " Train loss: 0.0013964283280074596 | Test loss: 4.0513  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.003919132519513369 | Test loss: 3.6805  | Test acc: 0.7375\n",
      "\n",
      " Train loss: 0.001812328351661563 | Test loss: 3.5608  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0023491436149924994 | Test loss: 3.5021  | Test acc: 0.7478\n",
      "\n",
      " Train loss: 0.002725296886637807 | Test loss: 4.2795  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.003459581173956394 | Test loss: 4.3608  | Test acc: 0.6993\n",
      "\n",
      " Train loss: 0.0028194196056574583 | Test loss: 3.4543  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.001435118610970676 | Test loss: 3.0039  | Test acc: 0.7396\n",
      "\n",
      " Train loss: 0.001987229101359844 | Test loss: 3.5786  | Test acc: 0.7009\n",
      "\n",
      " Train loss: 0.00238543632440269 | Test loss: 3.9695  | Test acc: 0.6841\n",
      "\n",
      " Train loss: 0.0011854107724502683 | Test loss: 4.2466  | Test acc: 0.6709\n",
      "\n",
      " Train loss: 0.0015086085768416524 | Test loss: 3.5800  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.004697475116699934 | Test loss: 3.5035  | Test acc: 0.7310\n",
      "\n",
      " Train loss: 0.0009969740640372038 | Test loss: 5.1231  | Test acc: 0.6840\n",
      "\n",
      " Train loss: 0.0028979454655200243 | Test loss: 4.1570  | Test acc: 0.7077\n",
      "\n",
      " Train loss: 0.001385129289701581 | Test loss: 3.5319  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0017181861912831664 | Test loss: 4.1344  | Test acc: 0.7051\n",
      "\n",
      " Train loss: 0.0009786196751520038 | Test loss: 5.2016  | Test acc: 0.6872\n",
      "\n",
      " Train loss: 0.003209901973605156 | Test loss: 6.2441  | Test acc: 0.6759\n",
      "\n",
      " Train loss: 0.0059900744818151 | Test loss: 4.9737  | Test acc: 0.7192\n",
      "\n",
      " Train loss: 0.002576432190835476 | Test loss: 4.0822  | Test acc: 0.7365\n",
      "\n",
      " Train loss: 0.0021447287872433662 | Test loss: 4.0532  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.0017746462253853679 | Test loss: 3.5847  | Test acc: 0.7388\n",
      "\n",
      " Train loss: 0.0016376117710024118 | Test loss: 3.2220  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0009419041452929378 | Test loss: 3.0846  | Test acc: 0.7583\n",
      "\n",
      " Train loss: 0.001205644104629755 | Test loss: 3.1460  | Test acc: 0.7502\n",
      "\n",
      " Train loss: 0.0009673858876340091 | Test loss: 3.4367  | Test acc: 0.7352\n",
      "\n",
      " Train loss: 0.0016367671778425574 | Test loss: 3.2117  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.0013315548421815038 | Test loss: 3.1179  | Test acc: 0.7546\n",
      "\n",
      " Train loss: 0.001553471782244742 | Test loss: 3.9610  | Test acc: 0.7219\n",
      "\n",
      " Train loss: 0.0020887143909931183 | Test loss: 4.1266  | Test acc: 0.7116\n",
      "\n",
      " Train loss: 0.0018572802655398846 | Test loss: 4.0668  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0007184976129792631 | Test loss: 3.8827  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0012093924451619387 | Test loss: 4.6178  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0011396748013794422 | Test loss: 4.8806  | Test acc: 0.6922\n",
      "\n",
      " Train loss: 0.0010301588336005807 | Test loss: 4.1682  | Test acc: 0.7052\n",
      "\n",
      " Train loss: 0.0016066096723079681 | Test loss: 3.4924  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.0024048727937042713 | Test loss: 4.6943  | Test acc: 0.7069\n",
      "\n",
      " Train loss: 0.0031433673575520515 | Test loss: 4.9982  | Test acc: 0.7130\n",
      "\n",
      " Train loss: 0.0033907252363860607 | Test loss: 4.1176  | Test acc: 0.7289\n",
      "\n",
      " Train loss: 0.0013143694959580898 | Test loss: 3.6424  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.0015755326021462679 | Test loss: 3.5758  | Test acc: 0.7605\n",
      "\n",
      " Train loss: 0.002269295509904623 | Test loss: 4.2120  | Test acc: 0.7178\n",
      "\n",
      " Train loss: 0.0016794571420177817 | Test loss: 4.6882  | Test acc: 0.6892\n",
      "\n",
      " Train loss: 0.0012472255621105433 | Test loss: 4.3496  | Test acc: 0.6829\n",
      "\n",
      " Train loss: 0.0028392698150128126 | Test loss: 3.4993  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.0013521930668503046 | Test loss: 3.5638  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.002325558103621006 | Test loss: 4.4511  | Test acc: 0.7173\n",
      "\n",
      " Train loss: 0.0022167230490595102 | Test loss: 3.5643  | Test acc: 0.7496\n",
      "\n",
      " Train loss: 0.0006274991319514811 | Test loss: 3.7354  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0009257951169274747 | Test loss: 4.3360  | Test acc: 0.6818\n",
      "\n",
      " Train loss: 0.0021138095762580633 | Test loss: 4.4410  | Test acc: 0.6922\n",
      "\n",
      " Train loss: 0.0015415288507938385 | Test loss: 4.9544  | Test acc: 0.6921\n",
      "\n",
      " Train loss: 0.002577647566795349 | Test loss: 4.1946  | Test acc: 0.7104\n",
      "\n",
      " Train loss: 0.0015227042604237795 | Test loss: 3.3454  | Test acc: 0.7515\n",
      "\n",
      " Train loss: 0.0012838720576837659 | Test loss: 3.0528  | Test acc: 0.7726\n",
      "\n",
      " Train loss: 0.001493292860686779 | Test loss: 3.2265  | Test acc: 0.7696\n",
      "\n",
      " Train loss: 0.0016278530238196254 | Test loss: 3.3031  | Test acc: 0.7539\n",
      "\n",
      " Train loss: 0.0006671228329651058 | Test loss: 3.7155  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.0012959549203515053 | Test loss: 4.1681  | Test acc: 0.7265\n",
      "\n",
      " Train loss: 0.0017567344475537539 | Test loss: 3.7129  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.0027501448057591915 | Test loss: 3.4704  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.000700673321262002 | Test loss: 3.3296  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.0012458196142688394 | Test loss: 3.5210  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.00063918880186975 | Test loss: 3.9324  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0011390080908313394 | Test loss: 4.2318  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0025627287104725838 | Test loss: 3.9624  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.005390358157455921 | Test loss: 3.1059  | Test acc: 0.7638\n",
      "\n",
      " Train loss: 0.0013200575485825539 | Test loss: 2.6000  | Test acc: 0.7753\n",
      "\n",
      " Train loss: 0.002357852179557085 | Test loss: 2.8385  | Test acc: 0.7692\n",
      "\n",
      " Train loss: 0.0006874400423839688 | Test loss: 5.0724  | Test acc: 0.6661\n",
      "\n",
      " Train loss: 0.002790511818602681 | Test loss: 3.6251  | Test acc: 0.7262\n",
      "\n",
      " Train loss: 0.001887443009763956 | Test loss: 2.9587  | Test acc: 0.7472\n",
      "\n",
      " Train loss: 0.0009985738433897495 | Test loss: 2.7420  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.004488802514970303 | Test loss: 2.6990  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.0006783125572837889 | Test loss: 3.2875  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0004810407990589738 | Test loss: 3.8339  | Test acc: 0.7107\n",
      "\n",
      " Train loss: 0.0018712376477196813 | Test loss: 3.6086  | Test acc: 0.7111\n",
      "\n",
      " Train loss: 0.0019096245523542166 | Test loss: 2.7132  | Test acc: 0.7610\n",
      "\n",
      " Train loss: 0.0008252612315118313 | Test loss: 2.5784  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0008487619925290346 | Test loss: 2.7615  | Test acc: 0.7457\n",
      "\n",
      " Train loss: 0.0013549643335863948 | Test loss: 2.9343  | Test acc: 0.7404\n",
      "\n",
      " Train loss: 0.0017670345259830356 | Test loss: 2.8998  | Test acc: 0.7488\n",
      "\n",
      " Train loss: 0.0019317902624607086 | Test loss: 2.8787  | Test acc: 0.7453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0007444201619364321 | Test loss: 3.0466  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.002362093422561884 | Test loss: 2.6654  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.0020349184051156044 | Test loss: 2.5460  | Test acc: 0.7501\n",
      "\n",
      " Train loss: 0.001531747984699905 | Test loss: 2.8184  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.0009127378580160439 | Test loss: 3.0008  | Test acc: 0.7416\n",
      "\n",
      " Train loss: 0.0010472217109054327 | Test loss: 2.8385  | Test acc: 0.7492\n",
      "\n",
      " Train loss: 0.0020064401905983686 | Test loss: 2.4951  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0005052497726865113 | Test loss: 2.4001  | Test acc: 0.7552\n",
      "\n",
      " Train loss: 0.0016293007647618651 | Test loss: 2.3343  | Test acc: 0.7577\n",
      "\n",
      " Train loss: 0.0011886326828971505 | Test loss: 2.4259  | Test acc: 0.7573\n",
      "\n",
      " Train loss: 0.00024573123664595187 | Test loss: 2.6044  | Test acc: 0.7489\n",
      "\n",
      " Train loss: 0.0018521103775128722 | Test loss: 2.5580  | Test acc: 0.7503\n",
      "\n",
      " Train loss: 0.001471285242587328 | Test loss: 3.3248  | Test acc: 0.7015\n",
      "\n",
      " Train loss: 0.002044414635747671 | Test loss: 3.9169  | Test acc: 0.6842\n",
      "\n",
      " Train loss: 0.001646641525439918 | Test loss: 3.4899  | Test acc: 0.7228\n",
      "\n",
      " Train loss: 0.0015235800528898835 | Test loss: 2.8575  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0012517959112301469 | Test loss: 2.8231  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0008991940994746983 | Test loss: 3.5221  | Test acc: 0.7119\n",
      "\n",
      " Train loss: 0.001554783433675766 | Test loss: 4.1440  | Test acc: 0.6868\n",
      "\n",
      " Train loss: 0.001519044628366828 | Test loss: 3.9961  | Test acc: 0.7007\n",
      "\n",
      " Train loss: 0.0016833343543112278 | Test loss: 2.7789  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.001342667150311172 | Test loss: 3.0241  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.0006888182833790779 | Test loss: 4.3722  | Test acc: 0.7051\n",
      "\n",
      " Train loss: 0.0014601972652599216 | Test loss: 5.2119  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.00288478028960526 | Test loss: 5.3008  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.003683591028675437 | Test loss: 4.1067  | Test acc: 0.7325\n",
      "\n",
      " Train loss: 0.0029558094684034586 | Test loss: 2.5639  | Test acc: 0.7466\n",
      "\n",
      " Train loss: 0.001306370017118752 | Test loss: 2.9790  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.00098552112467587 | Test loss: 5.4423  | Test acc: 0.6497\n",
      "\n",
      " Train loss: 0.003985550254583359 | Test loss: 5.0837  | Test acc: 0.6577\n",
      "\n",
      " Train loss: 0.002257607178762555 | Test loss: 3.3382  | Test acc: 0.6999\n",
      "\n",
      " Train loss: 0.001399586326442659 | Test loss: 2.6069  | Test acc: 0.7391\n",
      "\n",
      " Train loss: 0.0027743924874812365 | Test loss: 3.4058  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0018286141566932201 | Test loss: 4.0428  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0015132782282307744 | Test loss: 4.8328  | Test acc: 0.6760\n",
      "\n",
      " Train loss: 0.003299843752756715 | Test loss: 3.9352  | Test acc: 0.6766\n",
      "\n",
      " Train loss: 0.0009139030007645488 | Test loss: 3.8113  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.002202967880293727 | Test loss: 4.5225  | Test acc: 0.7106\n",
      "\n",
      " Train loss: 0.002827914198860526 | Test loss: 4.1752  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0024913835804909468 | Test loss: 3.9768  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0012147099478170276 | Test loss: 5.4335  | Test acc: 0.6942\n",
      "\n",
      " Train loss: 0.002568063559010625 | Test loss: 5.4617  | Test acc: 0.6847\n",
      "\n",
      " Train loss: 0.002197055844590068 | Test loss: 5.2782  | Test acc: 0.6676\n",
      "\n",
      " Train loss: 0.0011577130062505603 | Test loss: 5.9921  | Test acc: 0.6270\n",
      "\n",
      " Train loss: 0.003955046646296978 | Test loss: 4.1480  | Test acc: 0.6756\n",
      "\n",
      " Train loss: 0.001806096057407558 | Test loss: 3.2559  | Test acc: 0.7441\n",
      "\n",
      " Train loss: 0.0010795681737363338 | Test loss: 3.7750  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.0033484844025224447 | Test loss: 3.8636  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.001953954342752695 | Test loss: 3.1577  | Test acc: 0.7601\n",
      "\n",
      " Train loss: 0.002121573081240058 | Test loss: 2.4155  | Test acc: 0.7833\n",
      "\n",
      " Train loss: 0.00038364395732060075 | Test loss: 2.4906  | Test acc: 0.7779\n",
      "\n",
      " Train loss: 0.0011097743408754468 | Test loss: 2.8423  | Test acc: 0.7622\n",
      "\n",
      " Train loss: 0.002848914358764887 | Test loss: 2.8580  | Test acc: 0.7632\n",
      "\n",
      " Train loss: 0.0024734006728976965 | Test loss: 3.0405  | Test acc: 0.7477\n",
      "\n",
      " Train loss: 0.0020166165195405483 | Test loss: 3.6721  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.0005896821967326105 | Test loss: 4.2061  | Test acc: 0.6867\n",
      "\n",
      " Train loss: 0.003102558432146907 | Test loss: 4.1025  | Test acc: 0.6873\n",
      "\n",
      " Train loss: 0.002031853189691901 | Test loss: 4.5373  | Test acc: 0.6685\n",
      "\n",
      " Train loss: 0.0018513192189857364 | Test loss: 3.1024  | Test acc: 0.7370\n",
      "\n",
      " Train loss: 0.003512636525556445 | Test loss: 2.6488  | Test acc: 0.7634\n",
      "\n",
      " Train loss: 0.0002642463077791035 | Test loss: 4.2583  | Test acc: 0.6851\n",
      "\n",
      " Train loss: 0.0033157013822346926 | Test loss: 5.4079  | Test acc: 0.6714\n",
      "\n",
      " Train loss: 0.002433240879327059 | Test loss: 5.4733  | Test acc: 0.6655\n",
      "\n",
      " Train loss: 0.002066686050966382 | Test loss: 4.3815  | Test acc: 0.6720\n",
      "\n",
      " Train loss: 0.0019052043789997697 | Test loss: 3.1874  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0014873103937134147 | Test loss: 3.0703  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0006883050664328039 | Test loss: 3.2986  | Test acc: 0.7221\n",
      "\n",
      " Train loss: 0.0007903577643446624 | Test loss: 4.6162  | Test acc: 0.6990\n",
      "\n",
      " Train loss: 0.0018383190035820007 | Test loss: 5.5227  | Test acc: 0.6834\n",
      "\n",
      " Train loss: 0.0032215614337474108 | Test loss: 5.7374  | Test acc: 0.6734\n",
      "\n",
      " Train loss: 0.0034509659744799137 | Test loss: 4.5731  | Test acc: 0.7079\n",
      "\n",
      " Train loss: 0.0015049284556880593 | Test loss: 3.7134  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0029281191527843475 | Test loss: 4.0032  | Test acc: 0.7003\n",
      "\n",
      " Train loss: 0.003950650338083506 | Test loss: 3.6629  | Test acc: 0.7259\n",
      "\n",
      " Train loss: 0.0015524025075137615 | Test loss: 3.3661  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.0014422284439206123 | Test loss: 3.0556  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0021589358802884817 | Test loss: 3.3456  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.0010718991979956627 | Test loss: 3.1988  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.0020606741309165955 | Test loss: 3.2271  | Test acc: 0.7465\n",
      "\n",
      " Train loss: 0.0012666700640693307 | Test loss: 4.3427  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.0033367855940014124 | Test loss: 3.4265  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.0011791206197813153 | Test loss: 3.4171  | Test acc: 0.7312\n",
      "\n",
      " Train loss: 0.0017985759768635035 | Test loss: 3.6543  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.0011507133021950722 | Test loss: 3.8627  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.001063037314452231 | Test loss: 3.9050  | Test acc: 0.6982\n",
      "\n",
      " Train loss: 0.002089353511109948 | Test loss: 3.6976  | Test acc: 0.6921\n",
      "\n",
      " Train loss: 0.0013153085019439459 | Test loss: 3.7315  | Test acc: 0.6957\n",
      "\n",
      " Train loss: 0.0036604248452931643 | Test loss: 3.3860  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0006716637290082872 | Test loss: 3.1861  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.0012344405986368656 | Test loss: 3.1254  | Test acc: 0.7452\n",
      "\n",
      " Train loss: 0.002015588339418173 | Test loss: 3.1797  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0020010971929877996 | Test loss: 2.9995  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.0007874136790633202 | Test loss: 2.7430  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.0022778131533414125 | Test loss: 2.4762  | Test acc: 0.7543\n",
      "\n",
      " Train loss: 6.457538256654516e-05 | Test loss: 2.5648  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0003822660364676267 | Test loss: 2.8312  | Test acc: 0.7198\n",
      "\n",
      " Train loss: 0.0012685476103797555 | Test loss: 2.7833  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0027565236669033766 | Test loss: 2.5086  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.0009180096094496548 | Test loss: 2.4877  | Test acc: 0.7648\n",
      "\n",
      " Train loss: 0.0004569609882310033 | Test loss: 2.5135  | Test acc: 0.7674\n",
      "\n",
      " Train loss: 0.0009889709763228893 | Test loss: 2.7632  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.0010740263387560844 | Test loss: 3.2450  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0012627871474251151 | Test loss: 3.2040  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0005332611035555601 | Test loss: 2.5430  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.00097739533521235 | Test loss: 2.2057  | Test acc: 0.7817\n",
      "\n",
      " Train loss: 0.0009357313974760473 | Test loss: 2.4088  | Test acc: 0.7644\n",
      "\n",
      " Train loss: 0.0005946591263636947 | Test loss: 2.5257  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0017339332262054086 | Test loss: 2.3878  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.00022711511701345444 | Test loss: 2.4089  | Test acc: 0.7615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0007495225290767848 | Test loss: 2.4872  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0003281073004473001 | Test loss: 2.8506  | Test acc: 0.7403\n",
      "\n",
      " Train loss: 0.0006579263135790825 | Test loss: 3.0450  | Test acc: 0.7365\n",
      "\n",
      " Train loss: 0.0005306279635988176 | Test loss: 3.3490  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.0024579400196671486 | Test loss: 3.0734  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.0012497156858444214 | Test loss: 2.8748  | Test acc: 0.7329\n",
      "\n",
      " Train loss: 0.0010348097421228886 | Test loss: 3.2102  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0015566933434456587 | Test loss: 3.6777  | Test acc: 0.7021\n",
      "\n",
      " Train loss: 0.0010454871226102114 | Test loss: 4.3212  | Test acc: 0.6871\n",
      "\n",
      " Train loss: 0.0014511739136651158 | Test loss: 4.6192  | Test acc: 0.6734\n",
      "\n",
      " Train loss: 0.0027677142061293125 | Test loss: 2.9323  | Test acc: 0.7275\n",
      "\n",
      " Train loss: 0.002480476861819625 | Test loss: 2.2773  | Test acc: 0.7700\n",
      "\n",
      " Train loss: 0.0008523450815118849 | Test loss: 2.8037  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0014878377551212907 | Test loss: 3.3407  | Test acc: 0.7344\n",
      "\n",
      " Train loss: 0.0010795069392770529 | Test loss: 3.7815  | Test acc: 0.7057\n",
      "\n",
      " Train loss: 0.0018920324509963393 | Test loss: 4.0810  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.001116484054364264 | Test loss: 3.9059  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.0026678326539695263 | Test loss: 3.3194  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.0007702897419221699 | Test loss: 3.0611  | Test acc: 0.7401\n",
      "\n",
      " Train loss: 0.0013191300677135587 | Test loss: 3.9829  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0028029701206833124 | Test loss: 4.9544  | Test acc: 0.7065\n",
      "\n",
      " Train loss: 0.003674131352454424 | Test loss: 3.5749  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.0007394713466055691 | Test loss: 3.9766  | Test acc: 0.6741\n",
      "\n",
      " Train loss: 0.002618212718516588 | Test loss: 2.7208  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.0017574802041053772 | Test loss: 2.8106  | Test acc: 0.7227\n",
      "\n",
      " Train loss: 0.0009873665403574705 | Test loss: 3.0916  | Test acc: 0.7115\n",
      "\n",
      " Train loss: 0.001081577967852354 | Test loss: 2.9620  | Test acc: 0.7148\n",
      "\n",
      " Train loss: 0.0006111140828579664 | Test loss: 2.5722  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.000789824640378356 | Test loss: 2.5658  | Test acc: 0.7343\n",
      "\n",
      " Train loss: 0.0017432246822863817 | Test loss: 2.8331  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.001497618854045868 | Test loss: 2.8789  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.0018540092278271914 | Test loss: 2.8781  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0007552363676950336 | Test loss: 3.0614  | Test acc: 0.6992\n",
      "\n",
      " Train loss: 0.0011226583737879992 | Test loss: 2.9070  | Test acc: 0.7012\n",
      "\n",
      " Train loss: 0.0018922387389466166 | Test loss: 2.4710  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0027294328901916742 | Test loss: 2.5324  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.0015292007010430098 | Test loss: 3.8196  | Test acc: 0.6682\n",
      "\n",
      " Train loss: 0.0009841860737651587 | Test loss: 4.3684  | Test acc: 0.6582\n",
      "\n",
      " Train loss: 0.0008471936453133821 | Test loss: 4.1048  | Test acc: 0.6761\n",
      "\n",
      " Train loss: 0.0017430715961381793 | Test loss: 4.5098  | Test acc: 0.6658\n",
      "\n",
      " Train loss: 0.00228737760335207 | Test loss: 3.7614  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0026045916602015495 | Test loss: 2.4367  | Test acc: 0.7455\n",
      "\n",
      " Train loss: 0.0013283558655530214 | Test loss: 3.0009  | Test acc: 0.6926\n",
      "\n",
      " Train loss: 0.001159322913736105 | Test loss: 3.7472  | Test acc: 0.6674\n",
      "\n",
      " Train loss: 0.0015277292113751173 | Test loss: 4.1552  | Test acc: 0.6818\n",
      "\n",
      " Train loss: 0.002765926066786051 | Test loss: 4.5008  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.0016511523863300681 | Test loss: 4.6292  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.002832593861967325 | Test loss: 3.9629  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.002196436980739236 | Test loss: 3.9197  | Test acc: 0.7022\n",
      "\n",
      " Train loss: 0.0011320689227432013 | Test loss: 3.6772  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0007146606221795082 | Test loss: 4.8507  | Test acc: 0.6738\n",
      "\n",
      " Train loss: 0.0018779161619022489 | Test loss: 6.0916  | Test acc: 0.6469\n",
      "\n",
      " Train loss: 0.003668622113764286 | Test loss: 5.0382  | Test acc: 0.6884\n",
      "\n",
      " Train loss: 0.0019148074788972735 | Test loss: 4.0318  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0013279870618134737 | Test loss: 3.3441  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0011057504452764988 | Test loss: 2.5517  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0004883591318503022 | Test loss: 2.7389  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.00043809344060719013 | Test loss: 3.7518  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.0005893490742892027 | Test loss: 4.8576  | Test acc: 0.7053\n",
      "\n",
      " Train loss: 0.0030632263515144587 | Test loss: 3.9850  | Test acc: 0.7400\n",
      "\n",
      " Train loss: 0.001977877225726843 | Test loss: 2.8914  | Test acc: 0.7801\n",
      "\n",
      " Train loss: 0.0005490710609592497 | Test loss: 3.0358  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.0009010499343276024 | Test loss: 3.6282  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.0021577661391347647 | Test loss: 4.0452  | Test acc: 0.7265\n",
      "\n",
      " Train loss: 0.0015255216276273131 | Test loss: 3.8696  | Test acc: 0.7183\n",
      "\n",
      " Train loss: 0.0007414928404614329 | Test loss: 3.3943  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.002364964224398136 | Test loss: 2.9579  | Test acc: 0.7759\n",
      "\n",
      " Train loss: 0.0007704231538809836 | Test loss: 3.2430  | Test acc: 0.7709\n",
      "\n",
      " Train loss: 0.002600286854431033 | Test loss: 3.6426  | Test acc: 0.7642\n",
      "\n",
      " Train loss: 0.0014256605645641685 | Test loss: 4.0092  | Test acc: 0.7498\n",
      "\n",
      " Train loss: 0.0030299576465040445 | Test loss: 3.7994  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.0006309097516350448 | Test loss: 3.8066  | Test acc: 0.7531\n",
      "\n",
      " Train loss: 0.000807038217317313 | Test loss: 3.6275  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.001003505545668304 | Test loss: 3.4008  | Test acc: 0.7718\n",
      "\n",
      " Train loss: 0.0011549792252480984 | Test loss: 3.2985  | Test acc: 0.7715\n",
      "\n",
      " Train loss: 0.0017208793433383107 | Test loss: 3.1926  | Test acc: 0.7647\n",
      "\n",
      " Train loss: 0.0019718469120562077 | Test loss: 3.0544  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0014756275340914726 | Test loss: 2.9015  | Test acc: 0.7758\n",
      "\n",
      " Train loss: 0.0009934030240401626 | Test loss: 3.1601  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.001956547610461712 | Test loss: 2.7726  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.002139897318556905 | Test loss: 2.8013  | Test acc: 0.7694\n",
      "\n",
      " Train loss: 0.0003700507222674787 | Test loss: 3.3697  | Test acc: 0.7527\n",
      "\n",
      " Train loss: 0.0007892191642895341 | Test loss: 3.4911  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.002297620289027691 | Test loss: 3.0648  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.002228526398539543 | Test loss: 3.3388  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.0006235847249627113 | Test loss: 3.9769  | Test acc: 0.7274\n",
      "\n",
      " Train loss: 0.0028049189131706953 | Test loss: 3.8412  | Test acc: 0.7375\n",
      "\n",
      " Train loss: 0.002597959479317069 | Test loss: 2.9086  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.003061177209019661 | Test loss: 4.9400  | Test acc: 0.6570\n",
      "\n",
      " Train loss: 0.0042082141153514385 | Test loss: 4.3609  | Test acc: 0.6685\n",
      "\n",
      " Train loss: 0.002521653426811099 | Test loss: 4.4605  | Test acc: 0.7033\n",
      "\n",
      " Train loss: 0.001895242603495717 | Test loss: 4.0302  | Test acc: 0.7229\n",
      "\n",
      " Train loss: 0.0011651305248960853 | Test loss: 3.7914  | Test acc: 0.7099\n",
      "\n",
      " Train loss: 0.0013039899058640003 | Test loss: 4.0011  | Test acc: 0.6920\n",
      "\n",
      " Train loss: 0.0009532272815704346 | Test loss: 4.1727  | Test acc: 0.6842\n",
      "\n",
      " Train loss: 0.0015358757227659225 | Test loss: 3.8734  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.0007648344617336988 | Test loss: 4.2170  | Test acc: 0.7092\n",
      "\n",
      " Train loss: 0.0037682612892240286 | Test loss: 3.8353  | Test acc: 0.7200\n",
      "\n",
      " Train loss: 0.001388254575431347 | Test loss: 3.2432  | Test acc: 0.7588\n",
      "\n",
      " Train loss: 0.0023032508324831724 | Test loss: 4.0630  | Test acc: 0.7265\n",
      "\n",
      " Train loss: 0.002146915066987276 | Test loss: 5.9572  | Test acc: 0.6588\n",
      "\n",
      " Train loss: 0.0021478382404893637 | Test loss: 6.0718  | Test acc: 0.6859\n",
      "\n",
      " Train loss: 0.001657538814470172 | Test loss: 5.7786  | Test acc: 0.6833\n",
      "\n",
      " Train loss: 0.004602426663041115 | Test loss: 4.9616  | Test acc: 0.6994\n",
      "\n",
      " Train loss: 0.0017035281052812934 | Test loss: 4.4426  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.001705839647911489 | Test loss: 3.9662  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0026582602877169847 | Test loss: 3.4990  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.0019408875377848744 | Test loss: 3.7497  | Test acc: 0.7277\n",
      "\n",
      " Train loss: 0.0020718250889331102 | Test loss: 3.4035  | Test acc: 0.7395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0016868499806150794 | Test loss: 3.0656  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0011283374624326825 | Test loss: 2.8907  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0013492434518411756 | Test loss: 3.0619  | Test acc: 0.7449\n",
      "\n",
      " Train loss: 0.0021670348942279816 | Test loss: 3.2412  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0009574949508532882 | Test loss: 3.7135  | Test acc: 0.7076\n",
      "\n",
      " Train loss: 0.0018637871835380793 | Test loss: 4.1374  | Test acc: 0.6890\n",
      "\n",
      " Train loss: 0.0021366076543927193 | Test loss: 3.5316  | Test acc: 0.6931\n",
      "\n",
      " Train loss: 0.001134923193603754 | Test loss: 2.7252  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.0011458535445854068 | Test loss: 2.6152  | Test acc: 0.7463\n",
      "\n",
      " Train loss: 0.0010228801984339952 | Test loss: 2.8960  | Test acc: 0.7387\n",
      "\n",
      " Train loss: 0.0011700087925419211 | Test loss: 3.2271  | Test acc: 0.7256\n",
      "\n",
      " Train loss: 0.0008360373321920633 | Test loss: 3.7048  | Test acc: 0.7005\n",
      "\n",
      " Train loss: 0.00058068084763363 | Test loss: 5.2767  | Test acc: 0.6360\n",
      "\n",
      " Train loss: 0.0032414530869573355 | Test loss: 3.9986  | Test acc: 0.6852\n",
      "\n",
      " Train loss: 0.002673925831913948 | Test loss: 4.0772  | Test acc: 0.6713\n",
      "\n",
      " Train loss: 0.0008447976433672011 | Test loss: 3.9229  | Test acc: 0.6909\n",
      "\n",
      " Train loss: 0.0012828721664845943 | Test loss: 4.1725  | Test acc: 0.7001\n",
      "\n",
      " Train loss: 0.0024417222011834383 | Test loss: 5.3748  | Test acc: 0.6307\n",
      "\n",
      " Train loss: 0.004573164042085409 | Test loss: 3.2413  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.001997737679630518 | Test loss: 3.0479  | Test acc: 0.7548\n",
      "\n",
      " Train loss: 0.0007232145871967077 | Test loss: 3.7119  | Test acc: 0.7259\n",
      "\n",
      " Train loss: 0.0014987626345828176 | Test loss: 4.0799  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.0016460055485367775 | Test loss: 4.6405  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.0020552065689116716 | Test loss: 4.6585  | Test acc: 0.6997\n",
      "\n",
      " Train loss: 0.0010345662012696266 | Test loss: 4.0201  | Test acc: 0.7122\n",
      "\n",
      " Train loss: 0.0010202655103057623 | Test loss: 3.8979  | Test acc: 0.7152\n",
      "\n",
      " Train loss: 0.0025726964231580496 | Test loss: 4.0544  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.0009217864135280252 | Test loss: 4.3255  | Test acc: 0.7142\n",
      "\n",
      " Train loss: 0.0035573316272348166 | Test loss: 4.1173  | Test acc: 0.7301\n",
      "\n",
      " Train loss: 0.001463560969568789 | Test loss: 4.1788  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0025735809467732906 | Test loss: 4.4590  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.0017174542881548405 | Test loss: 4.8302  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0015977314906194806 | Test loss: 4.6044  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.0018455007812008262 | Test loss: 4.3332  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.0030450550839304924 | Test loss: 4.5126  | Test acc: 0.7128\n",
      "\n",
      " Train loss: 0.001049171551130712 | Test loss: 5.3536  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.003743588225916028 | Test loss: 5.0696  | Test acc: 0.6903\n",
      "\n",
      " Train loss: 0.004827924072742462 | Test loss: 4.4583  | Test acc: 0.7049\n",
      "\n",
      " Train loss: 0.0019818611908704042 | Test loss: 4.1652  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.0024054362438619137 | Test loss: 3.6040  | Test acc: 0.7350\n",
      "\n",
      " Train loss: 0.0016972750891000032 | Test loss: 4.1248  | Test acc: 0.6934\n",
      "\n",
      " Train loss: 0.0036209849640727043 | Test loss: 4.1188  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0022799810394644737 | Test loss: 4.7542  | Test acc: 0.7201\n",
      "\n",
      " Train loss: 0.0009294003248214722 | Test loss: 4.7271  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.0015696894843131304 | Test loss: 4.3757  | Test acc: 0.7472\n",
      "\n",
      " Train loss: 0.0027375880163162947 | Test loss: 4.2536  | Test acc: 0.7338\n",
      "\n",
      " Train loss: 0.0018564691999927163 | Test loss: 4.4920  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.003150555770844221 | Test loss: 3.8523  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.0017753613647073507 | Test loss: 4.1746  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.003271132940426469 | Test loss: 6.5923  | Test acc: 0.6313\n",
      "\n",
      " Train loss: 0.0027835266664624214 | Test loss: 6.8408  | Test acc: 0.6414\n",
      "\n",
      " Train loss: 0.004428633954375982 | Test loss: 8.1776  | Test acc: 0.6085\n",
      "\n",
      " Train loss: 0.006436820141971111 | Test loss: 6.5208  | Test acc: 0.6902\n",
      "\n",
      " Train loss: 0.003929438069462776 | Test loss: 5.2648  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.0026414208114147186 | Test loss: 4.5728  | Test acc: 0.7420\n",
      "\n",
      " Train loss: 0.001495502656325698 | Test loss: 5.5767  | Test acc: 0.6986\n",
      "\n",
      " Train loss: 0.0033031448256224394 | Test loss: 7.5879  | Test acc: 0.6203\n",
      "\n",
      " Train loss: 0.0027824982535094023 | Test loss: 7.8184  | Test acc: 0.6116\n",
      "\n",
      " Train loss: 0.004456635098904371 | Test loss: 5.3150  | Test acc: 0.6760\n",
      "\n",
      " Train loss: 0.005225122440606356 | Test loss: 3.4935  | Test acc: 0.7540\n",
      "\n",
      " Train loss: 0.001780090038664639 | Test loss: 4.5918  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.0024343044497072697 | Test loss: 6.0419  | Test acc: 0.6663\n",
      "\n",
      " Train loss: 0.0012898693094030023 | Test loss: 6.9715  | Test acc: 0.6174\n",
      "\n",
      " Train loss: 0.004331880249083042 | Test loss: 5.0992  | Test acc: 0.6732\n",
      "\n",
      " Train loss: 0.003139626467600465 | Test loss: 4.7582  | Test acc: 0.6700\n",
      "\n",
      " Train loss: 0.0011948419269174337 | Test loss: 4.2763  | Test acc: 0.7055\n",
      "\n",
      " Train loss: 0.0019827575888484716 | Test loss: 3.7880  | Test acc: 0.7438\n",
      "\n",
      " Train loss: 0.002729386556893587 | Test loss: 4.5343  | Test acc: 0.7159\n",
      "\n",
      " Train loss: 0.006563799921423197 | Test loss: 3.8934  | Test acc: 0.7512\n",
      "\n",
      " Train loss: 0.0010405770735815167 | Test loss: 4.7572  | Test acc: 0.7163\n",
      "\n",
      " Train loss: 0.0019803240429610014 | Test loss: 5.3819  | Test acc: 0.7072\n",
      "\n",
      " Train loss: 0.003504825057461858 | Test loss: 5.1809  | Test acc: 0.7013\n",
      "\n",
      " Train loss: 0.003774218261241913 | Test loss: 3.4793  | Test acc: 0.7727\n",
      "\n",
      " Train loss: 0.0026931853499263525 | Test loss: 3.7769  | Test acc: 0.7715\n",
      "\n",
      " Train loss: 0.002174483146518469 | Test loss: 4.0652  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0007265532622113824 | Test loss: 4.8495  | Test acc: 0.7225\n",
      "\n",
      " Train loss: 0.001275002141483128 | Test loss: 5.0322  | Test acc: 0.7057\n",
      "\n",
      " Train loss: 0.0025945398956537247 | Test loss: 4.7991  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0024969386868178844 | Test loss: 4.8584  | Test acc: 0.7207\n",
      "\n",
      " Train loss: 0.0010974709875881672 | Test loss: 5.2291  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0022117856424301863 | Test loss: 4.7664  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.00236587505787611 | Test loss: 4.7884  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.002695424249395728 | Test loss: 4.4683  | Test acc: 0.7181\n",
      "\n",
      " Train loss: 0.0018790457397699356 | Test loss: 3.7597  | Test acc: 0.7448\n",
      "\n",
      " Train loss: 0.0017196419648826122 | Test loss: 4.4555  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.002353623043745756 | Test loss: 4.6409  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.003114490071311593 | Test loss: 5.4730  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.003921417985111475 | Test loss: 6.1482  | Test acc: 0.6713\n",
      "\n",
      " Train loss: 0.004875379614531994 | Test loss: 4.4458  | Test acc: 0.7136\n",
      "\n",
      " Train loss: 0.001795646152459085 | Test loss: 4.1495  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0019125787075608969 | Test loss: 3.7516  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0013361119199544191 | Test loss: 4.1916  | Test acc: 0.7455\n",
      "\n",
      " Train loss: 0.002056477591395378 | Test loss: 4.4356  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0021666809916496277 | Test loss: 4.5311  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0015545772621408105 | Test loss: 4.9841  | Test acc: 0.7300\n",
      "\n",
      " Train loss: 0.0017311268020421267 | Test loss: 4.5718  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.0006075318669900298 | Test loss: 4.5435  | Test acc: 0.7295\n",
      "\n",
      " Train loss: 0.002812393708154559 | Test loss: 4.2238  | Test acc: 0.7396\n",
      "Looked at 25600/ 60000 samples\n",
      "\n",
      " Train loss: 0.0006251666345633566 | Test loss: 4.4568  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.002320047002285719 | Test loss: 5.0453  | Test acc: 0.7127\n",
      "\n",
      " Train loss: 0.0026901864912360907 | Test loss: 6.5148  | Test acc: 0.7085\n",
      "\n",
      " Train loss: 0.0023585548624396324 | Test loss: 9.4930  | Test acc: 0.6566\n",
      "\n",
      " Train loss: 0.003934764303267002 | Test loss: 9.1789  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.00548459030687809 | Test loss: 9.1284  | Test acc: 0.7244\n",
      "\n",
      " Train loss: 0.0018638437613844872 | Test loss: 8.6570  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.005078044719994068 | Test loss: 6.3575  | Test acc: 0.7366\n",
      "\n",
      " Train loss: 0.006231964100152254 | Test loss: 5.2397  | Test acc: 0.7076\n",
      "\n",
      " Train loss: 0.0037124003283679485 | Test loss: 6.5338  | Test acc: 0.6439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0014088077004998922 | Test loss: 7.2716  | Test acc: 0.6336\n",
      "\n",
      " Train loss: 0.0019287248142063618 | Test loss: 5.3943  | Test acc: 0.6944\n",
      "\n",
      " Train loss: 0.0017808971460908651 | Test loss: 6.1089  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.00381843326613307 | Test loss: 6.3450  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0015234503662213683 | Test loss: 6.4796  | Test acc: 0.7190\n",
      "\n",
      " Train loss: 0.0027483138255774975 | Test loss: 6.7213  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.0056058005429804325 | Test loss: 5.4768  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.003598575945943594 | Test loss: 8.0012  | Test acc: 0.6393\n",
      "\n",
      " Train loss: 0.002668088534846902 | Test loss: 7.1226  | Test acc: 0.6349\n",
      "\n",
      " Train loss: 0.002747962484136224 | Test loss: 4.2965  | Test acc: 0.7209\n",
      "\n",
      " Train loss: 0.003936574328690767 | Test loss: 4.4101  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0023622435983270407 | Test loss: 3.8230  | Test acc: 0.7553\n",
      "\n",
      " Train loss: 0.002331499243155122 | Test loss: 3.4912  | Test acc: 0.7504\n",
      "\n",
      " Train loss: 0.0036585726775228977 | Test loss: 3.4790  | Test acc: 0.7197\n",
      "\n",
      " Train loss: 0.000808830198366195 | Test loss: 5.3448  | Test acc: 0.6695\n",
      "\n",
      " Train loss: 0.002336484845727682 | Test loss: 4.9208  | Test acc: 0.6855\n",
      "\n",
      " Train loss: 0.004759207833558321 | Test loss: 4.5186  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0030270337592810392 | Test loss: 4.6717  | Test acc: 0.7189\n",
      "\n",
      " Train loss: 0.002214534441009164 | Test loss: 4.3443  | Test acc: 0.7374\n",
      "\n",
      " Train loss: 0.0020457925274968147 | Test loss: 4.7446  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.002455234294757247 | Test loss: 5.6947  | Test acc: 0.6775\n",
      "\n",
      " Train loss: 0.001543510938063264 | Test loss: 6.4281  | Test acc: 0.6457\n",
      "\n",
      " Train loss: 0.005933832842856646 | Test loss: 6.0543  | Test acc: 0.6893\n",
      "\n",
      " Train loss: 0.0028298876713961363 | Test loss: 5.2767  | Test acc: 0.7124\n",
      "\n",
      " Train loss: 0.0014306160155683756 | Test loss: 5.4012  | Test acc: 0.7131\n",
      "\n",
      " Train loss: 0.0034861683379858732 | Test loss: 6.6910  | Test acc: 0.6707\n",
      "\n",
      " Train loss: 0.003988746087998152 | Test loss: 5.2297  | Test acc: 0.7077\n",
      "\n",
      " Train loss: 0.003053714521229267 | Test loss: 4.6684  | Test acc: 0.7220\n",
      "\n",
      " Train loss: 0.003773793112486601 | Test loss: 4.7918  | Test acc: 0.7218\n",
      "\n",
      " Train loss: 0.0019382359459996223 | Test loss: 5.7803  | Test acc: 0.7050\n",
      "\n",
      " Train loss: 0.002370185451582074 | Test loss: 6.6098  | Test acc: 0.7002\n",
      "\n",
      " Train loss: 0.0019193782936781645 | Test loss: 6.5333  | Test acc: 0.6921\n",
      "\n",
      " Train loss: 0.0023011802695691586 | Test loss: 5.6336  | Test acc: 0.7144\n",
      "\n",
      " Train loss: 0.004561224021017551 | Test loss: 4.4726  | Test acc: 0.7433\n",
      "\n",
      " Train loss: 0.0006688219145871699 | Test loss: 7.5169  | Test acc: 0.6598\n",
      "\n",
      " Train loss: 0.0026484730187803507 | Test loss: 7.7912  | Test acc: 0.6512\n",
      "\n",
      " Train loss: 0.003636185545474291 | Test loss: 6.2691  | Test acc: 0.6862\n",
      "\n",
      " Train loss: 0.003703781170770526 | Test loss: 6.8277  | Test acc: 0.6836\n",
      "\n",
      " Train loss: 0.006075568031519651 | Test loss: 6.2646  | Test acc: 0.6869\n",
      "\n",
      " Train loss: 0.0027665256056934595 | Test loss: 4.5843  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.003852695692330599 | Test loss: 3.7222  | Test acc: 0.7663\n",
      "\n",
      " Train loss: 0.0005767723778262734 | Test loss: 5.2999  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.0056458692997694016 | Test loss: 5.1944  | Test acc: 0.6987\n",
      "\n",
      " Train loss: 0.0026456844061613083 | Test loss: 4.7424  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.0029834876768290997 | Test loss: 6.1692  | Test acc: 0.6761\n",
      "\n",
      " Train loss: 0.0012281148228794336 | Test loss: 5.5711  | Test acc: 0.6912\n",
      "\n",
      " Train loss: 0.0028085936792194843 | Test loss: 4.2859  | Test acc: 0.7294\n",
      "\n",
      " Train loss: 0.001855806214734912 | Test loss: 5.5722  | Test acc: 0.6881\n",
      "\n",
      " Train loss: 0.0015146455261856318 | Test loss: 6.1834  | Test acc: 0.6922\n",
      "\n",
      " Train loss: 0.0023305858485400677 | Test loss: 5.2725  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0018869556952267885 | Test loss: 3.7945  | Test acc: 0.7495\n",
      "\n",
      " Train loss: 0.0035698246210813522 | Test loss: 3.2228  | Test acc: 0.7814\n",
      "\n",
      " Train loss: 0.0010427463566884398 | Test loss: 3.3074  | Test acc: 0.7797\n",
      "\n",
      " Train loss: 0.001210273359902203 | Test loss: 3.5857  | Test acc: 0.7677\n",
      "\n",
      " Train loss: 0.0017884706612676382 | Test loss: 3.5974  | Test acc: 0.7611\n",
      "\n",
      " Train loss: 0.001278132782317698 | Test loss: 3.5867  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.001977029489353299 | Test loss: 3.7660  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0025771965738385916 | Test loss: 3.9073  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.0015280297957360744 | Test loss: 3.6600  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.0015542499022558331 | Test loss: 3.6560  | Test acc: 0.7566\n",
      "\n",
      " Train loss: 0.0006051450036466122 | Test loss: 3.9410  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0009425344178453088 | Test loss: 3.8750  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.002001931192353368 | Test loss: 3.0788  | Test acc: 0.7747\n",
      "\n",
      " Train loss: 0.0004666982567869127 | Test loss: 2.9260  | Test acc: 0.7859\n",
      "\n",
      " Train loss: 0.00183165876660496 | Test loss: 3.3747  | Test acc: 0.7668\n",
      "\n",
      " Train loss: 0.0010083353845402598 | Test loss: 4.7772  | Test acc: 0.6970\n",
      "\n",
      " Train loss: 0.001150710042566061 | Test loss: 5.3533  | Test acc: 0.6816\n",
      "\n",
      " Train loss: 0.00285200378857553 | Test loss: 4.6681  | Test acc: 0.7236\n",
      "\n",
      " Train loss: 0.0008938817190937698 | Test loss: 4.4216  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.003601091681048274 | Test loss: 4.5946  | Test acc: 0.7219\n",
      "\n",
      " Train loss: 0.0014000674709677696 | Test loss: 5.9257  | Test acc: 0.6773\n",
      "\n",
      " Train loss: 0.0005163295427337289 | Test loss: 7.3515  | Test acc: 0.6390\n",
      "\n",
      " Train loss: 0.003285676008090377 | Test loss: 6.7637  | Test acc: 0.6569\n",
      "\n",
      " Train loss: 0.004221843555569649 | Test loss: 5.3663  | Test acc: 0.7051\n",
      "\n",
      " Train loss: 0.0022524860687553883 | Test loss: 4.5950  | Test acc: 0.7066\n",
      "\n",
      " Train loss: 0.002282052766531706 | Test loss: 4.1076  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0028728109318763018 | Test loss: 5.1121  | Test acc: 0.6965\n",
      "\n",
      " Train loss: 0.0031318438705056906 | Test loss: 5.0478  | Test acc: 0.7026\n",
      "\n",
      " Train loss: 0.0014759572222828865 | Test loss: 6.1662  | Test acc: 0.6824\n",
      "\n",
      " Train loss: 0.002865280956029892 | Test loss: 4.7869  | Test acc: 0.7210\n",
      "\n",
      " Train loss: 0.004208922386169434 | Test loss: 4.8479  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.0005525480955839157 | Test loss: 5.1651  | Test acc: 0.7236\n",
      "\n",
      " Train loss: 0.002098980126902461 | Test loss: 4.6714  | Test acc: 0.7206\n",
      "\n",
      " Train loss: 0.00472897756844759 | Test loss: 3.0557  | Test acc: 0.7730\n",
      "\n",
      " Train loss: 0.0015397429233416915 | Test loss: 4.5977  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0015428818296641111 | Test loss: 7.8908  | Test acc: 0.6171\n",
      "\n",
      " Train loss: 0.004330795258283615 | Test loss: 4.6844  | Test acc: 0.6846\n",
      "\n",
      " Train loss: 0.0023958429228514433 | Test loss: 3.7816  | Test acc: 0.7032\n",
      "\n",
      " Train loss: 0.001815839670598507 | Test loss: 4.4554  | Test acc: 0.6718\n",
      "\n",
      " Train loss: 0.0024418537504971027 | Test loss: 3.9459  | Test acc: 0.7159\n",
      "\n",
      " Train loss: 0.0016765166074037552 | Test loss: 4.2020  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.002660709898918867 | Test loss: 5.1052  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.0035512237809598446 | Test loss: 4.7634  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.002955400850623846 | Test loss: 3.4300  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.00191507360432297 | Test loss: 3.0288  | Test acc: 0.7425\n",
      "\n",
      " Train loss: 0.0011831361334770918 | Test loss: 2.9876  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.001157958060503006 | Test loss: 3.5646  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.001420414075255394 | Test loss: 4.1799  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.0018165303627029061 | Test loss: 3.9963  | Test acc: 0.7396\n",
      "\n",
      " Train loss: 0.003707580966874957 | Test loss: 4.6795  | Test acc: 0.7213\n",
      "\n",
      " Train loss: 0.0022475889418274164 | Test loss: 5.0053  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.003405752358958125 | Test loss: 3.7735  | Test acc: 0.7356\n",
      "\n",
      " Train loss: 0.0012280531227588654 | Test loss: 4.5300  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0013219183310866356 | Test loss: 4.1873  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0017670452361926436 | Test loss: 3.6342  | Test acc: 0.7415\n",
      "\n",
      " Train loss: 0.0008771893917582929 | Test loss: 3.6685  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0011370821157470345 | Test loss: 3.7117  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.003436609171330929 | Test loss: 3.9157  | Test acc: 0.7476\n",
      "\n",
      " Train loss: 0.0010525534162297845 | Test loss: 5.6123  | Test acc: 0.6916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.003090924583375454 | Test loss: 4.7552  | Test acc: 0.6985\n",
      "\n",
      " Train loss: 0.0016062121139839292 | Test loss: 4.7130  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.0016618580557405949 | Test loss: 5.3661  | Test acc: 0.6770\n",
      "\n",
      " Train loss: 0.0014975087251514196 | Test loss: 8.3979  | Test acc: 0.6116\n",
      "\n",
      " Train loss: 0.004189060535281897 | Test loss: 7.4307  | Test acc: 0.6393\n",
      "\n",
      " Train loss: 0.002463196637108922 | Test loss: 5.9096  | Test acc: 0.6740\n",
      "\n",
      " Train loss: 0.0022053516004234552 | Test loss: 6.1253  | Test acc: 0.6635\n",
      "\n",
      " Train loss: 0.003546511521562934 | Test loss: 6.2195  | Test acc: 0.6656\n",
      "\n",
      " Train loss: 0.0022741747088730335 | Test loss: 6.3151  | Test acc: 0.6498\n",
      "\n",
      " Train loss: 0.0033366503193974495 | Test loss: 5.0480  | Test acc: 0.6900\n",
      "\n",
      " Train loss: 0.0003276352654211223 | Test loss: 5.3228  | Test acc: 0.6974\n",
      "\n",
      " Train loss: 0.0026065122801810503 | Test loss: 5.9886  | Test acc: 0.6855\n",
      "\n",
      " Train loss: 0.0014825956895947456 | Test loss: 5.6800  | Test acc: 0.7028\n",
      "\n",
      " Train loss: 0.001809538807719946 | Test loss: 4.9513  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.0009313470218330622 | Test loss: 4.3019  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0019973781891167164 | Test loss: 3.6098  | Test acc: 0.7750\n",
      "\n",
      " Train loss: 0.0038843476213514805 | Test loss: 3.5215  | Test acc: 0.7816\n",
      "\n",
      " Train loss: 0.0006618419429287314 | Test loss: 4.9449  | Test acc: 0.7211\n",
      "\n",
      " Train loss: 0.0012812087079510093 | Test loss: 6.1715  | Test acc: 0.6954\n",
      "\n",
      " Train loss: 0.0017607765039429069 | Test loss: 6.2380  | Test acc: 0.7015\n",
      "\n",
      " Train loss: 0.002529883524402976 | Test loss: 5.6191  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.0019710122141987085 | Test loss: 4.4819  | Test acc: 0.7471\n",
      "\n",
      " Train loss: 0.001971143065020442 | Test loss: 4.0058  | Test acc: 0.7609\n",
      "\n",
      " Train loss: 0.003361368551850319 | Test loss: 4.2834  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.0011679413728415966 | Test loss: 4.4949  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0033389644231647253 | Test loss: 4.3464  | Test acc: 0.7135\n",
      "\n",
      " Train loss: 0.0024474626407027245 | Test loss: 3.9122  | Test acc: 0.7222\n",
      "\n",
      " Train loss: 0.0026476706843823195 | Test loss: 3.8779  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.002144387923181057 | Test loss: 6.0767  | Test acc: 0.6554\n",
      "\n",
      " Train loss: 0.003699757158756256 | Test loss: 6.4700  | Test acc: 0.6988\n",
      "\n",
      " Train loss: 0.004303822759538889 | Test loss: 5.7353  | Test acc: 0.6814\n",
      "\n",
      " Train loss: 0.0024306336417794228 | Test loss: 4.1534  | Test acc: 0.7367\n",
      "\n",
      " Train loss: 0.0018637613393366337 | Test loss: 3.3742  | Test acc: 0.7661\n",
      "\n",
      " Train loss: 0.0012699236394837499 | Test loss: 3.7078  | Test acc: 0.7450\n",
      "\n",
      " Train loss: 0.0022049909457564354 | Test loss: 4.5603  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0015877143014222383 | Test loss: 4.5660  | Test acc: 0.7224\n",
      "\n",
      " Train loss: 0.0015381008852273226 | Test loss: 4.3429  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0020401915535330772 | Test loss: 4.0882  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0007286597974598408 | Test loss: 4.1026  | Test acc: 0.7508\n",
      "\n",
      " Train loss: 0.0026514814235270023 | Test loss: 3.7088  | Test acc: 0.7629\n",
      "\n",
      " Train loss: 0.0035469403956085443 | Test loss: 3.2229  | Test acc: 0.7832\n",
      "\n",
      " Train loss: 0.00096229457994923 | Test loss: 3.1130  | Test acc: 0.7871\n",
      "\n",
      " Train loss: 0.0005420611705631018 | Test loss: 3.2649  | Test acc: 0.7853\n",
      "\n",
      " Train loss: 0.0012077708961442113 | Test loss: 3.7239  | Test acc: 0.7651\n",
      "\n",
      " Train loss: 0.0044254884123802185 | Test loss: 3.7698  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.0010419536847621202 | Test loss: 4.7735  | Test acc: 0.6930\n",
      "\n",
      " Train loss: 0.003446691669523716 | Test loss: 4.9013  | Test acc: 0.6788\n",
      "\n",
      " Train loss: 0.005430217832326889 | Test loss: 3.4789  | Test acc: 0.7330\n",
      "\n",
      " Train loss: 0.0009084854973480105 | Test loss: 3.3453  | Test acc: 0.7256\n",
      "\n",
      " Train loss: 0.0033189381938427687 | Test loss: 3.9325  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.0037625764962285757 | Test loss: 4.2228  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.0020736849401146173 | Test loss: 4.6807  | Test acc: 0.6987\n",
      "\n",
      " Train loss: 0.0013538184575736523 | Test loss: 5.4257  | Test acc: 0.6443\n",
      "\n",
      " Train loss: 0.0022617296781390905 | Test loss: 3.7166  | Test acc: 0.7073\n",
      "\n",
      " Train loss: 0.00043148809345439076 | Test loss: 3.7192  | Test acc: 0.7103\n",
      "\n",
      " Train loss: 0.0028868485242128372 | Test loss: 3.9438  | Test acc: 0.6856\n",
      "\n",
      " Train loss: 0.002390139503404498 | Test loss: 3.5766  | Test acc: 0.6997\n",
      "\n",
      " Train loss: 0.0017893752083182335 | Test loss: 3.6190  | Test acc: 0.7124\n",
      "\n",
      " Train loss: 0.0009451652877032757 | Test loss: 4.7957  | Test acc: 0.6524\n",
      "\n",
      " Train loss: 0.003059003036469221 | Test loss: 4.3716  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.001783102285116911 | Test loss: 4.1186  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0012849047780036926 | Test loss: 4.7430  | Test acc: 0.6780\n",
      "\n",
      " Train loss: 0.00253275060094893 | Test loss: 3.3663  | Test acc: 0.7297\n",
      "\n",
      " Train loss: 0.0009864361491054296 | Test loss: 5.3137  | Test acc: 0.6757\n",
      "\n",
      " Train loss: 0.00227729813195765 | Test loss: 7.5970  | Test acc: 0.6292\n",
      "\n",
      " Train loss: 0.0025223097763955593 | Test loss: 6.9731  | Test acc: 0.6488\n",
      "\n",
      " Train loss: 0.0030826195143163204 | Test loss: 4.9564  | Test acc: 0.7088\n",
      "\n",
      " Train loss: 0.00631882157176733 | Test loss: 3.0121  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.006300207693129778 | Test loss: 3.9329  | Test acc: 0.7212\n",
      "\n",
      " Train loss: 0.001548044616356492 | Test loss: 6.2702  | Test acc: 0.6422\n",
      "\n",
      " Train loss: 0.002505700569599867 | Test loss: 8.1055  | Test acc: 0.5754\n",
      "\n",
      " Train loss: 0.0028228815644979477 | Test loss: 7.4539  | Test acc: 0.6239\n",
      "\n",
      " Train loss: 0.004370403476059437 | Test loss: 8.6411  | Test acc: 0.6094\n",
      "\n",
      " Train loss: 0.0038861569482833147 | Test loss: 7.5384  | Test acc: 0.6738\n",
      "\n",
      " Train loss: 0.0037662771064788103 | Test loss: 6.3101  | Test acc: 0.6612\n",
      "\n",
      " Train loss: 0.0033535396214574575 | Test loss: 5.5798  | Test acc: 0.6905\n",
      "\n",
      " Train loss: 0.002149442909285426 | Test loss: 5.4899  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.006392437964677811 | Test loss: 5.4505  | Test acc: 0.6975\n",
      "\n",
      " Train loss: 0.0020754472352564335 | Test loss: 6.8512  | Test acc: 0.6733\n",
      "\n",
      " Train loss: 0.0014796695904806256 | Test loss: 7.6529  | Test acc: 0.6636\n",
      "\n",
      " Train loss: 0.0020892720203846693 | Test loss: 6.4466  | Test acc: 0.6872\n",
      "\n",
      " Train loss: 0.0026640098076313734 | Test loss: 5.7604  | Test acc: 0.6894\n",
      "\n",
      " Train loss: 0.003259472083300352 | Test loss: 7.3271  | Test acc: 0.6486\n",
      "\n",
      " Train loss: 0.002267644042149186 | Test loss: 8.1507  | Test acc: 0.6568\n",
      "\n",
      " Train loss: 0.006542644929140806 | Test loss: 4.7200  | Test acc: 0.7158\n",
      "\n",
      " Train loss: 0.0012390444753691554 | Test loss: 7.6031  | Test acc: 0.7061\n",
      "\n",
      " Train loss: 0.004962509032338858 | Test loss: 9.6100  | Test acc: 0.7093\n",
      "\n",
      " Train loss: 0.0029991352930665016 | Test loss: 10.3105  | Test acc: 0.7096\n",
      "\n",
      " Train loss: 0.00321787572465837 | Test loss: 10.5350  | Test acc: 0.6928\n",
      "\n",
      " Train loss: 0.010314904153347015 | Test loss: 8.6344  | Test acc: 0.6940\n",
      "\n",
      " Train loss: 0.003711660858243704 | Test loss: 7.1670  | Test acc: 0.6698\n",
      "\n",
      " Train loss: 0.0030412159394472837 | Test loss: 8.4238  | Test acc: 0.6094\n",
      "\n",
      " Train loss: 0.003147826064378023 | Test loss: 9.4507  | Test acc: 0.6275\n",
      "\n",
      " Train loss: 0.0025793996173888445 | Test loss: 8.2554  | Test acc: 0.6442\n",
      "\n",
      " Train loss: 0.006135540083050728 | Test loss: 6.7191  | Test acc: 0.6875\n",
      "\n",
      " Train loss: 0.0033846839796751738 | Test loss: 8.7938  | Test acc: 0.6433\n",
      "\n",
      " Train loss: 0.005941401701420546 | Test loss: 9.3479  | Test acc: 0.6359\n",
      "\n",
      " Train loss: 0.004677597898989916 | Test loss: 9.1085  | Test acc: 0.6451\n",
      "\n",
      " Train loss: 0.007242035586386919 | Test loss: 9.5960  | Test acc: 0.6577\n",
      "\n",
      " Train loss: 0.005768815986812115 | Test loss: 6.8500  | Test acc: 0.6705\n",
      "\n",
      " Train loss: 0.0028002599719911814 | Test loss: 6.7313  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.00664923619478941 | Test loss: 7.7287  | Test acc: 0.6850\n",
      "\n",
      " Train loss: 0.004789894446730614 | Test loss: 7.8016  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.005830666981637478 | Test loss: 6.9728  | Test acc: 0.7217\n",
      "\n",
      " Train loss: 0.004179053939878941 | Test loss: 6.8544  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.00439081434160471 | Test loss: 6.4301  | Test acc: 0.7214\n",
      "\n",
      " Train loss: 0.00372175476513803 | Test loss: 5.6568  | Test acc: 0.7270\n",
      "\n",
      " Train loss: 0.0005853618495166302 | Test loss: 8.0018  | Test acc: 0.6421\n",
      "\n",
      " Train loss: 0.0030690443236380816 | Test loss: 9.4197  | Test acc: 0.6465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.005768331699073315 | Test loss: 6.1956  | Test acc: 0.7090\n",
      "\n",
      " Train loss: 0.002929562935605645 | Test loss: 9.1877  | Test acc: 0.6628\n",
      "\n",
      " Train loss: 0.00794826541095972 | Test loss: 7.8565  | Test acc: 0.6847\n",
      "\n",
      " Train loss: 0.005060585681349039 | Test loss: 7.4121  | Test acc: 0.7175\n",
      "\n",
      " Train loss: 0.0024133867118507624 | Test loss: 7.5729  | Test acc: 0.7170\n",
      "\n",
      " Train loss: 0.0008687273948453367 | Test loss: 7.9813  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.00670248968526721 | Test loss: 8.5121  | Test acc: 0.6772\n",
      "\n",
      " Train loss: 0.009905711747705936 | Test loss: 7.9627  | Test acc: 0.6864\n",
      "\n",
      " Train loss: 0.005297019146382809 | Test loss: 8.8055  | Test acc: 0.6945\n",
      "\n",
      " Train loss: 0.0017730758991092443 | Test loss: 13.5018  | Test acc: 0.6291\n",
      "\n",
      " Train loss: 0.009011659771203995 | Test loss: 11.8687  | Test acc: 0.6465\n",
      "\n",
      " Train loss: 0.0037124690134078264 | Test loss: 8.6898  | Test acc: 0.6706\n",
      "\n",
      " Train loss: 0.0059706768952310085 | Test loss: 7.8328  | Test acc: 0.6873\n",
      "\n",
      " Train loss: 0.0024563558399677277 | Test loss: 8.1991  | Test acc: 0.6792\n",
      "\n",
      " Train loss: 0.008671765215694904 | Test loss: 7.3219  | Test acc: 0.7270\n",
      "\n",
      " Train loss: 0.0034192921593785286 | Test loss: 10.8288  | Test acc: 0.6719\n",
      "\n",
      " Train loss: 0.005955593194812536 | Test loss: 13.5920  | Test acc: 0.6300\n",
      "\n",
      " Train loss: 0.007823161780834198 | Test loss: 17.9407  | Test acc: 0.5758\n",
      "\n",
      " Train loss: 0.007895251736044884 | Test loss: 9.8594  | Test acc: 0.6791\n",
      "\n",
      " Train loss: 0.005841264966875315 | Test loss: 7.5598  | Test acc: 0.7077\n",
      "\n",
      " Train loss: 0.0028450870886445045 | Test loss: 11.7295  | Test acc: 0.6400\n",
      "\n",
      " Train loss: 0.004621922969818115 | Test loss: 12.1074  | Test acc: 0.6366\n",
      "\n",
      " Train loss: 0.004965340252965689 | Test loss: 9.8467  | Test acc: 0.6724\n",
      "\n",
      " Train loss: 0.004359138663858175 | Test loss: 9.6540  | Test acc: 0.6815\n",
      "\n",
      " Train loss: 0.0036265708040446043 | Test loss: 8.8686  | Test acc: 0.6887\n",
      "\n",
      " Train loss: 0.005610588006675243 | Test loss: 7.5099  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0038089039735496044 | Test loss: 9.0691  | Test acc: 0.6411\n",
      "\n",
      " Train loss: 0.002157098613679409 | Test loss: 10.0050  | Test acc: 0.6221\n",
      "\n",
      " Train loss: 0.0085897920653224 | Test loss: 8.2431  | Test acc: 0.6966\n",
      "\n",
      " Train loss: 0.0039412472397089005 | Test loss: 7.9001  | Test acc: 0.7209\n",
      "\n",
      " Train loss: 0.003985525108873844 | Test loss: 8.5069  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.0033936528488993645 | Test loss: 11.4344  | Test acc: 0.6672\n",
      "\n",
      " Train loss: 0.0033650295808911324 | Test loss: 13.9548  | Test acc: 0.6343\n",
      "\n",
      " Train loss: 0.00957492645829916 | Test loss: 9.3823  | Test acc: 0.6767\n",
      "\n",
      " Train loss: 0.00218901876360178 | Test loss: 6.4115  | Test acc: 0.7304\n",
      "\n",
      " Train loss: 0.003583693178370595 | Test loss: 5.5672  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0006329454481601715 | Test loss: 7.6894  | Test acc: 0.7030\n",
      "\n",
      " Train loss: 0.00511131901293993 | Test loss: 6.9274  | Test acc: 0.7046\n",
      "\n",
      " Train loss: 0.00346183218061924 | Test loss: 7.2913  | Test acc: 0.6824\n",
      "\n",
      " Train loss: 0.005464873742312193 | Test loss: 6.4757  | Test acc: 0.7024\n",
      "\n",
      " Train loss: 0.005124466028064489 | Test loss: 5.7519  | Test acc: 0.7058\n",
      "\n",
      " Train loss: 0.006972648669034243 | Test loss: 4.7966  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0029319555032998323 | Test loss: 4.9648  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.004479466937482357 | Test loss: 4.9103  | Test acc: 0.7477\n",
      "\n",
      " Train loss: 0.0008411676972173154 | Test loss: 5.2844  | Test acc: 0.7341\n",
      "\n",
      " Train loss: 0.0019922826904803514 | Test loss: 5.5517  | Test acc: 0.7146\n",
      "\n",
      " Train loss: 0.0016336679691448808 | Test loss: 6.2612  | Test acc: 0.6998\n",
      "\n",
      " Train loss: 0.0025172994937747717 | Test loss: 5.9813  | Test acc: 0.7012\n",
      "\n",
      " Train loss: 0.0031599414069205523 | Test loss: 6.0396  | Test acc: 0.6963\n",
      "\n",
      " Train loss: 0.0029705711640417576 | Test loss: 5.7988  | Test acc: 0.6995\n",
      "\n",
      " Train loss: 0.004979653283953667 | Test loss: 4.9587  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.001987861469388008 | Test loss: 7.7784  | Test acc: 0.6741\n",
      "\n",
      " Train loss: 0.007238707039505243 | Test loss: 5.1911  | Test acc: 0.7353\n",
      "\n",
      " Train loss: 0.0032739234156906605 | Test loss: 5.9321  | Test acc: 0.7155\n",
      "\n",
      " Train loss: 0.004894421901553869 | Test loss: 6.5376  | Test acc: 0.7082\n",
      "\n",
      " Train loss: 0.006320048123598099 | Test loss: 6.2905  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.0018504951149225235 | Test loss: 5.9449  | Test acc: 0.7218\n",
      "\n",
      " Train loss: 0.002191761042922735 | Test loss: 6.3730  | Test acc: 0.6902\n",
      "\n",
      " Train loss: 0.0013467874377965927 | Test loss: 6.8100  | Test acc: 0.6762\n",
      "\n",
      " Train loss: 0.004183951765298843 | Test loss: 5.0869  | Test acc: 0.7217\n",
      "\n",
      " Train loss: 0.001205573440529406 | Test loss: 4.3958  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0015607877867296338 | Test loss: 5.2830  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.003386454191058874 | Test loss: 6.6077  | Test acc: 0.7025\n",
      "\n",
      " Train loss: 0.0028778582345694304 | Test loss: 7.7445  | Test acc: 0.6659\n",
      "\n",
      " Train loss: 0.003958915360271931 | Test loss: 6.3086  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.004971690941601992 | Test loss: 4.4464  | Test acc: 0.7411\n",
      "\n",
      " Train loss: 0.0013804241316393018 | Test loss: 5.4139  | Test acc: 0.6850\n",
      "\n",
      " Train loss: 0.004204216413199902 | Test loss: 6.3398  | Test acc: 0.6729\n",
      "\n",
      " Train loss: 0.003982538357377052 | Test loss: 6.6180  | Test acc: 0.6696\n",
      "\n",
      " Train loss: 0.00315101514570415 | Test loss: 5.6983  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.005051668267697096 | Test loss: 5.2041  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.001466725836507976 | Test loss: 4.4776  | Test acc: 0.7562\n",
      "\n",
      " Train loss: 0.0022859100718051195 | Test loss: 4.4709  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0025296767707914114 | Test loss: 4.1860  | Test acc: 0.7791\n",
      "\n",
      " Train loss: 0.0012291802559047937 | Test loss: 4.4362  | Test acc: 0.7791\n",
      "\n",
      " Train loss: 0.0031339304987341166 | Test loss: 4.4700  | Test acc: 0.7719\n",
      "\n",
      " Train loss: 0.0011349788401275873 | Test loss: 4.4226  | Test acc: 0.7674\n",
      "\n",
      " Train loss: 0.002305559581145644 | Test loss: 4.0902  | Test acc: 0.7710\n",
      "\n",
      " Train loss: 0.004436030518263578 | Test loss: 4.8252  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.0021905580069869757 | Test loss: 7.5752  | Test acc: 0.7278\n",
      "\n",
      " Train loss: 0.008958677761256695 | Test loss: 5.4932  | Test acc: 0.7492\n",
      "\n",
      " Train loss: 0.002510312246158719 | Test loss: 4.1246  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0027090441435575485 | Test loss: 6.5131  | Test acc: 0.7141\n",
      "\n",
      " Train loss: 0.00493896147236228 | Test loss: 7.6442  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.007084457203745842 | Test loss: 5.9147  | Test acc: 0.7263\n",
      "\n",
      " Train loss: 0.0035457550548017025 | Test loss: 5.0556  | Test acc: 0.7321\n",
      "\n",
      " Train loss: 0.006339287851005793 | Test loss: 5.8483  | Test acc: 0.7070\n",
      "\n",
      " Train loss: 0.0038656818214803934 | Test loss: 6.0351  | Test acc: 0.6932\n",
      "\n",
      " Train loss: 0.0031956287566572428 | Test loss: 5.6840  | Test acc: 0.6932\n",
      "\n",
      " Train loss: 0.004081215243786573 | Test loss: 4.2885  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0008436347707174718 | Test loss: 6.4004  | Test acc: 0.6816\n",
      "\n",
      " Train loss: 0.004775909706950188 | Test loss: 5.8468  | Test acc: 0.6941\n",
      "\n",
      " Train loss: 0.003551691770553589 | Test loss: 6.1913  | Test acc: 0.6661\n",
      "\n",
      " Train loss: 0.002995065413415432 | Test loss: 6.0464  | Test acc: 0.6891\n",
      "\n",
      " Train loss: 0.002043008105829358 | Test loss: 6.3441  | Test acc: 0.6971\n",
      "\n",
      " Train loss: 0.0015956417191773653 | Test loss: 6.0483  | Test acc: 0.6927\n",
      "\n",
      " Train loss: 0.0014910956379026175 | Test loss: 5.0901  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0020720118191093206 | Test loss: 8.7441  | Test acc: 0.5963\n",
      "\n",
      " Train loss: 0.004336205776780844 | Test loss: 12.6408  | Test acc: 0.5568\n",
      "\n",
      " Train loss: 0.005724658723920584 | Test loss: 9.1763  | Test acc: 0.6248\n",
      "\n",
      " Train loss: 0.003266121493652463 | Test loss: 7.4294  | Test acc: 0.6642\n",
      "\n",
      " Train loss: 0.003555592382326722 | Test loss: 8.8398  | Test acc: 0.6935\n",
      "\n",
      " Train loss: 0.000919793383218348 | Test loss: 12.4014  | Test acc: 0.6579\n",
      "\n",
      " Train loss: 0.007600774988532066 | Test loss: 11.8644  | Test acc: 0.6364\n",
      "\n",
      " Train loss: 0.007971116341650486 | Test loss: 10.4196  | Test acc: 0.6252\n",
      "\n",
      " Train loss: 0.0037663013208657503 | Test loss: 8.3364  | Test acc: 0.6359\n",
      "\n",
      " Train loss: 0.0039010499604046345 | Test loss: 6.1139  | Test acc: 0.6922\n",
      "\n",
      " Train loss: 0.002385911764577031 | Test loss: 6.3653  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0011540452251210809 | Test loss: 5.9947  | Test acc: 0.7296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0033081925939768553 | Test loss: 5.0252  | Test acc: 0.7644\n",
      "\n",
      " Train loss: 0.001705573289655149 | Test loss: 5.4910  | Test acc: 0.7505\n",
      "\n",
      " Train loss: 0.0022033550776541233 | Test loss: 6.5448  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.0017741629853844643 | Test loss: 7.5070  | Test acc: 0.6927\n",
      "\n",
      " Train loss: 0.00388780958019197 | Test loss: 7.9678  | Test acc: 0.6966\n",
      "\n",
      " Train loss: 0.006903663277626038 | Test loss: 8.9654  | Test acc: 0.6779\n",
      "\n",
      " Train loss: 0.003775048768147826 | Test loss: 9.8410  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.006053604185581207 | Test loss: 8.8153  | Test acc: 0.7077\n",
      "\n",
      " Train loss: 0.005966152995824814 | Test loss: 7.7624  | Test acc: 0.7239\n",
      "\n",
      " Train loss: 0.00818675011396408 | Test loss: 6.6319  | Test acc: 0.7249\n",
      "\n",
      " Train loss: 0.0009777493542060256 | Test loss: 10.4478  | Test acc: 0.6711\n",
      "\n",
      " Train loss: 0.005997008178383112 | Test loss: 11.3375  | Test acc: 0.6455\n",
      "\n",
      " Train loss: 0.00947888195514679 | Test loss: 9.6482  | Test acc: 0.6772\n",
      "\n",
      " Train loss: 0.0010327183408662677 | Test loss: 8.1130  | Test acc: 0.7004\n",
      "\n",
      " Train loss: 0.004096122924238443 | Test loss: 6.2598  | Test acc: 0.7320\n",
      "\n",
      " Train loss: 0.0021768552251160145 | Test loss: 7.6577  | Test acc: 0.7273\n",
      "\n",
      " Train loss: 0.00486571853980422 | Test loss: 7.1843  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.0017443287651985884 | Test loss: 6.6667  | Test acc: 0.7280\n",
      "\n",
      " Train loss: 0.0017199236899614334 | Test loss: 6.3802  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.002368577755987644 | Test loss: 6.9280  | Test acc: 0.7099\n",
      "\n",
      " Train loss: 0.004079695791006088 | Test loss: 7.8848  | Test acc: 0.6729\n",
      "\n",
      " Train loss: 0.00441701291128993 | Test loss: 8.2060  | Test acc: 0.6604\n",
      "\n",
      " Train loss: 0.00434504821896553 | Test loss: 8.2790  | Test acc: 0.6616\n",
      "\n",
      " Train loss: 0.005196420010179281 | Test loss: 5.9342  | Test acc: 0.7094\n",
      "\n",
      " Train loss: 0.0046141366474330425 | Test loss: 5.9035  | Test acc: 0.7164\n",
      "\n",
      " Train loss: 0.0022308852057904005 | Test loss: 8.4323  | Test acc: 0.6750\n",
      "\n",
      " Train loss: 0.007522876374423504 | Test loss: 5.5461  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0018996235448867083 | Test loss: 4.7463  | Test acc: 0.7699\n",
      "\n",
      " Train loss: 0.002985261846333742 | Test loss: 4.7505  | Test acc: 0.7619\n",
      "\n",
      " Train loss: 0.004061827436089516 | Test loss: 5.6894  | Test acc: 0.7382\n",
      "\n",
      " Train loss: 0.0030129721853882074 | Test loss: 6.5566  | Test acc: 0.7056\n",
      "\n",
      " Train loss: 0.003545473562553525 | Test loss: 7.5182  | Test acc: 0.6644\n",
      "\n",
      " Train loss: 0.0013675502268597484 | Test loss: 7.8507  | Test acc: 0.6594\n",
      "\n",
      " Train loss: 0.005165488459169865 | Test loss: 8.1394  | Test acc: 0.6543\n",
      "\n",
      " Train loss: 0.005190825555473566 | Test loss: 7.6641  | Test acc: 0.6721\n",
      "\n",
      " Train loss: 0.005654287524521351 | Test loss: 4.7246  | Test acc: 0.7713\n",
      "\n",
      " Train loss: 0.0015204742085188627 | Test loss: 5.2020  | Test acc: 0.7650\n",
      "\n",
      " Train loss: 0.0026740585453808308 | Test loss: 6.0057  | Test acc: 0.7524\n",
      "\n",
      " Train loss: 0.003237849334254861 | Test loss: 6.2932  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0019134038593620062 | Test loss: 6.4088  | Test acc: 0.7199\n",
      "\n",
      " Train loss: 0.003525193314999342 | Test loss: 5.8497  | Test acc: 0.7309\n",
      "\n",
      " Train loss: 0.0038819757755845785 | Test loss: 5.8862  | Test acc: 0.7228\n",
      "\n",
      " Train loss: 0.0022152571473270655 | Test loss: 6.2928  | Test acc: 0.7148\n",
      "\n",
      " Train loss: 0.004949488677084446 | Test loss: 6.0004  | Test acc: 0.7246\n",
      "\n",
      " Train loss: 0.0015835193917155266 | Test loss: 5.5678  | Test acc: 0.7432\n",
      "\n",
      " Train loss: 0.005086035002022982 | Test loss: 4.8221  | Test acc: 0.7696\n",
      "\n",
      " Train loss: 0.003747998969629407 | Test loss: 4.6253  | Test acc: 0.7691\n",
      "\n",
      " Train loss: 0.001639199093915522 | Test loss: 4.5212  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0033429679460823536 | Test loss: 4.6800  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0018555899150669575 | Test loss: 4.8989  | Test acc: 0.7331\n",
      "\n",
      " Train loss: 0.003498911391943693 | Test loss: 4.9630  | Test acc: 0.7386\n",
      "\n",
      " Train loss: 0.0032069245353341103 | Test loss: 4.0939  | Test acc: 0.7638\n",
      "\n",
      " Train loss: 0.002786817029118538 | Test loss: 4.4229  | Test acc: 0.7473\n",
      "\n",
      " Train loss: 0.004941919352859259 | Test loss: 4.2102  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0029723020270466805 | Test loss: 4.1300  | Test acc: 0.7486\n",
      "\n",
      " Train loss: 0.0019039951730519533 | Test loss: 4.2686  | Test acc: 0.7381\n",
      "\n",
      " Train loss: 0.0022616335190832615 | Test loss: 4.4239  | Test acc: 0.7285\n",
      "\n",
      " Train loss: 0.0019632470794022083 | Test loss: 4.2579  | Test acc: 0.7327\n",
      "\n",
      " Train loss: 0.0008652139804325998 | Test loss: 4.1809  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0006735437782481313 | Test loss: 4.2830  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.002721005817875266 | Test loss: 4.1861  | Test acc: 0.7468\n",
      "\n",
      " Train loss: 0.001178519451059401 | Test loss: 3.8447  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.0014679593732580543 | Test loss: 3.9390  | Test acc: 0.7581\n",
      "Looked at 38400/ 60000 samples\n",
      "\n",
      " Train loss: 0.0020889032166451216 | Test loss: 4.0921  | Test acc: 0.7595\n",
      "\n",
      " Train loss: 0.0008646981441415846 | Test loss: 5.1748  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.0033159868326038122 | Test loss: 5.5627  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.002279966836795211 | Test loss: 4.2535  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0015518440632149577 | Test loss: 3.5980  | Test acc: 0.7707\n",
      "\n",
      " Train loss: 0.0019520384958013892 | Test loss: 4.2126  | Test acc: 0.7596\n",
      "\n",
      " Train loss: 0.0014805782120674849 | Test loss: 4.7822  | Test acc: 0.7458\n",
      "\n",
      " Train loss: 0.002511905739083886 | Test loss: 4.9278  | Test acc: 0.7456\n",
      "\n",
      " Train loss: 0.001684121903963387 | Test loss: 4.4327  | Test acc: 0.7522\n",
      "\n",
      " Train loss: 0.0025082693900913 | Test loss: 3.7772  | Test acc: 0.7560\n",
      "\n",
      " Train loss: 0.0028708740137517452 | Test loss: 3.6858  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.0022179014049470425 | Test loss: 3.3450  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.0015861504944041371 | Test loss: 3.6406  | Test acc: 0.7526\n",
      "\n",
      " Train loss: 0.0024606199003756046 | Test loss: 3.4780  | Test acc: 0.7655\n",
      "\n",
      " Train loss: 0.002401954960078001 | Test loss: 3.9747  | Test acc: 0.7557\n",
      "\n",
      " Train loss: 0.0013312899973243475 | Test loss: 4.4487  | Test acc: 0.7368\n",
      "\n",
      " Train loss: 0.002874880563467741 | Test loss: 4.0811  | Test acc: 0.7463\n",
      "\n",
      " Train loss: 0.001946322270669043 | Test loss: 3.7844  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.0013463052455335855 | Test loss: 3.7071  | Test acc: 0.7271\n",
      "\n",
      " Train loss: 0.001834140275605023 | Test loss: 3.7838  | Test acc: 0.7121\n",
      "\n",
      " Train loss: 0.001884960918687284 | Test loss: 3.7777  | Test acc: 0.7106\n",
      "\n",
      " Train loss: 0.0015121803153306246 | Test loss: 3.2293  | Test acc: 0.7379\n",
      "\n",
      " Train loss: 0.0024097671266645193 | Test loss: 2.8412  | Test acc: 0.7691\n",
      "\n",
      " Train loss: 0.0004721658769994974 | Test loss: 3.0126  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0004761636082548648 | Test loss: 3.9527  | Test acc: 0.7362\n",
      "\n",
      " Train loss: 0.003502277424558997 | Test loss: 3.4668  | Test acc: 0.7693\n",
      "\n",
      " Train loss: 0.002422917168587446 | Test loss: 3.6723  | Test acc: 0.7582\n",
      "\n",
      " Train loss: 0.0015331568429246545 | Test loss: 4.0218  | Test acc: 0.7447\n",
      "\n",
      " Train loss: 0.0017098435200750828 | Test loss: 3.7113  | Test acc: 0.7642\n",
      "\n",
      " Train loss: 0.0013595360796898603 | Test loss: 3.8093  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.002105732448399067 | Test loss: 3.9488  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0014276161091402173 | Test loss: 3.7596  | Test acc: 0.7341\n",
      "\n",
      " Train loss: 0.0014710566028952599 | Test loss: 3.3369  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0010164373088628054 | Test loss: 3.0214  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.0016790347872301936 | Test loss: 2.8510  | Test acc: 0.7487\n",
      "\n",
      " Train loss: 0.0013814487028867006 | Test loss: 3.1594  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0007694672676734626 | Test loss: 4.4218  | Test acc: 0.7172\n",
      "\n",
      " Train loss: 0.0034767272882163525 | Test loss: 5.5328  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.00406912574544549 | Test loss: 4.2871  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0032757422886788845 | Test loss: 3.7179  | Test acc: 0.7162\n",
      "\n",
      " Train loss: 0.0008136502001434565 | Test loss: 3.5367  | Test acc: 0.7283\n",
      "\n",
      " Train loss: 0.0017941953847184777 | Test loss: 3.5893  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0014250414678826928 | Test loss: 3.8288  | Test acc: 0.7131\n",
      "\n",
      " Train loss: 0.002532334066927433 | Test loss: 3.3276  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0019229744793847203 | Test loss: 3.2078  | Test acc: 0.7362\n",
      "\n",
      " Train loss: 0.0013893510913476348 | Test loss: 3.7111  | Test acc: 0.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.002008225070312619 | Test loss: 3.8733  | Test acc: 0.6906\n",
      "\n",
      " Train loss: 0.0012385303853079677 | Test loss: 2.9489  | Test acc: 0.7552\n",
      "\n",
      " Train loss: 0.0021617216989398003 | Test loss: 2.7187  | Test acc: 0.7757\n",
      "\n",
      " Train loss: 0.000407065381295979 | Test loss: 3.1385  | Test acc: 0.7604\n",
      "\n",
      " Train loss: 0.0009030732908286154 | Test loss: 3.7766  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.0008588015916757286 | Test loss: 4.1884  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0033177966251969337 | Test loss: 3.5202  | Test acc: 0.7583\n",
      "\n",
      " Train loss: 0.002182477619498968 | Test loss: 3.6944  | Test acc: 0.7535\n",
      "\n",
      " Train loss: 0.0016731363721191883 | Test loss: 4.3632  | Test acc: 0.7202\n",
      "\n",
      " Train loss: 0.0020255574490875006 | Test loss: 4.9505  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.004576385021209717 | Test loss: 4.3002  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.004071833100169897 | Test loss: 3.5092  | Test acc: 0.7397\n",
      "\n",
      " Train loss: 0.0014105940936133265 | Test loss: 3.0037  | Test acc: 0.7625\n",
      "\n",
      " Train loss: 0.0015053723473101854 | Test loss: 3.1212  | Test acc: 0.7707\n",
      "\n",
      " Train loss: 0.0019035163568332791 | Test loss: 4.0332  | Test acc: 0.7517\n",
      "\n",
      " Train loss: 0.004169821739196777 | Test loss: 4.9613  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.0034597155172377825 | Test loss: 3.7446  | Test acc: 0.7341\n",
      "\n",
      " Train loss: 0.002385214902460575 | Test loss: 3.3375  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.0026222816668450832 | Test loss: 3.4647  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.0015574365388602018 | Test loss: 3.6889  | Test acc: 0.6922\n",
      "\n",
      " Train loss: 0.0014766308013349771 | Test loss: 4.0355  | Test acc: 0.6699\n",
      "\n",
      " Train loss: 0.0019741274882107973 | Test loss: 3.6083  | Test acc: 0.6813\n",
      "\n",
      " Train loss: 0.002346218330785632 | Test loss: 3.1833  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0007731560617685318 | Test loss: 3.7995  | Test acc: 0.7019\n",
      "\n",
      " Train loss: 0.0010464363731443882 | Test loss: 4.2489  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.001079026609659195 | Test loss: 3.9997  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.0024863716680556536 | Test loss: 2.9864  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.0007167958538047969 | Test loss: 4.2486  | Test acc: 0.7083\n",
      "\n",
      " Train loss: 0.002900815801694989 | Test loss: 5.3427  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.0019504663068801165 | Test loss: 6.1349  | Test acc: 0.6554\n",
      "\n",
      " Train loss: 0.004237678833305836 | Test loss: 5.6292  | Test acc: 0.6557\n",
      "\n",
      " Train loss: 0.002499560359865427 | Test loss: 4.0367  | Test acc: 0.7151\n",
      "\n",
      " Train loss: 0.002044295659288764 | Test loss: 2.9952  | Test acc: 0.7710\n",
      "\n",
      " Train loss: 0.0009441031725145876 | Test loss: 3.4526  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.002150630811229348 | Test loss: 4.1467  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.0037914563436061144 | Test loss: 3.8718  | Test acc: 0.7266\n",
      "\n",
      " Train loss: 0.0015225791139528155 | Test loss: 2.9592  | Test acc: 0.7547\n",
      "\n",
      " Train loss: 0.0022467784583568573 | Test loss: 2.9389  | Test acc: 0.7439\n",
      "\n",
      " Train loss: 0.001201156759634614 | Test loss: 4.0036  | Test acc: 0.6911\n",
      "\n",
      " Train loss: 0.00380582083016634 | Test loss: 3.5949  | Test acc: 0.7288\n",
      "\n",
      " Train loss: 0.0020575367379933596 | Test loss: 3.5899  | Test acc: 0.7440\n",
      "\n",
      " Train loss: 0.0005978578119538724 | Test loss: 3.6409  | Test acc: 0.7473\n",
      "\n",
      " Train loss: 0.001608070102520287 | Test loss: 3.1177  | Test acc: 0.7705\n",
      "\n",
      " Train loss: 0.0010834969580173492 | Test loss: 3.4062  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.0005400960799306631 | Test loss: 4.4470  | Test acc: 0.6937\n",
      "\n",
      " Train loss: 0.0017191212391480803 | Test loss: 4.0261  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.002303814049810171 | Test loss: 3.4975  | Test acc: 0.7281\n",
      "\n",
      " Train loss: 0.001866701990365982 | Test loss: 3.5699  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.0017920115496963263 | Test loss: 2.9102  | Test acc: 0.7590\n",
      "\n",
      " Train loss: 0.0008053260971792042 | Test loss: 2.9485  | Test acc: 0.7673\n",
      "\n",
      " Train loss: 0.0006735495408065617 | Test loss: 3.2882  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.001716239028610289 | Test loss: 3.2133  | Test acc: 0.7603\n",
      "\n",
      " Train loss: 0.0010167122818529606 | Test loss: 2.8370  | Test acc: 0.7817\n",
      "\n",
      " Train loss: 0.0029616698157042265 | Test loss: 2.6215  | Test acc: 0.7879\n",
      "\n",
      " Train loss: 0.0012739549856632948 | Test loss: 3.0240  | Test acc: 0.7398\n",
      "\n",
      " Train loss: 0.001197582227177918 | Test loss: 3.2867  | Test acc: 0.7191\n",
      "\n",
      " Train loss: 0.0013900297926738858 | Test loss: 3.1431  | Test acc: 0.7257\n",
      "\n",
      " Train loss: 0.0011613531969487667 | Test loss: 2.8422  | Test acc: 0.7390\n",
      "\n",
      " Train loss: 0.002548067830502987 | Test loss: 2.6068  | Test acc: 0.7746\n",
      "\n",
      " Train loss: 0.00039447200833819807 | Test loss: 2.7575  | Test acc: 0.7855\n",
      "\n",
      " Train loss: 0.0008459272794425488 | Test loss: 3.0506  | Test acc: 0.7738\n",
      "\n",
      " Train loss: 0.0008210036321543157 | Test loss: 3.2153  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0014436990022659302 | Test loss: 3.1871  | Test acc: 0.7490\n",
      "\n",
      " Train loss: 0.0018038928974419832 | Test loss: 2.3657  | Test acc: 0.7824\n",
      "\n",
      " Train loss: 0.0006830028141848743 | Test loss: 2.2901  | Test acc: 0.7861\n",
      "\n",
      " Train loss: 0.0008296738378703594 | Test loss: 2.8009  | Test acc: 0.7414\n",
      "\n",
      " Train loss: 0.0006828668992966413 | Test loss: 3.5629  | Test acc: 0.6984\n",
      "\n",
      " Train loss: 0.0004927482805214822 | Test loss: 4.3307  | Test acc: 0.6710\n",
      "\n",
      " Train loss: 0.003519655205309391 | Test loss: 3.7669  | Test acc: 0.7087\n",
      "\n",
      " Train loss: 0.0005563946324400604 | Test loss: 3.4549  | Test acc: 0.7336\n",
      "\n",
      " Train loss: 0.0009719845838844776 | Test loss: 3.2322  | Test acc: 0.7613\n",
      "\n",
      " Train loss: 0.0016171687748283148 | Test loss: 2.8933  | Test acc: 0.7783\n",
      "\n",
      " Train loss: 0.0013261294225230813 | Test loss: 2.8602  | Test acc: 0.7768\n",
      "\n",
      " Train loss: 0.0011440097587183118 | Test loss: 3.2573  | Test acc: 0.7565\n",
      "\n",
      " Train loss: 0.0033611732069402933 | Test loss: 3.4898  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.001716695143841207 | Test loss: 3.7700  | Test acc: 0.7232\n",
      "\n",
      " Train loss: 0.001024196040816605 | Test loss: 3.7470  | Test acc: 0.7190\n",
      "\n",
      " Train loss: 0.0007834261050447822 | Test loss: 3.6057  | Test acc: 0.7166\n",
      "\n",
      " Train loss: 0.0031035072170197964 | Test loss: 3.2227  | Test acc: 0.7362\n",
      "\n",
      " Train loss: 0.00041105164564214647 | Test loss: 2.8488  | Test acc: 0.7579\n",
      "\n",
      " Train loss: 0.0021622772328555584 | Test loss: 2.4810  | Test acc: 0.7838\n",
      "\n",
      " Train loss: 0.0010198882082477212 | Test loss: 2.3937  | Test acc: 0.7846\n",
      "\n",
      " Train loss: 0.0016297362744808197 | Test loss: 2.4216  | Test acc: 0.7771\n",
      "\n",
      " Train loss: 0.00128645240329206 | Test loss: 2.5134  | Test acc: 0.7640\n",
      "\n",
      " Train loss: 0.0011553921503946185 | Test loss: 2.5811  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.0004038028127979487 | Test loss: 2.6719  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0006622994551435113 | Test loss: 2.7682  | Test acc: 0.7299\n",
      "\n",
      " Train loss: 0.0034785957541316748 | Test loss: 2.5474  | Test acc: 0.7444\n",
      "\n",
      " Train loss: 0.0011124353623017669 | Test loss: 2.3980  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.00040201746742241085 | Test loss: 2.3008  | Test acc: 0.7662\n",
      "\n",
      " Train loss: 0.0009022748563438654 | Test loss: 2.2468  | Test acc: 0.7687\n",
      "\n",
      " Train loss: 0.00115692347753793 | Test loss: 2.2920  | Test acc: 0.7620\n",
      "\n",
      " Train loss: 0.00032449018908664584 | Test loss: 2.6508  | Test acc: 0.7306\n",
      "\n",
      " Train loss: 0.0013010635739192367 | Test loss: 3.0953  | Test acc: 0.7018\n",
      "\n",
      " Train loss: 0.002469279570505023 | Test loss: 3.2911  | Test acc: 0.7029\n",
      "\n",
      " Train loss: 0.0016270979540422559 | Test loss: 3.2077  | Test acc: 0.7023\n",
      "\n",
      " Train loss: 0.001073440071195364 | Test loss: 2.6116  | Test acc: 0.7479\n",
      "\n",
      " Train loss: 0.0018896363908424973 | Test loss: 2.1870  | Test acc: 0.7799\n",
      "\n",
      " Train loss: 0.0010773047106340528 | Test loss: 2.2588  | Test acc: 0.7735\n",
      "\n",
      " Train loss: 0.001317454967647791 | Test loss: 2.4275  | Test acc: 0.7532\n",
      "\n",
      " Train loss: 0.0005329407285898924 | Test loss: 2.6427  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.0012811832129955292 | Test loss: 2.6434  | Test acc: 0.7216\n",
      "\n",
      " Train loss: 0.0007256772951222956 | Test loss: 2.3698  | Test acc: 0.7395\n",
      "\n",
      " Train loss: 0.001157146762125194 | Test loss: 2.2779  | Test acc: 0.7413\n",
      "\n",
      " Train loss: 0.0011642648605629802 | Test loss: 2.1595  | Test acc: 0.7589\n",
      "\n",
      " Train loss: 0.0017955584917217493 | Test loss: 2.1802  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0013012378476560116 | Test loss: 2.1172  | Test acc: 0.7690\n",
      "\n",
      " Train loss: 0.0010485418606549501 | Test loss: 2.0966  | Test acc: 0.7794\n",
      "\n",
      " Train loss: 0.0008179169381037354 | Test loss: 2.1890  | Test acc: 0.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.0010148024884983897 | Test loss: 2.4134  | Test acc: 0.7603\n",
      "\n",
      " Train loss: 0.0005841573583893478 | Test loss: 2.2903  | Test acc: 0.7646\n",
      "\n",
      " Train loss: 0.0009411919745616615 | Test loss: 2.0848  | Test acc: 0.7892\n",
      "\n",
      " Train loss: 0.0005168439820408821 | Test loss: 2.1320  | Test acc: 0.7914\n",
      "\n",
      " Train loss: 0.0009722924442030489 | Test loss: 2.4036  | Test acc: 0.7681\n",
      "\n",
      " Train loss: 0.0006133098504506052 | Test loss: 2.4751  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0014359911438077688 | Test loss: 2.5881  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0013320186408236623 | Test loss: 2.4949  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0016328847268596292 | Test loss: 2.4473  | Test acc: 0.7722\n",
      "\n",
      " Train loss: 0.0015083764446899295 | Test loss: 2.2422  | Test acc: 0.7785\n",
      "\n",
      " Train loss: 0.0016330125508829951 | Test loss: 2.1499  | Test acc: 0.7785\n",
      "\n",
      " Train loss: 0.000806673604529351 | Test loss: 2.5125  | Test acc: 0.7482\n",
      "\n",
      " Train loss: 0.0015802370617166162 | Test loss: 3.0077  | Test acc: 0.7072\n",
      "\n",
      " Train loss: 0.0008340904023498297 | Test loss: 2.8654  | Test acc: 0.7253\n",
      "\n",
      " Train loss: 0.0011071974877268076 | Test loss: 2.5733  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.0018495219992473722 | Test loss: 2.1884  | Test acc: 0.7671\n",
      "\n",
      " Train loss: 0.0011817743070423603 | Test loss: 2.2404  | Test acc: 0.7581\n",
      "\n",
      " Train loss: 0.0008322327048517764 | Test loss: 2.4103  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0035829630214720964 | Test loss: 2.3970  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.0031663072295486927 | Test loss: 2.3230  | Test acc: 0.7516\n",
      "\n",
      " Train loss: 0.0007467380492016673 | Test loss: 2.8797  | Test acc: 0.7138\n",
      "\n",
      " Train loss: 0.0010180026292800903 | Test loss: 3.9014  | Test acc: 0.6720\n",
      "\n",
      " Train loss: 0.001493785995990038 | Test loss: 4.3652  | Test acc: 0.6791\n",
      "\n",
      " Train loss: 0.0031813676469027996 | Test loss: 4.3065  | Test acc: 0.6780\n",
      "\n",
      " Train loss: 0.0021583708003163338 | Test loss: 3.8758  | Test acc: 0.6898\n",
      "\n",
      " Train loss: 0.001686280476860702 | Test loss: 3.0314  | Test acc: 0.7118\n",
      "\n",
      " Train loss: 0.0012999734608456492 | Test loss: 2.0280  | Test acc: 0.7464\n",
      "\n",
      " Train loss: 0.0016940180212259293 | Test loss: 2.8479  | Test acc: 0.7023\n",
      "\n",
      " Train loss: 0.002506328746676445 | Test loss: 3.7169  | Test acc: 0.6846\n",
      "\n",
      " Train loss: 0.003616705536842346 | Test loss: 3.2250  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0016552007291465998 | Test loss: 2.3672  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0011816485784947872 | Test loss: 2.4731  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.0008692133706063032 | Test loss: 3.0358  | Test acc: 0.7168\n",
      "\n",
      " Train loss: 0.0012213035952299833 | Test loss: 2.9456  | Test acc: 0.7105\n",
      "\n",
      " Train loss: 0.000843441637698561 | Test loss: 2.7690  | Test acc: 0.7177\n",
      "\n",
      " Train loss: 0.0004078748170286417 | Test loss: 3.4340  | Test acc: 0.7076\n",
      "\n",
      " Train loss: 0.0031467073131352663 | Test loss: 3.7790  | Test acc: 0.7126\n",
      "\n",
      " Train loss: 0.001232276437804103 | Test loss: 3.8826  | Test acc: 0.7223\n",
      "\n",
      " Train loss: 0.0004893375444225967 | Test loss: 3.4134  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0011665286729112267 | Test loss: 2.5330  | Test acc: 0.7531\n",
      "\n",
      " Train loss: 0.0024282748345285654 | Test loss: 2.2166  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0013933576410636306 | Test loss: 2.9422  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0024937575217336416 | Test loss: 3.3003  | Test acc: 0.7047\n",
      "\n",
      " Train loss: 0.0023613842204213142 | Test loss: 2.4183  | Test acc: 0.7416\n",
      "\n",
      " Train loss: 0.0011987792095169425 | Test loss: 1.9202  | Test acc: 0.7782\n",
      "\n",
      " Train loss: 0.001013889443129301 | Test loss: 2.5256  | Test acc: 0.7557\n",
      "\n",
      " Train loss: 0.0010951963486149907 | Test loss: 3.0374  | Test acc: 0.7357\n",
      "\n",
      " Train loss: 0.0020995894446969032 | Test loss: 2.6269  | Test acc: 0.7364\n",
      "\n",
      " Train loss: 0.0011219085427001119 | Test loss: 2.5362  | Test acc: 0.7099\n",
      "\n",
      " Train loss: 0.0031500475015491247 | Test loss: 2.2716  | Test acc: 0.7345\n",
      "\n",
      " Train loss: 0.0007862000493332744 | Test loss: 2.4315  | Test acc: 0.7377\n",
      "\n",
      " Train loss: 0.0005956536042504013 | Test loss: 2.6484  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0012236962793394923 | Test loss: 2.4818  | Test acc: 0.7298\n",
      "\n",
      " Train loss: 0.0016947300173342228 | Test loss: 2.4260  | Test acc: 0.7316\n",
      "\n",
      " Train loss: 0.0013521581422537565 | Test loss: 2.8091  | Test acc: 0.6840\n",
      "\n",
      " Train loss: 0.001592152868397534 | Test loss: 2.8235  | Test acc: 0.6803\n",
      "\n",
      " Train loss: 0.00133115379139781 | Test loss: 3.1646  | Test acc: 0.6726\n",
      "\n",
      " Train loss: 0.0018946821801364422 | Test loss: 3.2064  | Test acc: 0.6689\n",
      "\n",
      " Train loss: 0.001030202955007553 | Test loss: 2.7882  | Test acc: 0.6940\n",
      "\n",
      " Train loss: 0.0013510641874745488 | Test loss: 2.4687  | Test acc: 0.7409\n",
      "\n",
      " Train loss: 0.0010328764328733087 | Test loss: 2.6643  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.001567457802593708 | Test loss: 3.1707  | Test acc: 0.7436\n",
      "\n",
      " Train loss: 0.0016150482697412372 | Test loss: 3.4643  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.001742896856740117 | Test loss: 2.8836  | Test acc: 0.7781\n",
      "\n",
      " Train loss: 0.0008085052249953151 | Test loss: 2.7544  | Test acc: 0.7740\n",
      "\n",
      " Train loss: 0.0018986278446391225 | Test loss: 2.9379  | Test acc: 0.7471\n",
      "\n",
      " Train loss: 0.001152362092398107 | Test loss: 3.5184  | Test acc: 0.7135\n",
      "\n",
      " Train loss: 0.0012018578127026558 | Test loss: 3.7635  | Test acc: 0.6884\n",
      "\n",
      " Train loss: 0.0006962409825064242 | Test loss: 3.7960  | Test acc: 0.6855\n",
      "\n",
      " Train loss: 0.0022580495569854975 | Test loss: 3.8617  | Test acc: 0.6935\n",
      "\n",
      " Train loss: 0.0015560424653813243 | Test loss: 3.5225  | Test acc: 0.7282\n",
      "\n",
      " Train loss: 0.0009882464073598385 | Test loss: 3.1824  | Test acc: 0.7598\n",
      "\n",
      " Train loss: 0.001247149659320712 | Test loss: 3.1072  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0015119249001145363 | Test loss: 3.6351  | Test acc: 0.7422\n",
      "\n",
      " Train loss: 0.0017329456750303507 | Test loss: 3.8307  | Test acc: 0.7307\n",
      "\n",
      " Train loss: 0.0003854740352835506 | Test loss: 3.9056  | Test acc: 0.7311\n",
      "\n",
      " Train loss: 0.0005734449368901551 | Test loss: 3.7270  | Test acc: 0.7443\n",
      "\n",
      " Train loss: 0.002050482202321291 | Test loss: 3.4295  | Test acc: 0.7571\n",
      "\n",
      " Train loss: 0.0022554672323167324 | Test loss: 3.1025  | Test acc: 0.7696\n",
      "\n",
      " Train loss: 0.001636932953260839 | Test loss: 3.1476  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.0017776060849428177 | Test loss: 3.3496  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0009608045220375061 | Test loss: 3.4809  | Test acc: 0.7410\n",
      "\n",
      " Train loss: 0.0007002015481702983 | Test loss: 3.1236  | Test acc: 0.7523\n",
      "\n",
      " Train loss: 0.000710998778231442 | Test loss: 2.6531  | Test acc: 0.7699\n",
      "\n",
      " Train loss: 0.0011070104083046317 | Test loss: 2.7154  | Test acc: 0.7599\n",
      "\n",
      " Train loss: 0.0010128093417733908 | Test loss: 3.2376  | Test acc: 0.7308\n",
      "\n",
      " Train loss: 0.0014825077960267663 | Test loss: 3.8223  | Test acc: 0.6987\n",
      "\n",
      " Train loss: 0.0009790194453671575 | Test loss: 4.3256  | Test acc: 0.6826\n",
      "\n",
      " Train loss: 0.0021087219938635826 | Test loss: 2.9601  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.002245203359052539 | Test loss: 2.3604  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.00015076952695380896 | Test loss: 2.2794  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0007084307726472616 | Test loss: 2.3700  | Test acc: 0.7451\n",
      "\n",
      " Train loss: 0.00032705042394809425 | Test loss: 2.4249  | Test acc: 0.7404\n",
      "\n",
      " Train loss: 0.001030157320201397 | Test loss: 2.7193  | Test acc: 0.7242\n",
      "\n",
      " Train loss: 0.0012724371626973152 | Test loss: 2.2616  | Test acc: 0.7592\n",
      "\n",
      " Train loss: 0.0008283944916911423 | Test loss: 2.2988  | Test acc: 0.7725\n",
      "\n",
      " Train loss: 0.001138270366936922 | Test loss: 2.7575  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0018370128236711025 | Test loss: 2.5164  | Test acc: 0.7651\n",
      "\n",
      " Train loss: 0.0022652707993984222 | Test loss: 2.2255  | Test acc: 0.7740\n",
      "\n",
      " Train loss: 0.002160165226086974 | Test loss: 2.1277  | Test acc: 0.7563\n",
      "\n",
      " Train loss: 0.0008858551736921072 | Test loss: 2.7438  | Test acc: 0.7150\n",
      "\n",
      " Train loss: 0.0011806593975052238 | Test loss: 3.3741  | Test acc: 0.7020\n",
      "\n",
      " Train loss: 0.0021551374811679125 | Test loss: 3.2509  | Test acc: 0.7279\n",
      "\n",
      " Train loss: 0.0010720425052568316 | Test loss: 3.1297  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0012934657279402018 | Test loss: 3.0370  | Test acc: 0.7134\n",
      "\n",
      " Train loss: 0.0007199526880867779 | Test loss: 2.3387  | Test acc: 0.7316\n",
      "\n",
      " Train loss: 0.0011187156196683645 | Test loss: 2.3803  | Test acc: 0.7285\n",
      "\n",
      " Train loss: 0.0007580212550237775 | Test loss: 3.4979  | Test acc: 0.6915\n",
      "\n",
      " Train loss: 0.0016257502138614655 | Test loss: 3.5736  | Test acc: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.000837511382997036 | Test loss: 2.7992  | Test acc: 0.7284\n",
      "\n",
      " Train loss: 0.0009120096219703555 | Test loss: 2.3585  | Test acc: 0.7459\n",
      "\n",
      " Train loss: 0.0013887080131098628 | Test loss: 2.4466  | Test acc: 0.7529\n",
      "\n",
      " Train loss: 0.001603439450263977 | Test loss: 2.5631  | Test acc: 0.7462\n",
      "\n",
      " Train loss: 0.0005305758095346391 | Test loss: 2.2996  | Test acc: 0.7544\n",
      "\n",
      " Train loss: 0.0010254812659695745 | Test loss: 2.1469  | Test acc: 0.7677\n",
      "\n",
      " Train loss: 0.0002186503552366048 | Test loss: 2.2495  | Test acc: 0.7667\n",
      "\n",
      " Train loss: 0.0008709253743290901 | Test loss: 2.3404  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0008329615811817348 | Test loss: 2.3232  | Test acc: 0.7579\n",
      "\n",
      " Train loss: 0.0005858722724951804 | Test loss: 2.1281  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.0008444517734460533 | Test loss: 2.0070  | Test acc: 0.7494\n",
      "\n",
      " Train loss: 0.0007614256464876235 | Test loss: 2.2885  | Test acc: 0.7122\n",
      "\n",
      " Train loss: 0.0008976350072771311 | Test loss: 2.4375  | Test acc: 0.6956\n",
      "\n",
      " Train loss: 0.000638703175354749 | Test loss: 2.4621  | Test acc: 0.6896\n",
      "\n",
      " Train loss: 0.0012873030500486493 | Test loss: 2.3965  | Test acc: 0.6959\n",
      "\n",
      " Train loss: 0.001274185604415834 | Test loss: 1.9830  | Test acc: 0.7363\n",
      "\n",
      " Train loss: 0.0020488877780735493 | Test loss: 1.8275  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.0007738005369901657 | Test loss: 1.8955  | Test acc: 0.7648\n",
      "\n",
      " Train loss: 0.0004213706124573946 | Test loss: 1.9568  | Test acc: 0.7757\n",
      "\n",
      " Train loss: 0.0006793590146116912 | Test loss: 2.1468  | Test acc: 0.7711\n",
      "\n",
      " Train loss: 0.0015242071822285652 | Test loss: 2.2228  | Test acc: 0.7658\n",
      "\n",
      " Train loss: 0.0008574026869609952 | Test loss: 2.1419  | Test acc: 0.7656\n",
      "\n",
      " Train loss: 0.0004245465970598161 | Test loss: 2.2628  | Test acc: 0.7545\n",
      "\n",
      " Train loss: 0.0012499659787863493 | Test loss: 2.3587  | Test acc: 0.7489\n",
      "\n",
      " Train loss: 0.0006123131606727839 | Test loss: 2.3210  | Test acc: 0.7534\n",
      "\n",
      " Train loss: 0.0003161598287988454 | Test loss: 2.2180  | Test acc: 0.7627\n",
      "\n",
      " Train loss: 0.001445982838049531 | Test loss: 2.1685  | Test acc: 0.7643\n",
      "\n",
      " Train loss: 0.001761562773026526 | Test loss: 2.0205  | Test acc: 0.7793\n",
      "\n",
      " Train loss: 0.0004767006612382829 | Test loss: 1.9919  | Test acc: 0.7810\n",
      "\n",
      " Train loss: 0.0015265352558344603 | Test loss: 1.9691  | Test acc: 0.7797\n",
      "\n",
      " Train loss: 0.00027280228096060455 | Test loss: 1.9493  | Test acc: 0.7800\n",
      "\n",
      " Train loss: 0.00011935967631870881 | Test loss: 2.0212  | Test acc: 0.7798\n",
      "\n",
      " Train loss: 0.0007724390015937388 | Test loss: 1.9768  | Test acc: 0.7797\n",
      "\n",
      " Train loss: 0.0009515537531115115 | Test loss: 2.2520  | Test acc: 0.7585\n",
      "\n",
      " Train loss: 0.001142157125286758 | Test loss: 2.4828  | Test acc: 0.7434\n",
      "\n",
      " Train loss: 0.0007186410366557539 | Test loss: 2.5599  | Test acc: 0.7355\n",
      "\n",
      " Train loss: 0.0007121567614376545 | Test loss: 2.1657  | Test acc: 0.7653\n",
      "\n",
      " Train loss: 0.0008943769498728216 | Test loss: 1.9903  | Test acc: 0.7790\n",
      "\n",
      " Train loss: 0.0002699485048651695 | Test loss: 1.9746  | Test acc: 0.7752\n",
      "\n",
      " Train loss: 0.0003528290835674852 | Test loss: 2.1030  | Test acc: 0.7617\n",
      "\n",
      " Train loss: 0.0005439840606413782 | Test loss: 2.5081  | Test acc: 0.7239\n",
      "\n",
      " Train loss: 0.002102689351886511 | Test loss: 2.5324  | Test acc: 0.7185\n",
      "\n",
      " Train loss: 0.000939112389460206 | Test loss: 2.3831  | Test acc: 0.7264\n",
      "\n",
      " Train loss: 0.00022052356507629156 | Test loss: 2.3479  | Test acc: 0.7342\n",
      "\n",
      " Train loss: 0.0014328655088320374 | Test loss: 2.2843  | Test acc: 0.7515\n",
      "\n",
      " Train loss: 0.0005561469006352127 | Test loss: 2.4240  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0020196610130369663 | Test loss: 2.4905  | Test acc: 0.7486\n",
      "\n",
      " Train loss: 0.001004498451948166 | Test loss: 2.5413  | Test acc: 0.7511\n",
      "\n",
      " Train loss: 0.0016982440138235688 | Test loss: 2.2223  | Test acc: 0.7745\n",
      "\n",
      " Train loss: 0.0005600223666988313 | Test loss: 2.0773  | Test acc: 0.7769\n",
      "\n",
      " Train loss: 0.0006496481946669519 | Test loss: 1.9522  | Test acc: 0.7821\n",
      "\n",
      " Train loss: 0.0022079520858824253 | Test loss: 1.8408  | Test acc: 0.7764\n",
      "\n",
      " Train loss: 0.0007255821255967021 | Test loss: 1.8930  | Test acc: 0.7711\n",
      "\n",
      " Train loss: 0.0008336060564033687 | Test loss: 2.2379  | Test acc: 0.7478\n",
      "\n",
      " Train loss: 0.0014389704447239637 | Test loss: 2.5102  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.0006802150164730847 | Test loss: 3.1705  | Test acc: 0.6874\n",
      "\n",
      " Train loss: 0.0017174736130982637 | Test loss: 3.0564  | Test acc: 0.6948\n",
      "\n",
      " Train loss: 0.002022366039454937 | Test loss: 2.2801  | Test acc: 0.7415\n",
      "\n",
      " Train loss: 0.0005018135998398066 | Test loss: 1.8627  | Test acc: 0.7674\n",
      "\n",
      " Train loss: 0.0006447263294830918 | Test loss: 1.8928  | Test acc: 0.7570\n",
      "\n",
      " Train loss: 0.003068465506657958 | Test loss: 1.7928  | Test acc: 0.7520\n",
      "\n",
      " Train loss: 0.0007339341100305319 | Test loss: 1.9730  | Test acc: 0.7233\n",
      "\n",
      " Train loss: 0.0010030169505625963 | Test loss: 2.0486  | Test acc: 0.7317\n",
      "\n",
      " Train loss: 0.000541890796739608 | Test loss: 2.1794  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0013351388042792678 | Test loss: 2.0775  | Test acc: 0.7261\n",
      "\n",
      " Train loss: 0.000935114047024399 | Test loss: 1.7802  | Test acc: 0.7698\n",
      "\n",
      " Train loss: 0.0004708251217380166 | Test loss: 1.6425  | Test acc: 0.7941\n",
      "\n",
      " Train loss: 0.0006584431976079941 | Test loss: 1.7427  | Test acc: 0.7893\n",
      "\n",
      " Train loss: 0.0006878632120788097 | Test loss: 2.0319  | Test acc: 0.7574\n",
      "\n",
      " Train loss: 0.0006104127387516201 | Test loss: 2.6370  | Test acc: 0.7147\n",
      "\n",
      " Train loss: 0.0006191427237354219 | Test loss: 3.1335  | Test acc: 0.6883\n",
      "\n",
      " Train loss: 0.000638951372820884 | Test loss: 3.2735  | Test acc: 0.6853\n",
      "\n",
      " Train loss: 0.0011368293780833483 | Test loss: 2.5944  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.001283738180063665 | Test loss: 2.2492  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0012496141716837883 | Test loss: 2.0507  | Test acc: 0.7748\n",
      "\n",
      " Train loss: 0.0007441134075634181 | Test loss: 2.1673  | Test acc: 0.7882\n",
      "\n",
      " Train loss: 0.0005154156242497265 | Test loss: 2.5554  | Test acc: 0.7743\n",
      "\n",
      " Train loss: 0.0019410735694691539 | Test loss: 2.3796  | Test acc: 0.7786\n",
      "\n",
      " Train loss: 0.0004361038445495069 | Test loss: 2.3257  | Test acc: 0.7801\n",
      "\n",
      " Train loss: 0.0004332381358835846 | Test loss: 2.7287  | Test acc: 0.7417\n",
      "\n",
      " Train loss: 0.0016828849911689758 | Test loss: 3.0646  | Test acc: 0.7293\n",
      "\n",
      " Train loss: 0.0008781658834777772 | Test loss: 2.4810  | Test acc: 0.7536\n",
      "\n",
      " Train loss: 5.047307786298916e-05 | Test loss: 2.1309  | Test acc: 0.7728\n",
      "\n",
      " Train loss: 0.0004862468922510743 | Test loss: 1.9075  | Test acc: 0.7946\n",
      "\n",
      " Train loss: 0.0004847995878662914 | Test loss: 1.8716  | Test acc: 0.8034\n",
      "\n",
      " Train loss: 0.000991517212241888 | Test loss: 2.0340  | Test acc: 0.7907\n",
      "\n",
      " Train loss: 0.0014395139878615737 | Test loss: 2.2440  | Test acc: 0.7771\n",
      "\n",
      " Train loss: 0.0012437383411452174 | Test loss: 2.2970  | Test acc: 0.7708\n",
      "\n",
      " Train loss: 0.0002569412754382938 | Test loss: 2.2688  | Test acc: 0.7674\n",
      "\n",
      " Train loss: 0.0007164711132645607 | Test loss: 2.1420  | Test acc: 0.7750\n",
      "\n",
      " Train loss: 0.00046033289982005954 | Test loss: 2.0648  | Test acc: 0.7806\n",
      "\n",
      " Train loss: 0.0014180495636537671 | Test loss: 2.0685  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0010481217177584767 | Test loss: 2.1760  | Test acc: 0.7613\n",
      "\n",
      " Train loss: 0.00024784321431070566 | Test loss: 2.2643  | Test acc: 0.7602\n",
      "\n",
      " Train loss: 0.001015517977066338 | Test loss: 2.5092  | Test acc: 0.7525\n",
      "\n",
      " Train loss: 0.0010470368433743715 | Test loss: 3.1610  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.001967111136764288 | Test loss: 3.0196  | Test acc: 0.7332\n",
      "\n",
      " Train loss: 0.001958864275366068 | Test loss: 2.9238  | Test acc: 0.7371\n",
      "\n",
      " Train loss: 0.000711423868779093 | Test loss: 2.5725  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0006892989040352404 | Test loss: 2.0848  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0014688874362036586 | Test loss: 1.9349  | Test acc: 0.7825\n",
      "\n",
      " Train loss: 0.0008067062008194625 | Test loss: 2.1076  | Test acc: 0.7683\n",
      "\n",
      " Train loss: 0.0005927043384872377 | Test loss: 2.4772  | Test acc: 0.7420\n",
      "\n",
      " Train loss: 0.0007907435647211969 | Test loss: 2.6631  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.002923248801380396 | Test loss: 2.3755  | Test acc: 0.7641\n",
      "\n",
      " Train loss: 0.0020813695155084133 | Test loss: 2.1855  | Test acc: 0.7737\n",
      "\n",
      " Train loss: 0.0009649903513491154 | Test loss: 2.1620  | Test acc: 0.7684\n",
      "\n",
      " Train loss: 0.0010264343582093716 | Test loss: 2.1619  | Test acc: 0.7669\n",
      "\n",
      " Train loss: 0.0009051004308275878 | Test loss: 2.0730  | Test acc: 0.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.00045476394006982446 | Test loss: 1.9361  | Test acc: 0.7824\n",
      "\n",
      " Train loss: 0.0016004114877432585 | Test loss: 1.5530  | Test acc: 0.8041\n",
      "\n",
      " Train loss: 0.0007493893499486148 | Test loss: 1.8722  | Test acc: 0.7710\n",
      "\n",
      " Train loss: 0.0007711471407674253 | Test loss: 2.2122  | Test acc: 0.7380\n",
      "\n",
      " Train loss: 0.0008158614509738982 | Test loss: 2.1741  | Test acc: 0.7372\n",
      "\n",
      " Train loss: 0.0005349821294657886 | Test loss: 2.1440  | Test acc: 0.7328\n",
      "\n",
      " Train loss: 0.00054874800844118 | Test loss: 2.1362  | Test acc: 0.7315\n",
      "\n",
      " Train loss: 0.0008022867259569466 | Test loss: 2.1600  | Test acc: 0.7369\n",
      "\n",
      " Train loss: 0.0023628389462828636 | Test loss: 1.8935  | Test acc: 0.7616\n",
      "\n",
      " Train loss: 0.0019206712022423744 | Test loss: 1.6588  | Test acc: 0.7797\n",
      "\n",
      " Train loss: 0.00020062175462953746 | Test loss: 1.6263  | Test acc: 0.7813\n",
      "\n",
      " Train loss: 0.0004618973471224308 | Test loss: 1.7723  | Test acc: 0.7636\n",
      "\n",
      " Train loss: 0.0015078098513185978 | Test loss: 1.8415  | Test acc: 0.7591\n",
      "\n",
      " Train loss: 0.0008949493640102446 | Test loss: 1.8739  | Test acc: 0.7593\n",
      "\n",
      " Train loss: 0.000590880517847836 | Test loss: 1.9975  | Test acc: 0.7469\n",
      "\n",
      " Train loss: 0.0010653103236109018 | Test loss: 2.1579  | Test acc: 0.7188\n",
      "\n",
      " Train loss: 0.0006539096939377487 | Test loss: 2.0681  | Test acc: 0.7297\n",
      "\n",
      " Train loss: 0.002393872942775488 | Test loss: 1.7527  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0004834293504245579 | Test loss: 1.7059  | Test acc: 0.7712\n",
      "\n",
      " Train loss: 0.0008345575188286602 | Test loss: 1.8260  | Test acc: 0.7671\n",
      "\n",
      " Train loss: 0.001378818997181952 | Test loss: 1.8166  | Test acc: 0.7633\n",
      "\n",
      " Train loss: 0.001168956863693893 | Test loss: 1.8585  | Test acc: 0.7518\n",
      "\n",
      " Train loss: 0.0011487852316349745 | Test loss: 1.8425  | Test acc: 0.7430\n",
      "\n",
      " Train loss: 0.000998597708530724 | Test loss: 1.7483  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.0008357320330105722 | Test loss: 1.7472  | Test acc: 0.7361\n",
      "\n",
      " Train loss: 0.0005473746568895876 | Test loss: 1.6406  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0006213270244188607 | Test loss: 1.5881  | Test acc: 0.7649\n",
      "Looked at 51200/ 60000 samples\n",
      "\n",
      " Train loss: 0.0012825527228415012 | Test loss: 1.6496  | Test acc: 0.7701\n",
      "\n",
      " Train loss: 0.0007362319156527519 | Test loss: 1.9688  | Test acc: 0.7482\n",
      "\n",
      " Train loss: 0.0005275536677800119 | Test loss: 2.3393  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.0009342203265987337 | Test loss: 2.0785  | Test acc: 0.7419\n",
      "\n",
      " Train loss: 0.0007657143287360668 | Test loss: 1.8280  | Test acc: 0.7542\n",
      "\n",
      " Train loss: 0.0010972913587465882 | Test loss: 1.8203  | Test acc: 0.7541\n",
      "\n",
      " Train loss: 0.001196952536702156 | Test loss: 1.9476  | Test acc: 0.7481\n",
      "\n",
      " Train loss: 0.0018190232804045081 | Test loss: 2.1534  | Test acc: 0.7300\n",
      "\n",
      " Train loss: 0.0008002398535609245 | Test loss: 1.9951  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.0009590145782567561 | Test loss: 1.7688  | Test acc: 0.7632\n",
      "\n",
      " Train loss: 0.0007236925885081291 | Test loss: 1.7064  | Test acc: 0.7695\n",
      "\n",
      " Train loss: 0.0008671424584463239 | Test loss: 1.6831  | Test acc: 0.7847\n",
      "\n",
      " Train loss: 0.0009931346867233515 | Test loss: 1.8947  | Test acc: 0.7667\n",
      "\n",
      " Train loss: 0.0002182272874051705 | Test loss: 2.3318  | Test acc: 0.7354\n",
      "\n",
      " Train loss: 0.001503771753050387 | Test loss: 2.0972  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.0018487551715224981 | Test loss: 1.9359  | Test acc: 0.7560\n",
      "\n",
      " Train loss: 0.0006361320265568793 | Test loss: 2.4058  | Test acc: 0.7050\n",
      "\n",
      " Train loss: 0.00023078371305018663 | Test loss: 3.2734  | Test acc: 0.6676\n",
      "\n",
      " Train loss: 0.0014715553261339664 | Test loss: 3.1655  | Test acc: 0.6648\n",
      "\n",
      " Train loss: 0.0025827765930444 | Test loss: 2.5187  | Test acc: 0.7215\n",
      "\n",
      " Train loss: 0.0014810437569394708 | Test loss: 2.4049  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0010882235364988446 | Test loss: 2.8363  | Test acc: 0.7160\n",
      "\n",
      " Train loss: 0.0009228619164787233 | Test loss: 3.1538  | Test acc: 0.7035\n",
      "\n",
      " Train loss: 0.0009242953965440392 | Test loss: 2.8766  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.001790519803762436 | Test loss: 2.7290  | Test acc: 0.7137\n",
      "\n",
      " Train loss: 0.001780624152161181 | Test loss: 2.9797  | Test acc: 0.6947\n",
      "\n",
      " Train loss: 0.0013001704355701804 | Test loss: 3.2130  | Test acc: 0.6808\n",
      "\n",
      " Train loss: 0.001511444803327322 | Test loss: 2.8670  | Test acc: 0.6953\n",
      "\n",
      " Train loss: 0.0034588442649692297 | Test loss: 2.3404  | Test acc: 0.7076\n",
      "\n",
      " Train loss: 0.0014134692028164864 | Test loss: 3.0561  | Test acc: 0.6513\n",
      "\n",
      " Train loss: 0.0017864538822323084 | Test loss: 3.6816  | Test acc: 0.6225\n",
      "\n",
      " Train loss: 0.002881122985854745 | Test loss: 3.8310  | Test acc: 0.6766\n",
      "\n",
      " Train loss: 0.0024568645749241114 | Test loss: 3.8823  | Test acc: 0.6857\n",
      "\n",
      " Train loss: 0.0011986081954091787 | Test loss: 3.8903  | Test acc: 0.6739\n",
      "\n",
      " Train loss: 0.002332113217562437 | Test loss: 3.0241  | Test acc: 0.7152\n",
      "\n",
      " Train loss: 0.00049925985513255 | Test loss: 2.5628  | Test acc: 0.7377\n",
      "\n",
      " Train loss: 0.000997745431959629 | Test loss: 2.4297  | Test acc: 0.7431\n",
      "\n",
      " Train loss: 0.0011488574091345072 | Test loss: 2.6044  | Test acc: 0.7453\n",
      "\n",
      " Train loss: 0.002300742082297802 | Test loss: 2.8628  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0008460794924758375 | Test loss: 3.0350  | Test acc: 0.7303\n",
      "\n",
      " Train loss: 0.002286812523379922 | Test loss: 2.5509  | Test acc: 0.7609\n",
      "\n",
      " Train loss: 0.0010817344300448895 | Test loss: 2.4351  | Test acc: 0.7647\n",
      "\n",
      " Train loss: 0.0012393423821777105 | Test loss: 2.3092  | Test acc: 0.7654\n",
      "\n",
      " Train loss: 0.0002804505929816514 | Test loss: 2.3431  | Test acc: 0.7482\n",
      "\n",
      " Train loss: 0.0009944583289325237 | Test loss: 2.6165  | Test acc: 0.7337\n",
      "\n",
      " Train loss: 0.001498991041444242 | Test loss: 2.5898  | Test acc: 0.7464\n",
      "\n",
      " Train loss: 0.0007632371853105724 | Test loss: 2.5331  | Test acc: 0.7561\n",
      "\n",
      " Train loss: 0.0015305766137316823 | Test loss: 2.3697  | Test acc: 0.7725\n",
      "\n",
      " Train loss: 0.0009369971230626106 | Test loss: 2.3356  | Test acc: 0.7739\n",
      "\n",
      " Train loss: 0.0006812126957811415 | Test loss: 2.6225  | Test acc: 0.7553\n",
      "\n",
      " Train loss: 0.0014535412192344666 | Test loss: 2.5138  | Test acc: 0.7678\n",
      "\n",
      " Train loss: 0.0010707412147894502 | Test loss: 2.2912  | Test acc: 0.7865\n",
      "\n",
      " Train loss: 0.0016187501605600119 | Test loss: 2.4993  | Test acc: 0.7614\n",
      "\n",
      " Train loss: 0.001660674111917615 | Test loss: 2.2579  | Test acc: 0.7789\n",
      "\n",
      " Train loss: 0.0006351001211442053 | Test loss: 1.9713  | Test acc: 0.7966\n",
      "\n",
      " Train loss: 0.0014201521407812834 | Test loss: 1.9976  | Test acc: 0.7904\n",
      "\n",
      " Train loss: 0.0007035875460132957 | Test loss: 1.9777  | Test acc: 0.8006\n",
      "\n",
      " Train loss: 0.0006268167635425925 | Test loss: 2.1353  | Test acc: 0.7922\n",
      "\n",
      " Train loss: 0.001050393795594573 | Test loss: 2.2351  | Test acc: 0.7851\n",
      "\n",
      " Train loss: 0.0008789548301137984 | Test loss: 2.6023  | Test acc: 0.7576\n",
      "\n",
      " Train loss: 0.00028399244183674455 | Test loss: 2.9564  | Test acc: 0.7349\n",
      "\n",
      " Train loss: 0.001453158794902265 | Test loss: 2.9347  | Test acc: 0.7324\n",
      "\n",
      " Train loss: 0.0008037359802983701 | Test loss: 2.5005  | Test acc: 0.7550\n",
      "\n",
      " Train loss: 0.0014772992581129074 | Test loss: 2.0575  | Test acc: 0.7762\n",
      "\n",
      " Train loss: 0.0005051798070780933 | Test loss: 2.3529  | Test acc: 0.7578\n",
      "\n",
      " Train loss: 0.0008616615668870509 | Test loss: 2.6554  | Test acc: 0.7492\n",
      "\n",
      " Train loss: 0.0009250836446881294 | Test loss: 2.7047  | Test acc: 0.7714\n",
      "\n",
      " Train loss: 0.0022361453156918287 | Test loss: 3.1290  | Test acc: 0.7350\n",
      "\n",
      " Train loss: 0.003260186407715082 | Test loss: 3.6455  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.0024441054556518793 | Test loss: 3.8394  | Test acc: 0.6942\n",
      "\n",
      " Train loss: 0.0009803271386772394 | Test loss: 3.4570  | Test acc: 0.7184\n",
      "\n",
      " Train loss: 0.0020151901990175247 | Test loss: 3.0227  | Test acc: 0.7454\n",
      "\n",
      " Train loss: 0.0010405094362795353 | Test loss: 3.2661  | Test acc: 0.7237\n",
      "\n",
      " Train loss: 0.0011171655496582389 | Test loss: 3.7841  | Test acc: 0.7001\n",
      "\n",
      " Train loss: 0.001975382911041379 | Test loss: 3.0502  | Test acc: 0.7292\n",
      "\n",
      " Train loss: 0.0008882844704203308 | Test loss: 2.3434  | Test acc: 0.7731\n",
      "\n",
      " Train loss: 0.0015710870502516627 | Test loss: 2.3631  | Test acc: 0.7753\n",
      "\n",
      " Train loss: 0.001077658380381763 | Test loss: 3.2057  | Test acc: 0.7420\n",
      "\n",
      " Train loss: 0.0007204014109447598 | Test loss: 3.9127  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.002838067477568984 | Test loss: 3.7083  | Test acc: 0.7129\n",
      "\n",
      " Train loss: 0.002863513771444559 | Test loss: 3.2268  | Test acc: 0.7485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.001884835073724389 | Test loss: 2.9997  | Test acc: 0.7734\n",
      "\n",
      " Train loss: 0.0005089991609565914 | Test loss: 3.7792  | Test acc: 0.7243\n",
      "\n",
      " Train loss: 0.0028664206620305777 | Test loss: 3.8772  | Test acc: 0.7195\n",
      "\n",
      " Train loss: 0.002694659400731325 | Test loss: 3.0842  | Test acc: 0.7597\n",
      "\n",
      " Train loss: 0.0029525896534323692 | Test loss: 3.4259  | Test acc: 0.7322\n",
      "\n",
      " Train loss: 0.0016593147302046418 | Test loss: 4.8029  | Test acc: 0.6827\n",
      "\n",
      " Train loss: 0.0021952625829726458 | Test loss: 4.1396  | Test acc: 0.7069\n",
      "\n",
      " Train loss: 0.001368580968119204 | Test loss: 3.4194  | Test acc: 0.7373\n",
      "\n",
      " Train loss: 0.002454651053994894 | Test loss: 3.2598  | Test acc: 0.7452\n",
      "\n",
      " Train loss: 0.0024248098488897085 | Test loss: 3.9028  | Test acc: 0.6915\n",
      "\n",
      " Train loss: 0.0021105811465531588 | Test loss: 3.5867  | Test acc: 0.7101\n",
      "\n",
      " Train loss: 0.002647330053150654 | Test loss: 3.0775  | Test acc: 0.7563\n",
      "\n",
      " Train loss: 0.0014463703846558928 | Test loss: 3.2901  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.0008295621955767274 | Test loss: 4.1470  | Test acc: 0.6992\n",
      "\n",
      " Train loss: 0.0021722253877669573 | Test loss: 3.0010  | Test acc: 0.7685\n",
      "\n",
      " Train loss: 0.0016164175467565656 | Test loss: 2.9804  | Test acc: 0.7723\n",
      "\n",
      " Train loss: 0.000739346956834197 | Test loss: 3.0308  | Test acc: 0.7663\n",
      "\n",
      " Train loss: 0.000625789281912148 | Test loss: 3.5488  | Test acc: 0.7290\n",
      "\n",
      " Train loss: 0.0008172154775820673 | Test loss: 3.2119  | Test acc: 0.7467\n",
      "\n",
      " Train loss: 0.0009911535307765007 | Test loss: 2.9188  | Test acc: 0.7717\n",
      "\n",
      " Train loss: 0.00043217750499024987 | Test loss: 3.0451  | Test acc: 0.7744\n",
      "\n",
      " Train loss: 0.0014558563707396388 | Test loss: 3.3370  | Test acc: 0.7675\n",
      "\n",
      " Train loss: 0.0021303819958120584 | Test loss: 3.4286  | Test acc: 0.7677\n",
      "\n",
      " Train loss: 0.0012379653053358197 | Test loss: 3.0881  | Test acc: 0.7872\n",
      "\n",
      " Train loss: 0.0011088487226516008 | Test loss: 2.9832  | Test acc: 0.7824\n",
      "\n",
      " Train loss: 0.001292495639063418 | Test loss: 3.0132  | Test acc: 0.7759\n",
      "\n",
      " Train loss: 0.0009909359505400062 | Test loss: 3.5568  | Test acc: 0.7412\n",
      "\n",
      " Train loss: 0.0013554320903494954 | Test loss: 4.3509  | Test acc: 0.7040\n",
      "\n",
      " Train loss: 0.0013930543791502714 | Test loss: 4.3704  | Test acc: 0.7046\n",
      "\n",
      " Train loss: 0.0018507116474211216 | Test loss: 4.1052  | Test acc: 0.7157\n",
      "\n",
      " Train loss: 0.0012986025540158153 | Test loss: 3.6328  | Test acc: 0.7302\n",
      "\n",
      " Train loss: 0.0013893719296902418 | Test loss: 4.2571  | Test acc: 0.7050\n",
      "\n",
      " Train loss: 0.002000833163037896 | Test loss: 5.0640  | Test acc: 0.6831\n",
      "\n",
      " Train loss: 0.0033287927508354187 | Test loss: 4.5700  | Test acc: 0.6971\n",
      "\n",
      " Train loss: 0.0006011590594425797 | Test loss: 4.1830  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.0013002847554162145 | Test loss: 3.7204  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0010566851124167442 | Test loss: 3.1542  | Test acc: 0.7450\n",
      "\n",
      " Train loss: 0.0019129783613607287 | Test loss: 3.0910  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0024888934567570686 | Test loss: 2.8787  | Test acc: 0.7115\n",
      "\n",
      " Train loss: 0.0019782735034823418 | Test loss: 2.3244  | Test acc: 0.7558\n",
      "\n",
      " Train loss: 0.000504863157402724 | Test loss: 2.5541  | Test acc: 0.7365\n",
      "\n",
      " Train loss: 0.0008544180309399962 | Test loss: 2.5346  | Test acc: 0.7442\n",
      "\n",
      " Train loss: 0.0005929323961026967 | Test loss: 2.3433  | Test acc: 0.7680\n",
      "\n",
      " Train loss: 0.0016025962540879846 | Test loss: 2.4741  | Test acc: 0.7676\n",
      "\n",
      " Train loss: 0.001072162063792348 | Test loss: 2.8805  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.000729485705960542 | Test loss: 3.7026  | Test acc: 0.7109\n",
      "\n",
      " Train loss: 0.001636598608456552 | Test loss: 4.4095  | Test acc: 0.6696\n",
      "\n",
      " Train loss: 0.002894605975598097 | Test loss: 3.8073  | Test acc: 0.7041\n",
      "\n",
      " Train loss: 0.002866062568500638 | Test loss: 3.0102  | Test acc: 0.7513\n",
      "\n",
      " Train loss: 0.000988700077868998 | Test loss: 2.9494  | Test acc: 0.7301\n",
      "\n",
      " Train loss: 0.0034762341529130936 | Test loss: 3.0010  | Test acc: 0.7182\n",
      "\n",
      " Train loss: 0.0006076484569348395 | Test loss: 3.5567  | Test acc: 0.7269\n",
      "\n",
      " Train loss: 0.0031439620070159435 | Test loss: 4.3546  | Test acc: 0.7093\n",
      "\n",
      " Train loss: 0.002590355696156621 | Test loss: 4.0014  | Test acc: 0.7010\n",
      "\n",
      " Train loss: 0.0025636740028858185 | Test loss: 3.7449  | Test acc: 0.7140\n",
      "\n",
      " Train loss: 0.0005816040793433785 | Test loss: 3.3098  | Test acc: 0.7335\n",
      "\n",
      " Train loss: 0.0016015220899134874 | Test loss: 3.2248  | Test acc: 0.7296\n",
      "\n",
      " Train loss: 0.0007875670562498271 | Test loss: 3.1736  | Test acc: 0.7236\n",
      "\n",
      " Train loss: 0.0016128268325701356 | Test loss: 3.0379  | Test acc: 0.7291\n",
      "\n",
      " Train loss: 0.002402431797236204 | Test loss: 3.3217  | Test acc: 0.7186\n",
      "\n",
      " Train loss: 0.0015546429203823209 | Test loss: 4.0075  | Test acc: 0.6846\n",
      "\n",
      " Train loss: 0.004093898460268974 | Test loss: 3.1116  | Test acc: 0.7396\n",
      "\n",
      " Train loss: 0.0015590374823659658 | Test loss: 3.0948  | Test acc: 0.7515\n",
      "\n",
      " Train loss: 0.0010432600975036621 | Test loss: 3.4097  | Test acc: 0.7478\n",
      "\n",
      " Train loss: 0.0005293696885928512 | Test loss: 3.9080  | Test acc: 0.7335\n",
      "\n",
      " Train loss: 0.0007573544862680137 | Test loss: 4.1130  | Test acc: 0.7363\n",
      "\n",
      " Train loss: 0.0028421753086149693 | Test loss: 3.2871  | Test acc: 0.7690\n",
      "\n",
      " Train loss: 0.0014707790687680244 | Test loss: 3.0552  | Test acc: 0.7538\n",
      "\n",
      " Train loss: 0.0006658178172074258 | Test loss: 3.0411  | Test acc: 0.7512\n",
      "\n",
      " Train loss: 0.0006286381976678967 | Test loss: 3.6328  | Test acc: 0.7245\n",
      "\n",
      " Train loss: 0.0010913705918937922 | Test loss: 4.2299  | Test acc: 0.7042\n",
      "\n",
      " Train loss: 0.0021791490726172924 | Test loss: 4.1043  | Test acc: 0.7059\n",
      "\n",
      " Train loss: 0.0032143923453986645 | Test loss: 3.3722  | Test acc: 0.7402\n",
      "\n",
      " Train loss: 0.0009865851607173681 | Test loss: 2.8816  | Test acc: 0.7687\n",
      "\n",
      " Train loss: 0.001523554208688438 | Test loss: 2.7193  | Test acc: 0.7826\n",
      "\n",
      " Train loss: 0.001612591790035367 | Test loss: 2.8599  | Test acc: 0.7711\n",
      "\n",
      " Train loss: 0.0006578663596883416 | Test loss: 3.0050  | Test acc: 0.7557\n",
      "\n",
      " Train loss: 0.002441136399284005 | Test loss: 2.8580  | Test acc: 0.7457\n",
      "\n",
      " Train loss: 0.0005953279323875904 | Test loss: 2.9300  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.001801205682568252 | Test loss: 2.6428  | Test acc: 0.7394\n",
      "\n",
      " Train loss: 0.0018906714394688606 | Test loss: 2.2885  | Test acc: 0.7650\n",
      "\n",
      " Train loss: 0.0008596422849223018 | Test loss: 2.1202  | Test acc: 0.7806\n",
      "\n",
      " Train loss: 0.0009735801722854376 | Test loss: 2.2675  | Test acc: 0.7587\n",
      "\n",
      " Train loss: 0.000537755258847028 | Test loss: 2.4671  | Test acc: 0.7497\n",
      "\n",
      " Train loss: 0.0007240151171572506 | Test loss: 2.8776  | Test acc: 0.7313\n",
      "\n",
      " Train loss: 0.0026336340233683586 | Test loss: 3.5366  | Test acc: 0.6843\n",
      "\n",
      " Train loss: 0.00391248008236289 | Test loss: 2.5530  | Test acc: 0.7660\n",
      "\n",
      " Train loss: 0.0005684010684490204 | Test loss: 2.6130  | Test acc: 0.7639\n",
      "\n",
      " Train loss: 0.0007594366325065494 | Test loss: 2.7636  | Test acc: 0.7485\n",
      "\n",
      " Train loss: 0.0015145117649808526 | Test loss: 2.4465  | Test acc: 0.7613\n",
      "\n",
      " Train loss: 0.00045640688040293753 | Test loss: 2.5865  | Test acc: 0.7427\n",
      "\n",
      " Train loss: 0.0025486787781119347 | Test loss: 3.1162  | Test acc: 0.7086\n",
      "\n",
      " Train loss: 0.0007390585378743708 | Test loss: 3.4193  | Test acc: 0.7132\n",
      "\n",
      " Train loss: 0.0024190768599510193 | Test loss: 2.9078  | Test acc: 0.7460\n",
      "\n",
      " Train loss: 0.0004535428888630122 | Test loss: 2.5752  | Test acc: 0.7609\n",
      "\n",
      " Train loss: 0.00025137545890174806 | Test loss: 2.5457  | Test acc: 0.7630\n",
      "\n",
      " Train loss: 0.0016768111381679773 | Test loss: 2.7950  | Test acc: 0.7486\n",
      "\n",
      " Train loss: 0.002297786995768547 | Test loss: 3.2264  | Test acc: 0.7286\n",
      "\n",
      " Train loss: 0.000828428310342133 | Test loss: 3.5992  | Test acc: 0.7267\n",
      "\n",
      " Train loss: 0.0011308299144729972 | Test loss: 3.6078  | Test acc: 0.7385\n",
      "\n",
      " Train loss: 0.0007326088380068541 | Test loss: 3.7324  | Test acc: 0.7255\n",
      "\n",
      " Train loss: 0.002166660036891699 | Test loss: 3.6347  | Test acc: 0.7113\n",
      "\n",
      " Train loss: 0.0015943953767418861 | Test loss: 3.5498  | Test acc: 0.6996\n",
      "\n",
      " Train loss: 0.0015548879746347666 | Test loss: 4.1898  | Test acc: 0.6540\n",
      "\n",
      " Train loss: 0.0018538912991061807 | Test loss: 4.1720  | Test acc: 0.6627\n",
      "\n",
      " Train loss: 0.002715175272896886 | Test loss: 3.3000  | Test acc: 0.7038\n",
      "\n",
      " Train loss: 0.0020681677851825953 | Test loss: 2.9368  | Test acc: 0.7043\n",
      "\n",
      " Train loss: 0.0013669717591255903 | Test loss: 3.2568  | Test acc: 0.6957\n",
      "\n",
      " Train loss: 0.002421411918476224 | Test loss: 2.8895  | Test acc: 0.7249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train loss: 0.000862860877532512 | Test loss: 2.7218  | Test acc: 0.7422\n",
      "\n",
      " Train loss: 0.0007100030779838562 | Test loss: 2.7511  | Test acc: 0.7418\n",
      "\n",
      " Train loss: 0.001488097244873643 | Test loss: 2.7025  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.00134432059712708 | Test loss: 2.6931  | Test acc: 0.7612\n",
      "\n",
      " Train loss: 0.0014795410679653287 | Test loss: 2.3486  | Test acc: 0.7676\n",
      "\n",
      " Train loss: 0.0005624537589028478 | Test loss: 2.3219  | Test acc: 0.7526\n",
      "\n",
      " Train loss: 0.0013364964397624135 | Test loss: 2.6634  | Test acc: 0.7254\n",
      "\n",
      " Train loss: 0.0010021915659308434 | Test loss: 3.2938  | Test acc: 0.6927\n",
      "\n",
      " Train loss: 0.0014472519978880882 | Test loss: 3.9474  | Test acc: 0.6646\n",
      "\n",
      " Train loss: 0.001558771007694304 | Test loss: 3.2648  | Test acc: 0.6802\n",
      "\n",
      " Train loss: 0.001804328290745616 | Test loss: 2.8051  | Test acc: 0.7048\n",
      "\n",
      " Train loss: 0.0005673767300322652 | Test loss: 3.1010  | Test acc: 0.7125\n",
      "\n",
      " Train loss: 0.0014775112504139543 | Test loss: 2.9427  | Test acc: 0.7633\n",
      "\n",
      " Train loss: 0.001292999368160963 | Test loss: 3.2077  | Test acc: 0.7248\n",
      "\n",
      " Train loss: 0.0009372276836074889 | Test loss: 3.0321  | Test acc: 0.7470\n",
      "\n",
      " Train loss: 0.0013711026404052973 | Test loss: 2.8280  | Test acc: 0.7539\n",
      "\n",
      " Train loss: 0.0018179246690124273 | Test loss: 2.8640  | Test acc: 0.7178\n",
      "\n",
      " Train loss: 0.002010201569646597 | Test loss: 3.2305  | Test acc: 0.6888\n",
      "\n",
      " Train loss: 0.0025425369385629892 | Test loss: 2.8514  | Test acc: 0.7084\n",
      "\n",
      " Train loss: 0.001160236308351159 | Test loss: 2.2872  | Test acc: 0.7480\n",
      "\n",
      " Train loss: 0.0011867072898894548 | Test loss: 1.9628  | Test acc: 0.7796\n",
      "\n",
      " Train loss: 0.0016309554921463132 | Test loss: 1.9394  | Test acc: 0.7812\n",
      "\n",
      " Train loss: 0.001102928421460092 | Test loss: 1.9404  | Test acc: 0.7739\n",
      "\n",
      " Train loss: 0.001132879056967795 | Test loss: 2.2192  | Test acc: 0.7568\n",
      "\n",
      " Train loss: 0.002205481519922614 | Test loss: 2.5319  | Test acc: 0.7260\n",
      "\n",
      " Train loss: 0.0012487268541008234 | Test loss: 2.7022  | Test acc: 0.7066\n",
      "\n",
      " Train loss: 0.0006361674750223756 | Test loss: 2.8877  | Test acc: 0.6973\n",
      "\n",
      " Train loss: 0.0006801595445722342 | Test loss: 4.1676  | Test acc: 0.6239\n",
      "\n",
      " Train loss: 0.0018809253815561533 | Test loss: 5.0391  | Test acc: 0.5953\n",
      "\n",
      " Train loss: 0.0037784716114401817 | Test loss: 3.1639  | Test acc: 0.7027\n",
      "\n",
      " Train loss: 0.0010350721422582865 | Test loss: 2.4739  | Test acc: 0.7445\n",
      "\n",
      " Train loss: 0.001077253371477127 | Test loss: 2.6643  | Test acc: 0.7393\n",
      "\n",
      " Train loss: 0.0010839899769052863 | Test loss: 3.1819  | Test acc: 0.7058\n",
      "\n",
      " Train loss: 0.0007751401863060892 | Test loss: 4.1170  | Test acc: 0.6605\n",
      "\n",
      " Train loss: 0.0014043721603229642 | Test loss: 2.7198  | Test acc: 0.7351\n",
      "\n",
      " Train loss: 0.0014613388339057565 | Test loss: 2.3843  | Test acc: 0.7556\n",
      "\n",
      " Train loss: 0.0002879893290810287 | Test loss: 2.7952  | Test acc: 0.7437\n",
      "\n",
      " Train loss: 0.0008578816195949912 | Test loss: 2.7940  | Test acc: 0.7509\n",
      "\n",
      " Train loss: 0.0029001899529248476 | Test loss: 2.5255  | Test acc: 0.7642\n",
      "\n",
      " Train loss: 0.0018701446242630482 | Test loss: 2.5108  | Test acc: 0.7683\n",
      "\n",
      " Train loss: 0.0010478314943611622 | Test loss: 2.7332  | Test acc: 0.7400\n",
      "\n",
      " Train loss: 0.0005107914912514389 | Test loss: 3.6909  | Test acc: 0.6898\n",
      "\n",
      " Train loss: 0.0032727173529565334 | Test loss: 5.7619  | Test acc: 0.6226\n",
      "\n",
      " Train loss: 0.0026551068294793367 | Test loss: 5.2188  | Test acc: 0.6394\n",
      "\n",
      " Train loss: 0.0011873540934175253 | Test loss: 4.3963  | Test acc: 0.6727\n",
      "\n",
      " Train loss: 0.001442406210117042 | Test loss: 4.9003  | Test acc: 0.6878\n",
      "\n",
      " Train loss: 0.0007319228025153279 | Test loss: 6.0997  | Test acc: 0.6740\n",
      "\n",
      " Train loss: 0.0030848332680761814 | Test loss: 5.3524  | Test acc: 0.6971\n",
      "\n",
      " Train loss: 0.0029498774092644453 | Test loss: 3.5901  | Test acc: 0.7448\n",
      "\n",
      " Train loss: 0.0018778203520923853 | Test loss: 3.5444  | Test acc: 0.7333\n",
      "\n",
      " Train loss: 0.0010998566867783666 | Test loss: 6.8004  | Test acc: 0.6420\n",
      "\n",
      " Train loss: 0.0017538412939757109 | Test loss: 7.8512  | Test acc: 0.6217\n",
      "\n",
      " Train loss: 0.004622609820216894 | Test loss: 5.6035  | Test acc: 0.7008\n",
      "\n",
      " Train loss: 0.004878812003880739 | Test loss: 4.7762  | Test acc: 0.7102\n",
      "\n",
      " Train loss: 0.000781499722506851 | Test loss: 5.1170  | Test acc: 0.7097\n",
      "\n",
      " Train loss: 0.002910766750574112 | Test loss: 4.3203  | Test acc: 0.7242\n",
      "\n",
      " Train loss: 0.002880928572267294 | Test loss: 3.6813  | Test acc: 0.7389\n",
      "\n",
      " Train loss: 0.001065293326973915 | Test loss: 4.4641  | Test acc: 0.6879\n",
      "\n",
      " Train loss: 0.0011548029724508524 | Test loss: 6.3966  | Test acc: 0.5975\n",
      "\n",
      " Train loss: 0.004879340063780546 | Test loss: 4.4214  | Test acc: 0.6818\n",
      "\n",
      " Train loss: 0.0010897023603320122 | Test loss: 3.7963  | Test acc: 0.6903\n",
      "\n",
      " Train loss: 0.0018969892989844084 | Test loss: 3.9266  | Test acc: 0.6989\n",
      "\n",
      " Train loss: 0.0018767460715025663 | Test loss: 3.9145  | Test acc: 0.7000\n",
      "\n",
      " Train loss: 0.0023335253354161978 | Test loss: 3.3484  | Test acc: 0.7238\n",
      "\n",
      " Train loss: 0.0018248611595481634 | Test loss: 3.5208  | Test acc: 0.7218\n",
      "\n",
      " Train loss: 0.0017891679890453815 | Test loss: 3.6330  | Test acc: 0.7334\n",
      "\n",
      " Train loss: 0.0012125216890126467 | Test loss: 3.5619  | Test acc: 0.7208\n",
      "\n",
      " Train loss: 0.005079494323581457 | Test loss: 2.7735  | Test acc: 0.7378\n",
      "\n",
      " Train loss: 0.0010644010035321116 | Test loss: 3.4840  | Test acc: 0.7120\n",
      "\n",
      " Train loss: 0.0001870531268650666 | Test loss: 4.2875  | Test acc: 0.6859\n",
      "\n",
      " Train loss: 0.0031779673881828785 | Test loss: 3.3718  | Test acc: 0.7439\n",
      "\n",
      " Train loss: 0.00102979876101017 | Test loss: 2.9226  | Test acc: 0.7768\n",
      "\n",
      " Train loss: 0.0007585734711028636 | Test loss: 4.0500  | Test acc: 0.7499\n",
      "\n",
      " Train loss: 0.0015530093805864453 | Test loss: 7.9929  | Test acc: 0.6414\n",
      "\n",
      " Train loss: 0.005363993812352419 | Test loss: 3.1507  | Test acc: 0.7475\n",
      "\n",
      " Train loss: 0.0011741359485313296 | Test loss: 3.4896  | Test acc: 0.7110\n",
      "\n",
      " Train loss: 0.002710346132516861 | Test loss: 3.3918  | Test acc: 0.7187\n",
      "\n",
      " Train loss: 0.002583045745268464 | Test loss: 3.4688  | Test acc: 0.7359\n",
      "\n",
      " Train loss: 0.0010042167268693447 | Test loss: 3.8175  | Test acc: 0.7227\n",
      "\n",
      " Train loss: 0.003558988217264414 | Test loss: 4.1787  | Test acc: 0.7031\n",
      "\n",
      " Train loss: 0.0014058208325877786 | Test loss: 4.2447  | Test acc: 0.6958\n",
      "\n",
      " Train loss: 0.002213450148701668 | Test loss: 3.6119  | Test acc: 0.7408\n",
      "\n",
      " Train loss: 0.00021391267364379019 | Test loss: 3.9089  | Test acc: 0.7285\n",
      "\n",
      " Train loss: 0.0035612827632576227 | Test loss: 3.3144  | Test acc: 0.7564\n",
      "\n",
      " Train loss: 0.0009087123326025903 | Test loss: 3.6492  | Test acc: 0.7289\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'torch.device' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Calculate training time\u001b[39;00m\n\u001b[0;32m     56\u001b[0m train_time_end_on_cpu \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m---> 57\u001b[0m total_train_time_model_1 \u001b[38;5;241m=\u001b[39m print_train_time(start \u001b[38;5;241m=\u001b[39m train_time_start_on_cpu, end \u001b[38;5;241m=\u001b[39m train_time_end_on_cpu, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'torch.device' object is not callable"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bar \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch {epoch}\\n------\")\n",
    "    train_loss = 0 # Calculating train loss per batch\n",
    "    \n",
    "    # looping through training batches\n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        model_1.train()\n",
    "        \n",
    "        y_pred = model_1(X)\n",
    "        \n",
    "        # Loss per batch\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/ {len(train_dataloader.dataset)} samples\")\n",
    "            \n",
    "            # Divide total train loss by length of train dataloader \n",
    "            # To find the average loss per epoch\n",
    "            \n",
    "        train_loss /= len(train_dataloader)\n",
    "            \n",
    "        # Testing the model \n",
    "\n",
    "        test_loss, test_acc = 0, 0\n",
    "        model_1.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X, y in test_dataloader:\n",
    "                test_pred = model_1(X)            \n",
    "                test_loss += loss_fn(test_pred, y)\n",
    "                test_acc += acc(test_pred.argmax(dim = 1), y)\n",
    "            \n",
    "            # Calculate the average test loss per batch\n",
    "            test_loss /= len(test_dataloader)\n",
    "            \n",
    "            # Calculate the average test loss per batch\n",
    "            test_acc /= len(test_dataloader)\n",
    "        \n",
    "        print(f\"\\n Train loss: {train_loss} | Test loss: {test_loss:.4f}  | Test acc: {test_acc:.4f}\")\n",
    "        \n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start = train_time_start_on_cpu, end = train_time_end_on_cpu, device = str(next(model_1.parameters()).device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e78cc",
   "metadata": {},
   "source": [
    "### Building the model with non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f3c8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape:int, \n",
    "                 hidden_units:int,\n",
    "                 output_shape:int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_stack = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(in_features = input_shape, out_features = hidden_units),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features = hidden_units, out_features = output_shape),\n",
    "                nn.ReLU() \n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c776342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_2 = FashionMNISTModelV1(input_shape = 784, hidden_units = 10, output_shape = 10)\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88f8d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model_2.parameters(), lr = 0.1)\n",
    "\n",
    "acc = Accuracy(task = 'Multiclass', num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "716aa4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411ad69",
   "metadata": {},
   "source": [
    "### Functionalizing the train and test loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e7f198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader,\n",
    "                 loss: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 accuracy,\n",
    "                 device: torch.device = device):\n",
    "    \n",
    "    \n",
    "\n",
    "        train_loss, train_acc = 0,0 \n",
    "        # looping through training batches\n",
    "        for batch, (X,y) in enumerate(data_loader):\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Loss and accuracy per batch\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss\n",
    "            \n",
    "            train_acc += acc(y_pred.argmax(dim = 1), y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "        # Divide total train loss by length of train dataloader \n",
    "        # To find the average loss per epoch\n",
    "\n",
    "        train_loss /= len(data_loader)\n",
    "        train_acc /= len(data_loader)\n",
    "        \n",
    "        print(f\"Train loss: {train_loss:.5f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6df0bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss: torch.nn.Module,\n",
    "              accuracy,\n",
    "              device: torch.device = device):\n",
    "             \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            \n",
    "            test_pred = model(X)  \n",
    "            \n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += acc(test_pred.argmax(dim = 1), y)\n",
    "            \n",
    "        # Calculate the average test loss per batch\n",
    "        test_loss /= len(data_loader)\n",
    "            \n",
    "        # Calculate the average test loss per batch\n",
    "        test_acc /= len(data_loader)\n",
    "        \n",
    "        print(f\"\\n Test loss: {test_loss:.4f}  | Test acc: {test_acc:.2f}%\")\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e21f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ef097672b343e38b8c423ea816cf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "-----------\n",
      "Train loss: 0.77471, Train Acc: 0.71%\n",
      "\n",
      " Test loss: 0.6818  | Test acc: 0.75%\n",
      "Epoch: 1 \n",
      "-----------\n",
      "Train loss: 0.61971, Train Acc: 0.77%\n",
      "\n",
      " Test loss: 0.6971  | Test acc: 0.74%\n",
      "Epoch: 2 \n",
      "-----------\n",
      "Train loss: 0.61003, Train Acc: 0.78%\n",
      "\n",
      " Test loss: 0.6475  | Test acc: 0.77%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n-----------\")\n",
    "    \n",
    "    train_step(model = model_2,\n",
    "              data_loader = train_dataloader,\n",
    "              loss = loss_fn,\n",
    "              optimizer = optimizer,\n",
    "              accuracy = acc,\n",
    "              device = device)\n",
    "    \n",
    "    test_step(model = model_2,\n",
    "              data_loader = test_dataloader,\n",
    "              loss = loss_fn,\n",
    "              accuracy = acc,\n",
    "              device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afdf34",
   "metadata": {},
   "source": [
    "### Building CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58558f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
